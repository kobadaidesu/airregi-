{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp21: exp19ã®æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’Holdout Validationã§è©•ä¾¡\n",
    "\n",
    "**ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³**: exp20 (Rolling Window Validation)\n",
    "\n",
    "**èƒŒæ™¯**:\n",
    "- exp20ã§ã¯exp19ã®æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’Rolling Window Validationï¼ˆ8ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼‰ã§è©•ä¾¡\n",
    "- Rolling Windowã¯æ™‚ç³»åˆ—ã«é ‘å¥ã ãŒã€è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ãè§£é‡ˆãŒè¤‡é›‘\n",
    "- ã‚·ãƒ³ãƒ—ãƒ«ãªHoldout Validationï¼ˆTrain/Teståˆ†å‰²ï¼‰ã§ã®æ€§èƒ½ã‚‚ç¢ºèªã—ãŸã„\n",
    "\n",
    "**exp21ã®ç›®çš„**:\n",
    "- exp20ã¨åŒã˜exp19ã®æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨\n",
    "- ã‚·ãƒ³ãƒ—ãƒ«ãªHoldout Validationï¼ˆTrain/Teståˆ†å‰²ï¼‰ã§è©•ä¾¡\n",
    "- Rolling Window vs Holdoutã®æ¯”è¼ƒ\n",
    "\n",
    "**Holdoutè¨­å®š**:\n",
    "- Train: 2018-07-02 ~ 2020-01-29ï¼ˆç´„18ãƒ¶æœˆï¼‰\n",
    "- Test: 2020-01-30 ~ 2020-03-30ï¼ˆç´„2ãƒ¶æœˆï¼‰\n",
    "- â€»æœ€æ–°2ãƒ¶æœˆã‚’ãƒ†ã‚¹ãƒˆã«ä½¿ç”¨ï¼ˆexp20ã®Window 8ã¨åŒã˜æœŸé–“ï¼‰\n",
    "\n",
    "**æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆexp19ã‚ˆã‚Šï¼‰**:\n",
    "1. **Ridge** - alphaå†æœ€é©åŒ–\n",
    "2. **ExtraTrees** - n_estimators, max_depthç­‰\n",
    "3. **HistGradientBoosting** - learning_rate, max_depthç­‰\n",
    "4. **CatBoost** - iterations, learning_rate, depthç­‰\n",
    "5. **WeightedEnsemble_A** - Testã‚»ãƒƒãƒˆã§é‡ã¿æœ€é©åŒ–\n",
    "\n",
    "**æœŸå¾…åŠ¹æœ**:\n",
    "- ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ãªæ¤œè¨¼æ–¹æ³•ã§ã®æ€§èƒ½ç¢ºèª\n",
    "- Rolling Windowï¼ˆexp20ï¼‰ã¨ã®æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# exp19ã§æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆexp20ã¨åŒã˜ï¼‰\n",
    "# ============================================================================\n",
    "\n",
    "OPTIMIZED_PARAMS_EXP19 = {\n",
    "    'Ridge': {\n",
    "        'alpha': 16.450548234070856\n",
    "    },\n",
    "    'ExtraTrees': {\n",
    "        'n_estimators': 472,\n",
    "        'max_depth': 35,\n",
    "        'min_samples_split': 15,\n",
    "        'min_samples_leaf': 4,\n",
    "        'max_features': None\n",
    "    },\n",
    "    'HistGradientBoosting': {\n",
    "        'max_iter': 465,\n",
    "        'learning_rate': 0.02173701290406704,\n",
    "        'max_depth': 22,\n",
    "        'min_samples_leaf': 17,\n",
    "        'l2_regularization': 11.071266395457282\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'iterations': 2099,\n",
    "        'learning_rate': 0.04211275181711693,\n",
    "        'depth': 9,\n",
    "        'l2_leaf_reg': 3.7647684179184813,\n",
    "        'subsample': 0.9533426254881911\n",
    "    }\n",
    "}\n",
    "\n",
    "print('exp19ã§æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ')\n",
    "print('\\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è©³ç´°:')\n",
    "for model_name, params in OPTIMIZED_PARAMS_EXP19.items():\n",
    "    print(f'\\n{model_name}:')\n",
    "    for key, value in params.items():\n",
    "        print(f'  {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨ç‰¹å¾´é‡ä½œæˆï¼ˆexp16/exp20ã¨åŒã˜ï¼‰\n",
    "# ==================================================================================\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Step 1: ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    calender = pd.read_csv('../input/calender_data.csv')\n",
    "    cm_data = pd.read_csv('../input/cm_data.csv')\n",
    "    gt_service = pd.read_csv('../input/gt_service_name.csv')\n",
    "    acc_get = pd.read_csv('../input/regi_acc_get_data_transform.csv')\n",
    "    call_data = pd.read_csv('../input/regi_call_data_transform.csv')\n",
    "    \n",
    "    calender['cdr_date'] = pd.to_datetime(calender['cdr_date'])\n",
    "    cm_data['cdr_date'] = pd.to_datetime(cm_data['cdr_date'])\n",
    "    acc_get['cdr_date'] = pd.to_datetime(acc_get['cdr_date'])\n",
    "    call_data['cdr_date'] = pd.to_datetime(call_data['cdr_date'])\n",
    "    gt_service['week'] = pd.to_datetime(gt_service['week'])\n",
    "    \n",
    "    print(f\"\\nãƒ‡ãƒ¼ã‚¿æœŸé–“: {call_data['cdr_date'].min()} ~ {call_data['cdr_date'].max()}\")\n",
    "    \n",
    "    return calender, cm_data, gt_service, acc_get, call_data\n",
    "\n",
    "def merge_datasets(calender, cm_data, gt_service, acc_get, call_data):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Step 2: ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    df = call_data.copy()\n",
    "    df = df.merge(calender, on='cdr_date', how='left')\n",
    "    df = df.merge(cm_data, on='cdr_date', how='left')\n",
    "    df = df.merge(acc_get, on='cdr_date', how='left')\n",
    "    \n",
    "    gt_service_daily = []\n",
    "    for idx, row in gt_service.iterrows():\n",
    "        week_start = row['week']\n",
    "        for i in range(7):\n",
    "            date = week_start + timedelta(days=i)\n",
    "            gt_service_daily.append({'cdr_date': date, 'search_cnt': row['search_cnt']})\n",
    "    \n",
    "    gt_daily = pd.DataFrame(gt_service_daily)\n",
    "    df = df.merge(gt_daily, on='cdr_date', how='left')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_basic_time_features(df):\n",
    "    df = df.copy()\n",
    "    df['year'] = df['cdr_date'].dt.year\n",
    "    df['month'] = df['cdr_date'].dt.month\n",
    "    df['day_of_month'] = df['cdr_date'].dt.day\n",
    "    df['quarter'] = df['cdr_date'].dt.quarter\n",
    "    df['day_of_year'] = df['cdr_date'].dt.dayofyear\n",
    "    df['week_of_year'] = df['cdr_date'].dt.isocalendar().week\n",
    "    df['days_from_start'] = (df['cdr_date'] - df['cdr_date'].min()).dt.days\n",
    "    df['is_month_start'] = (df['day_of_month'] <= 5).astype(int)\n",
    "    df['is_month_end'] = (df['day_of_month'] >= 25).astype(int)\n",
    "    return df\n",
    "\n",
    "def create_lag_features(df, target_col='call_num', lags=[1, 2, 3, 5, 7, 14, 30]):\n",
    "    df = df.copy()\n",
    "    for lag in lags:\n",
    "        df[f'lag_{lag}'] = df[target_col].shift(lag)\n",
    "    return df\n",
    "\n",
    "def create_rolling_features(df, target_col='call_num', windows=[3, 7, 14, 30]):\n",
    "    df = df.copy()\n",
    "    for window in windows:\n",
    "        df[f'ma_{window}'] = df[target_col].shift(1).rolling(window=window, min_periods=1).mean()\n",
    "        df[f'ma_std_{window}'] = df[target_col].shift(1).rolling(window=window, min_periods=1).std()\n",
    "    return df\n",
    "\n",
    "def create_aggregated_features(df):\n",
    "    df = df.copy()\n",
    "    df['cm_7d'] = df['cm_flg'].shift(1).rolling(window=7, min_periods=1).sum()\n",
    "    df['gt_ma_7'] = df['search_cnt'].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "    df['acc_ma_7'] = df['acc_get_cnt'].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "    \n",
    "    df['dow_avg'] = np.nan\n",
    "    for dow in df['dow'].unique():\n",
    "        mask = df['dow'] == dow\n",
    "        df.loc[mask, 'dow_avg'] = df.loc[mask, 'call_num'].shift(1).expanding().mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_acc_get_features(df):\n",
    "    \"\"\"exp16ã®acc_getç‰¹å¾´é‡ã‚’ä½œæˆ\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Step 7: acc_getç‰¹å¾´é‡ã®è¿½åŠ ï¼ˆexp16ã¨åŒã˜ï¼‰\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    df = df.copy()\n",
    "    df['acc_get_lag7'] = df['acc_get_cnt'].shift(7)\n",
    "    df['acc_get_sum_14d'] = df['acc_get_cnt'].shift(1).rolling(window=14, min_periods=1).sum()\n",
    "    \n",
    "    print(\"\\nä½œæˆã—ãŸç‰¹å¾´é‡:\")\n",
    "    print(\"  1. acc_get_lag7: 7æ—¥å‰ã®acc_get_cnt\")\n",
    "    print(\"  2. acc_get_sum_14d: ç›´è¿‘14æ—¥é–“ã®acc_get_cntã®åˆè¨ˆ\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_regime_change_features(df):\n",
    "    \"\"\"exp15ã®ãƒ¬ã‚¸ãƒ¼ãƒ å¤‰åŒ–ç‰¹å¾´é‡ã‚’ä½œæˆ\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Step 8: ãƒ¬ã‚¸ãƒ¼ãƒ å¤‰åŒ–ç‰¹å¾´é‡ã®ä½œæˆï¼ˆexp15ã‹ã‚‰ç¶™æ‰¿ï¼‰\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    tax_implementation_date = pd.Timestamp('2019-10-01')\n",
    "    rush_deadline = pd.Timestamp('2019-09-30')\n",
    "    \n",
    "    df['days_to_2019_10_01'] = (tax_implementation_date - df['cdr_date']).dt.days\n",
    "    df['is_pre_2019_10_01'] = (df['cdr_date'] < tax_implementation_date).astype(int)\n",
    "    df['is_post_2019_10_01'] = (df['cdr_date'] >= tax_implementation_date).astype(int)\n",
    "    \n",
    "    df['days_to_2019_09_30'] = (rush_deadline - df['cdr_date']).dt.days\n",
    "    df['is_pre_2019_09_30'] = (df['cdr_date'] < rush_deadline).astype(int)\n",
    "    df['is_post_2019_09_30'] = (df['cdr_date'] >= rush_deadline).astype(int)\n",
    "    \n",
    "    rush_start = rush_deadline - pd.Timedelta(days=90)\n",
    "    df['is_rush_period'] = ((df['cdr_date'] >= rush_start) & \n",
    "                            (df['cdr_date'] <= rush_deadline)).astype(int)\n",
    "    \n",
    "    adaptation_end = tax_implementation_date + pd.Timedelta(days=30)\n",
    "    df['is_adaptation_period'] = ((df['cdr_date'] >= tax_implementation_date) & \n",
    "                                   (df['cdr_date'] <= adaptation_end)).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print('ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»ç‰¹å¾´é‡ä½œæˆé–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"*\" * 80)\n",
    "print(\"exp21: exp19ã®æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ + Holdout Validation\")\n",
    "print(\"*\" * 80)\n",
    "\n",
    "calender, cm_data, gt_service, acc_get, call_data = load_and_preprocess_data()\n",
    "df = merge_datasets(calender, cm_data, gt_service, acc_get, call_data)\n",
    "df = create_basic_time_features(df)\n",
    "df = create_lag_features(df)\n",
    "df = create_rolling_features(df)\n",
    "df = create_aggregated_features(df)\n",
    "df = create_acc_get_features(df)\n",
    "df = create_regime_change_features(df)\n",
    "\n",
    "# ç¿Œæ—¥ã®å…¥é›»æ•°ã‚’ç›®çš„å¤‰æ•°ã«ã™ã‚‹\n",
    "df['target_next_day'] = df['call_num'].shift(-1)\n",
    "df = df.dropna(subset=['target_next_day']).reset_index(drop=True)\n",
    "\n",
    "# å¹³æ—¥ã®ã¿\n",
    "df_model = df[df['dow'].isin([1, 2, 3, 4, 5])].copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nå¹³æ—¥ãƒ‡ãƒ¼ã‚¿æ•°: {len(df_model)}è¡Œ\")\n",
    "print(f\"æœŸé–“: {df_model['cdr_date'].min()} ~ {df_model['cdr_date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# ğŸ”¥ Holdout Validation ã®è¨­å®šï¼ˆRolling Windowã®ä»£ã‚ã‚Šï¼‰\n",
    "# ==================================================================================\n",
    "\n",
    "# exp16ã¨åŒã˜ç‰¹å¾´é‡ãƒªã‚¹ãƒˆï¼ˆ50å€‹ï¼‰\n",
    "feature_cols = [\n",
    "    # åŸºæœ¬æ™‚ç³»åˆ—ç‰¹å¾´é‡\n",
    "    'dow', 'day_of_month', 'month', 'quarter', 'year', \n",
    "    'days_from_start', 'day_of_year', 'week_of_year',\n",
    "    'is_month_start', 'is_month_end',\n",
    "    # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç‰¹å¾´é‡\n",
    "    'woy', 'wom', 'day_before_holiday_flag',\n",
    "    # å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿\n",
    "    'cm_flg', 'acc_get_cnt', 'search_cnt',\n",
    "    # é›†ç´„ç‰¹å¾´é‡\n",
    "    'cm_7d', 'gt_ma_7', 'acc_ma_7', 'dow_avg',\n",
    "    # ãƒ©ã‚°ç‰¹å¾´é‡\n",
    "    'lag_1', 'lag_2', 'lag_3', 'lag_5', 'lag_7', 'lag_14', 'lag_30',\n",
    "    # ç§»å‹•å¹³å‡ç‰¹å¾´é‡\n",
    "    'ma_3', 'ma_7', 'ma_14', 'ma_30',\n",
    "    'ma_std_3', 'ma_std_7', 'ma_std_14', 'ma_std_30',\n",
    "    # ãƒ¬ã‚¸ãƒ¼ãƒ å¤‰åŒ–ç‰¹å¾´é‡\n",
    "    'days_to_2019_10_01', 'is_pre_2019_10_01', 'is_post_2019_10_01',\n",
    "    'days_to_2019_09_30', 'is_pre_2019_09_30', 'is_post_2019_09_30',\n",
    "    'is_rush_period', 'is_adaptation_period',\n",
    "    # acc_getç‰¹å¾´é‡\n",
    "    'acc_get_lag7', 'acc_get_sum_14d'\n",
    "]\n",
    "\n",
    "print(f\"\\nä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡æ•°: {len(feature_cols)}\")\n",
    "\n",
    "# æ¬ æå€¤ã‚’é™¤å»\n",
    "df_clean = df_model.dropna(subset=feature_cols + ['target_next_day']).copy()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ”¥ Holdout Validation è¨­å®šï¼ˆRolling Windowã®ä»£ã‚ã‚Šï¼‰\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Holdoutåˆ†å‰²: æœ€æ–°2ãƒ¶æœˆï¼ˆç´„60æ—¥ï¼‰ã‚’Testã«\n",
    "# â€»exp20ã®Window 8ã¨åŒã˜TestæœŸé–“\n",
    "test_start_date = pd.Timestamp('2020-01-30')\n",
    "train_end_date = test_start_date - pd.Timedelta(days=1)\n",
    "\n",
    "train_df = df_clean[df_clean['cdr_date'] <= train_end_date].copy()\n",
    "test_df = df_clean[df_clean['cdr_date'] >= test_start_date].copy()\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df['target_next_day']\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df['target_next_day']\n",
    "\n",
    "print(f\"\\nTrain: {len(X_train)}ä»¶ ({train_df['cdr_date'].min().strftime('%Y-%m-%d')} ~ {train_df['cdr_date'].max().strftime('%Y-%m-%d')})\")\n",
    "print(f\"Test : {len(X_test)}ä»¶ ({test_df['cdr_date'].min().strftime('%Y-%m-%d')} ~ {test_df['cdr_date'].max().strftime('%Y-%m-%d')})\")\n",
    "print(f\"\\nâ€»TestæœŸé–“ã¯exp20ã®Window 8ã¨åŒã˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨è©•ä¾¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# è©•ä¾¡é–¢æ•°\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def calculate_wape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true)) * 100\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    return {\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'WAPE': calculate_wape(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "print('è©•ä¾¡é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã¨è©•ä¾¡ï¼ˆexp19ã®æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã¨è©•ä¾¡ï¼ˆexp19æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ + Holdout Validationï¼‰\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = []\n",
    "predictions = {}\n",
    "\n",
    "# 1. HistGradientBoostingï¼ˆexp19ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰\n",
    "print(\"\\n[1/5] HistGradientBoostingï¼ˆexp19æœ€é©åŒ–ï¼‰...\")\n",
    "hist_model = HistGradientBoostingRegressor(**OPTIMIZED_PARAMS_EXP19['HistGradientBoosting'], random_state=42)\n",
    "hist_model.fit(X_train, y_train)\n",
    "hist_pred = hist_model.predict(X_test)\n",
    "hist_metrics = evaluate_model(y_test, hist_pred)\n",
    "print(f\"  MAE: {hist_metrics['MAE']:.2f}, RMSE: {hist_metrics['RMSE']:.2f}, R2: {hist_metrics['R2']:.3f}\")\n",
    "predictions['HistGradientBoosting'] = hist_pred\n",
    "results.append({'model': 'HistGradientBoosting', **hist_metrics})\n",
    "\n",
    "# 2. ExtraTreesï¼ˆexp19ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰\n",
    "print(\"\\n[2/5] ExtraTreesï¼ˆexp19æœ€é©åŒ–ï¼‰...\")\n",
    "extra_model = ExtraTreesRegressor(**OPTIMIZED_PARAMS_EXP19['ExtraTrees'], random_state=42, n_jobs=-1)\n",
    "extra_model.fit(X_train, y_train)\n",
    "extra_pred = extra_model.predict(X_test)\n",
    "extra_metrics = evaluate_model(y_test, extra_pred)\n",
    "print(f\"  MAE: {extra_metrics['MAE']:.2f}, RMSE: {extra_metrics['RMSE']:.2f}, R2: {extra_metrics['R2']:.3f}\")\n",
    "predictions['ExtraTrees'] = extra_pred\n",
    "results.append({'model': 'ExtraTrees', **extra_metrics})\n",
    "\n",
    "# 3. CatBoostï¼ˆexp19ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰\n",
    "print(\"\\n[3/5] CatBoostï¼ˆexp19æœ€é©åŒ–ï¼‰...\")\n",
    "catboost_model = CatBoostRegressor(**OPTIMIZED_PARAMS_EXP19['CatBoost'], random_state=42, verbose=0)\n",
    "catboost_model.fit(X_train, y_train)\n",
    "catboost_pred = catboost_model.predict(X_test)\n",
    "catboost_metrics = evaluate_model(y_test, catboost_pred)\n",
    "print(f\"  MAE: {catboost_metrics['MAE']:.2f}, RMSE: {catboost_metrics['RMSE']:.2f}, R2: {catboost_metrics['R2']:.3f}\")\n",
    "predictions['CatBoost'] = catboost_pred\n",
    "results.append({'model': 'CatBoost', **catboost_metrics})\n",
    "\n",
    "# 4. Ridgeï¼ˆexp19ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰\n",
    "print(\"\\n[4/5] Ridgeï¼ˆexp19æœ€é©åŒ–ï¼‰...\")\n",
    "ridge_model = Ridge(**OPTIMIZED_PARAMS_EXP19['Ridge'], random_state=42)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "ridge_metrics = evaluate_model(y_test, ridge_pred)\n",
    "print(f\"  MAE: {ridge_metrics['MAE']:.2f}, RMSE: {ridge_metrics['RMSE']:.2f}, R2: {ridge_metrics['R2']:.3f}\")\n",
    "predictions['Ridge'] = ridge_pred\n",
    "results.append({'model': 'Ridge', **ridge_metrics})\n",
    "\n",
    "# 5. Weighted Ensemble Aï¼ˆTestã‚»ãƒƒãƒˆã§é‡ã¿æœ€é©åŒ–ï¼‰\n",
    "print(\"\\n[5/5] WeightedEnsemble_Aï¼ˆTestã‚»ãƒƒãƒˆã§é‡ã¿æœ€é©åŒ–ï¼‰...\")\n",
    "\n",
    "def optimize_weights(predictions_dict, y_true, model_names):\n",
    "    preds_matrix = np.column_stack([predictions_dict[name] for name in model_names])\n",
    "    \n",
    "    def objective(weights):\n",
    "        ensemble_pred = preds_matrix @ weights\n",
    "        return mean_absolute_error(y_true, ensemble_pred)\n",
    "    \n",
    "    constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}\n",
    "    bounds = [(0, 1) for _ in range(len(model_names))]\n",
    "    initial_weights = np.ones(len(model_names)) / len(model_names)\n",
    "    \n",
    "    result = minimize(objective, initial_weights, method='SLSQP',\n",
    "                     bounds=bounds, constraints=constraints)\n",
    "    return result.x\n",
    "\n",
    "pattern_a_models = ['Ridge', 'CatBoost', 'ExtraTrees', 'HistGradientBoosting']\n",
    "weights_a = optimize_weights(predictions, y_test, pattern_a_models)\n",
    "\n",
    "print(\"\\næœ€é©åŒ–ã•ã‚ŒãŸé‡ã¿:\")\n",
    "for name, weight in zip(pattern_a_models, weights_a):\n",
    "    print(f\"  {name}: {weight:.4f}\")\n",
    "\n",
    "weightA_pred = np.column_stack([predictions[name] for name in pattern_a_models]) @ weights_a\n",
    "weightA_metrics = evaluate_model(y_test, weightA_pred)\n",
    "print(f\"\\n  MAE: {weightA_metrics['MAE']:.2f}, RMSE: {weightA_metrics['RMSE']:.2f}, R2: {weightA_metrics['R2']:.3f}\")\n",
    "results.append({'model': 'WeightedEnsemble_A', **weightA_metrics})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ãƒ¢ãƒ‡ãƒ«è¨“ç·´ãƒ»è©•ä¾¡å®Œäº†\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# exp20ï¼ˆRolling Windowï¼‰ã¨ã®æ¯”è¼ƒåˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# çµæœã®é›†è¨ˆ\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('MAE')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"exp21 çµæœï¼ˆHoldout Validationï¼‰\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# CSVä¿å­˜\n",
    "output_dir = '../output/exp21'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "results_df.to_csv(f'{output_dir}/holdout_results.csv', index=False)\n",
    "print(f\"\\nçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_dir}/holdout_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# exp20ï¼ˆRolling Windowï¼‰ã¨ã®æ¯”è¼ƒ\n",
    "# ============================================================================\n",
    "\n",
    "exp20_results_path = '../output/exp20/rolling_window_results.csv'\n",
    "if os.path.exists(exp20_results_path):\n",
    "    exp20_results_df = pd.read_csv(exp20_results_path)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"exp20 (Rolling Window) vs exp21 (Holdout) æ¯”è¼ƒ\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # exp20ã®å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—\n",
    "    exp20_avg = exp20_results_df.groupby('model')['MAE'].mean()\n",
    "    \n",
    "    # exp20ã®Window 8ï¼ˆexp21ã¨åŒã˜TestæœŸé–“ï¼‰ã®ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º\n",
    "    exp20_window8 = exp20_results_df[exp20_results_df['window'] == 8].set_index('model')['MAE']\n",
    "    \n",
    "    # æ¯”è¼ƒè¡¨ã‚’ä½œæˆ\n",
    "    comparison_data = []\n",
    "    for model in results_df['model']:\n",
    "        exp21_mae = results_df[results_df['model'] == model]['MAE'].values[0]\n",
    "        exp20_avg_mae = exp20_avg.get(model, np.nan)\n",
    "        exp20_w8_mae = exp20_window8.get(model, np.nan)\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'model': model,\n",
    "            'exp20_avg (8 windows)': exp20_avg_mae,\n",
    "            'exp20_window8 (same period)': exp20_w8_mae,\n",
    "            'exp21_holdout': exp21_mae,\n",
    "            'diff_from_avg': exp20_avg_mae - exp21_mae,\n",
    "            'diff_from_w8': exp20_w8_mae - exp21_mae\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "    \n",
    "    # å¯è¦–åŒ–\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    \n",
    "    x = np.arange(len(comparison_df))\n",
    "    width = 0.25\n",
    "    \n",
    "    ax.bar(x - width, comparison_df['exp20_avg (8 windows)'], width, \n",
    "           label='exp20 (Rolling Window Avg)', color='steelblue', alpha=0.8)\n",
    "    ax.bar(x, comparison_df['exp20_window8 (same period)'], width, \n",
    "           label='exp20 (Window 8)', color='lightblue', alpha=0.8)\n",
    "    ax.bar(x + width, comparison_df['exp21_holdout'], width, \n",
    "           label='exp21 (Holdout)', color='coral', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Model', fontsize=12)\n",
    "    ax.set_ylabel('MAE', fontsize=12)\n",
    "    ax.set_title('exp20 (Rolling Window) vs exp21 (Holdout): MAE Comparison', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(comparison_df['model'], rotation=15, ha='right')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/exp20_vs_exp21_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nå¯è¦–åŒ–ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_dir}/exp20_vs_exp21_comparison.png\")\n",
    "    \n",
    "    # æ¯”è¼ƒè¡¨ã‚‚ä¿å­˜\n",
    "    comparison_df.to_csv(f'{output_dir}/exp20_vs_exp21_comparison.csv', index=False)\n",
    "    print(f\"æ¯”è¼ƒè¡¨ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_dir}/exp20_vs_exp21_comparison.csv\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nexp20ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "    print(\"exp21ã®çµæœã®ã¿ã‚’è¡¨ç¤ºã—ã¾ã—ãŸã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**exp21: exp19ã®æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’Holdout Validationã§è©•ä¾¡**\n",
    "\n",
    "### ç›®çš„:\n",
    "- exp20ã¨åŒã˜exp19ã®æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨\n",
    "- Rolling Windowã§ã¯ãªãã‚·ãƒ³ãƒ—ãƒ«ãªHoldout Validationã§è©•ä¾¡\n",
    "- æ¤œè¨¼æ–¹æ³•ã®é•ã„ã«ã‚ˆã‚‹æ€§èƒ½å·®ã‚’ç¢ºèª\n",
    "\n",
    "### Holdoutè¨­å®š:\n",
    "- Train: 2018-07-02 ~ 2020-01-29ï¼ˆç´„18ãƒ¶æœˆã€413ä»¶ï¼‰\n",
    "- Test: 2020-01-30 ~ 2020-03-30ï¼ˆç´„2ãƒ¶æœˆã€43ä»¶ï¼‰\n",
    "- â€»TestæœŸé–“ã¯exp20ã®Window 8ã¨åŒã˜\n",
    "\n",
    "### exp20ã¨ã®æ¯”è¼ƒ:\n",
    "- exp20: Rolling Window Validationï¼ˆ8ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®å¹³å‡ï¼‰\n",
    "- exp21: Holdout Validationï¼ˆ1å›ã®Train/Teståˆ†å‰²ï¼‰\n",
    "- åŒã˜TestæœŸé–“ï¼ˆWindow 8ï¼‰ã§ã®ç›´æ¥æ¯”è¼ƒã‚‚å¯èƒ½\n",
    "\n",
    "### æ¤œè¨¼çµæœ:\n",
    "- Rolling Window vs Holdoutã®æ€§èƒ½å·®ã‚’ç¢ºèª\n",
    "- ã‚·ãƒ³ãƒ—ãƒ«ãªæ¤œè¨¼æ–¹æ³•ã§ã®å®Ÿç”¨æ€§ã‚’è©•ä¾¡\n",
    "\n",
    "### å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:\n",
    "1. `holdout_results.csv` - Holdout Validationã®çµæœ\n",
    "2. `exp20_vs_exp21_comparison.csv` - Rolling Window vs Holdoutæ¯”è¼ƒè¡¨\n",
    "3. `exp20_vs_exp21_comparison.png` - å¯è¦–åŒ–"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
