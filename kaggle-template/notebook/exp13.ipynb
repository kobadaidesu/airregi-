{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp13: å³å¯†ãªãƒ¢ãƒ‡ãƒ«è©•ä¾¡ (Train/Validation/Test 3åˆ†å‰²)\n",
    "\n",
    "**ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³**: exp11ã®ç‰¹å¾´é‡ã¨æ¤œè¨¼æ–¹æ³•ã‚’ä½¿ç”¨\n",
    "\n",
    "**exp12ã‹ã‚‰ã®æ”¹å–„ç‚¹**:\n",
    "- ãƒ‡ãƒ¼ã‚¿ã‚’ **Train / Validation / Test ã®3åˆ†å‰²**ã«å¤‰æ›´\n",
    "- Validationã‚»ãƒƒãƒˆ: ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿æœ€é©åŒ–ã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã«ä½¿ç”¨\n",
    "- Testã‚»ãƒƒãƒˆ: æœ€çµ‚è©•ä¾¡ç”¨ã®å®Œå…¨ã«ç‹¬ç«‹ã—ãŸãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆã‚»ãƒƒãƒˆ\n",
    "\n",
    "**è©•ä¾¡å†…å®¹**:\n",
    "- å„ãƒ¢ãƒ‡ãƒ«(weightA, weightB, hist, extra, catboost)ã«ã¤ã„ã¦:\n",
    "  - è¨“ç·´ç›´å¾Œã«å€‹åˆ¥ã§MAE, RMSE, R2, WAPEã‚’è¡¨ç¤º\n",
    "  - Validationã‚»ãƒƒãƒˆã¨Testã‚»ãƒƒãƒˆã®ä¸¡æ–¹ã§è©•ä¾¡\n",
    "- æœ€å¾Œã«å…¨ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æŒ‡æ¨™ã‚’æ¯”è¼ƒã—ã‚„ã™ã„è¡¨å½¢å¼ã§ä¸€è¦§è¡¨ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Best Optuna Parameters (from exp05 optimization)\n",
    "# ============================================================================\n",
    "\n",
    "BEST_PARAMS = {\n",
    "    'Ridge': {'alpha': 70.4183028501599},\n",
    "    'RandomForest': {\n",
    "        'n_estimators': 261,\n",
    "        'max_depth': 21,\n",
    "        'min_samples_split': 13,\n",
    "        'min_samples_leaf': 1,\n",
    "        'max_features': None\n",
    "    },\n",
    "    'ExtraTrees': {\n",
    "        'n_estimators': 229,\n",
    "        'max_depth': 29,\n",
    "        'min_samples_split': 16,\n",
    "        'min_samples_leaf': 1,\n",
    "        'max_features': None\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'n_estimators': 477,\n",
    "        'learning_rate': 0.26835579181051533,\n",
    "        'max_depth': 2,\n",
    "        'min_samples_split': 5,\n",
    "        'min_samples_leaf': 1,\n",
    "        'subsample': 0.9721678101451118\n",
    "    },\n",
    "    'HistGradientBoosting': {\n",
    "        'max_iter': 238,\n",
    "        'learning_rate': 0.015251103470998385,\n",
    "        'max_depth': 20,\n",
    "        'min_samples_leaf': 33,\n",
    "        'l2_regularization': 9.037967498117355\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': 4666,\n",
    "        'learning_rate': 0.18057598957444881,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.7726782988943871,\n",
    "        'colsample_bytree': 0.6039221062901661,\n",
    "        'reg_lambda': 0.9814360532884759,\n",
    "        'reg_alpha': 1.6016986762895833\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': 127,\n",
    "        'learning_rate': 0.1601531217136121,\n",
    "        'num_leaves': 112,\n",
    "        'max_depth': 12,\n",
    "        'subsample': 0.9085081386743783,\n",
    "        'colsample_bytree': 0.6296178606936361,\n",
    "        'reg_lambda': 0.5211124595788266,\n",
    "        'reg_alpha': 0.5793452976256486\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'iterations': 2295,\n",
    "        'learning_rate': 0.10429705988762059,\n",
    "        'depth': 5,\n",
    "        'l2_leaf_reg': 6.359326196557493,\n",
    "        'subsample': 0.8738193035765242\n",
    "    }\n",
    "}\n",
    "\n",
    "print('Best parameters loaded from exp05 optimization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Step 1: ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†\n",
    "# ==================================================================================\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"\n",
    "    å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ã€æ—¥ä»˜å‹ã«å¤‰æ›\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Step 1: ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "    calender = pd.read_csv('../input/calender_data.csv')\n",
    "    cm_data = pd.read_csv('../input/cm_data.csv')\n",
    "    gt_service = pd.read_csv('../input/gt_service_name.csv')\n",
    "    acc_get = pd.read_csv('../input/regi_acc_get_data_transform.csv')\n",
    "    call_data = pd.read_csv('../input/regi_call_data_transform.csv')\n",
    "    \n",
    "    # æ—¥ä»˜ã‚«ãƒ©ãƒ ã‚’datetimeå‹ã«å¤‰æ›\n",
    "    calender['cdr_date'] = pd.to_datetime(calender['cdr_date'])\n",
    "    cm_data['cdr_date'] = pd.to_datetime(cm_data['cdr_date'])\n",
    "    acc_get['cdr_date'] = pd.to_datetime(acc_get['cdr_date'])\n",
    "    call_data['cdr_date'] = pd.to_datetime(call_data['cdr_date'])\n",
    "    gt_service['week'] = pd.to_datetime(gt_service['week'])\n",
    "    \n",
    "    print(f\"\\nã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿: {calender.shape}\")\n",
    "    print(f\"CMãƒ‡ãƒ¼ã‚¿: {cm_data.shape}\")\n",
    "    print(f\"Google Trendsãƒ‡ãƒ¼ã‚¿: {gt_service.shape}\")\n",
    "    print(f\"ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå–å¾—ãƒ‡ãƒ¼ã‚¿: {acc_get.shape}\")\n",
    "    print(f\"å…¥é›»ãƒ‡ãƒ¼ã‚¿ï¼ˆç›®çš„å¤‰æ•°ï¼‰: {call_data.shape}\")\n",
    "    \n",
    "    return calender, cm_data, gt_service, acc_get, call_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Step 2: ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ\n",
    "# ==================================================================================\n",
    "\n",
    "def merge_datasets(calender, cm_data, gt_service, acc_get, call_data):\n",
    "    \"\"\"\n",
    "    å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’çµ±åˆ\n",
    "    Google Trendsã¯é€±æ¬¡ãƒ‡ãƒ¼ã‚¿ãªã®ã§æ—¥æ¬¡ã«å±•é–‹\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Step 2: ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼ˆå…¥é›»æ•°ï¼‰ã‚’åŸºæº–ã«ãƒãƒ¼ã‚¸\n",
    "    df = call_data.copy()\n",
    "    print(f\"\\nãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿: {df.shape}\")\n",
    "    \n",
    "    # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼æƒ…å ±ã‚’ãƒãƒ¼ã‚¸\n",
    "    df = df.merge(calender, on='cdr_date', how='left')\n",
    "    print(f\"ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼æƒ…å ±ãƒãƒ¼ã‚¸å¾Œ: {df.shape}\")\n",
    "    \n",
    "    # CMæƒ…å ±ã‚’ãƒãƒ¼ã‚¸\n",
    "    df = df.merge(cm_data, on='cdr_date', how='left')\n",
    "    print(f\"CMæƒ…å ±ãƒãƒ¼ã‚¸å¾Œ: {df.shape}\")\n",
    "    \n",
    "    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå–å¾—æ•°ã‚’ãƒãƒ¼ã‚¸\n",
    "    df = df.merge(acc_get, on='cdr_date', how='left')\n",
    "    print(f\"ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå–å¾—æ•°ãƒãƒ¼ã‚¸å¾Œ: {df.shape}\")\n",
    "    \n",
    "    # Google Trendsãƒ‡ãƒ¼ã‚¿ã¯é€±æ¬¡ãªã®ã§æ—¥æ¬¡ã«å±•é–‹\n",
    "    print(\"\\nGoogle Trendsãƒ‡ãƒ¼ã‚¿ã‚’é€±æ¬¡â†’æ—¥æ¬¡ã«å±•é–‹...\")\n",
    "    gt_service_daily = []\n",
    "    for idx, row in gt_service.iterrows():\n",
    "        week_start = row['week']\n",
    "        for i in range(7):\n",
    "            date = week_start + timedelta(days=i)\n",
    "            gt_service_daily.append({\n",
    "                'cdr_date': date, \n",
    "                'search_cnt': row['search_cnt']\n",
    "            })\n",
    "    \n",
    "    gt_daily = pd.DataFrame(gt_service_daily)\n",
    "    df = df.merge(gt_daily, on='cdr_date', how='left')\n",
    "    print(f\"Google Trendsãƒãƒ¼ã‚¸å¾Œ: {df.shape}\")\n",
    "    \n",
    "    # æ¬ æå€¤ã®ç¢ºèª\n",
    "    print(\"\\næ¬ æå€¤ã®æ•°:\")\n",
    "    print(df.isnull().sum().sort_values(ascending=False).head(10))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Step 3: åŸºæœ¬çš„ãªæ™‚ç³»åˆ—ç‰¹å¾´é‡ã®ä½œæˆ\n",
    "# ==================================================================================\n",
    "\n",
    "def create_basic_time_features(df):\n",
    "    \"\"\"\n",
    "    æ—¥ä»˜ã‹ã‚‰æ´¾ç”Ÿã™ã‚‹åŸºæœ¬çš„ãªæ™‚ç³»åˆ—ç‰¹å¾´é‡ã‚’ä½œæˆ\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Step 3: åŸºæœ¬çš„ãªæ™‚ç³»åˆ—ç‰¹å¾´é‡ã®ä½œæˆ\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # å¹´æœˆæ—¥ã®ç‰¹å¾´é‡\n",
    "    df['year'] = df['cdr_date'].dt.year\n",
    "    df['month'] = df['cdr_date'].dt.month\n",
    "    df['day_of_month'] = df['cdr_date'].dt.day\n",
    "    df['quarter'] = df['cdr_date'].dt.quarter\n",
    "    df['day_of_year'] = df['cdr_date'].dt.dayofyear\n",
    "    \n",
    "    # é€±ã®æƒ…å ±\n",
    "    df['week_of_year'] = df['cdr_date'].dt.isocalendar().week\n",
    "    \n",
    "    # çµŒéæ—¥æ•°\n",
    "    df['days_from_start'] = (df['cdr_date'] - df['cdr_date'].min()).dt.days\n",
    "    \n",
    "    # æœˆåˆãƒ»æœˆæœ«ãƒ•ãƒ©ã‚°\n",
    "    df['is_month_start'] = (df['day_of_month'] <= 5).astype(int)\n",
    "    df['is_month_end'] = (df['day_of_month'] >= 25).astype(int)\n",
    "    \n",
    "    print(\"\\nä½œæˆã—ãŸåŸºæœ¬ç‰¹å¾´é‡:\")\n",
    "    time_features = ['year', 'month', 'day_of_month', 'quarter', 'day_of_year', \n",
    "                     'week_of_year', 'days_from_start', 'is_month_start', 'is_month_end']\n",
    "    print(time_features)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Step 4: ãƒ©ã‚°ç‰¹å¾´é‡ã®ä½œæˆ\n",
    "# ==================================================================================\n",
    "\n",
    "def create_lag_features(df, target_col='call_num', lags=[1, 2, 3, 5, 7, 14, 30]):\n",
    "    \"\"\"\n",
    "    ãƒ©ã‚°ç‰¹å¾´é‡ï¼ˆéå»ã®ãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’ä½œæˆ\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Step 4: ãƒ©ã‚°ç‰¹å¾´é‡ã®ä½œæˆï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢ï¼‰\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    print(f\"\\nç›®çš„å¤‰æ•°: {target_col}\")\n",
    "    print(f\"ä½œæˆã™ã‚‹ãƒ©ã‚°: {lags}\")\n",
    "    \n",
    "    for lag in lags:\n",
    "        col_name = f'lag_{lag}'\n",
    "        df[col_name] = df[target_col].shift(lag)\n",
    "        print(f\"  ä½œæˆ: {col_name} (shift={lag})\")\n",
    "    \n",
    "    print(f\"\\næ³¨æ„: æœ€åˆã®{max(lags)}æ—¥é–“ã¯ãƒ©ã‚°ç‰¹å¾´é‡ãŒNaNã«ãªã‚Šã¾ã™\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Step 5: ç§»å‹•å¹³å‡ç‰¹å¾´é‡ã®ä½œæˆ\n",
    "# ==================================================================================\n",
    "\n",
    "def create_rolling_features(df, target_col='call_num', windows=[3, 7, 14, 30]):\n",
    "    \"\"\"\n",
    "    ç§»å‹•å¹³å‡ãƒ»ç§»å‹•æ¨™æº–åå·®ã‚’ä½œæˆ\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Step 5: ç§»å‹•å¹³å‡ç‰¹å¾´é‡ã®ä½œæˆï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢ï¼‰\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    print(f\"\\nç›®çš„å¤‰æ•°: {target_col}\")\n",
    "    print(f\"ç§»å‹•å¹³å‡ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦: {windows}\")\n",
    "    \n",
    "    for window in windows:\n",
    "        # ç§»å‹•å¹³å‡\n",
    "        ma_col = f'ma_{window}'\n",
    "        df[ma_col] = df[target_col].shift(1).rolling(window=window, min_periods=1).mean()\n",
    "        print(f\"  ä½œæˆ: {ma_col} (éå»{window}æ—¥é–“ã®å¹³å‡)\")\n",
    "        \n",
    "        # ç§»å‹•æ¨™æº–åå·®\n",
    "        std_col = f'ma_std_{window}'\n",
    "        df[std_col] = df[target_col].shift(1).rolling(window=window, min_periods=1).std()\n",
    "        print(f\"  ä½œæˆ: {std_col} (éå»{window}æ—¥é–“ã®æ¨™æº–åå·®)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Step 6: ãã®ä»–ã®é›†ç´„ç‰¹å¾´é‡\n",
    "# ==================================================================================\n",
    "\n",
    "def create_aggregated_features(df):\n",
    "    \"\"\"\n",
    "    ãã®ä»–ã®æœ‰ç”¨ãªé›†ç´„ç‰¹å¾´é‡ã‚’ä½œæˆ\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Step 6: ãã®ä»–ã®é›†ç´„ç‰¹å¾´é‡\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # CMåŠ¹æœã®ç´¯ç©\n",
    "    df['cm_7d'] = df['cm_flg'].shift(1).rolling(window=7, min_periods=1).sum()\n",
    "    print(\"  ä½œæˆ: cm_7d (éå»7æ—¥é–“ã®CMå®Ÿæ–½å›æ•°)\")\n",
    "    \n",
    "    # Google Trendsã®ç§»å‹•å¹³å‡\n",
    "    df['gt_ma_7'] = df['search_cnt'].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "    print(\"  ä½œæˆ: gt_ma_7 (éå»7æ—¥é–“ã®Google Trendså¹³å‡)\")\n",
    "    \n",
    "    # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå–å¾—æ•°ã®ç§»å‹•å¹³å‡\n",
    "    df['acc_ma_7'] = df['acc_get_cnt'].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "    print(\"  ä½œæˆ: acc_ma_7 (éå»7æ—¥é–“ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå–å¾—å¹³å‡)\")\n",
    "    \n",
    "    # æ›œæ—¥ã”ã¨ã®éå»å¹³å‡\n",
    "    print(\"\\n  ä½œæˆä¸­: dow_avg (åŒã˜æ›œæ—¥ã®éå»å¹³å‡)...\")\n",
    "    df['dow_avg'] = np.nan\n",
    "    for dow in df['dow'].unique():\n",
    "        mask = df['dow'] == dow\n",
    "        df.loc[mask, 'dow_avg'] = df.loc[mask, 'call_num'].shift(1).expanding().mean()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Step 7: ç‰¹å¾´é‡ã®é¸æŠã¨ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆTrain/Validation/Test 3åˆ†å‰²ï¼‰\n",
    "# ==================================================================================\n",
    "\n",
    "def select_features_and_split(df, val_months=2, test_months=2):\n",
    "    \"\"\"\n",
    "    ç‰¹å¾´é‡ã‚’é¸æŠã—ã€Train / Validation / Test ã®3åˆ†å‰²ã‚’å®Ÿæ–½\n",
    "    \n",
    "    Args:\n",
    "        df: ç‰¹å¾´é‡ãŒä½œæˆã•ã‚ŒãŸDataFrame\n",
    "        val_months: Validationã‚»ãƒƒãƒˆã®æœŸé–“ï¼ˆæœˆæ•°ï¼‰\n",
    "        test_months: Testã‚»ãƒƒãƒˆã®æœŸé–“ï¼ˆæœˆæ•°ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, train_meta, val_meta, test_meta, feature_cols\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Step 7: ç‰¹å¾´é‡é¸æŠã¨ãƒ‡ãƒ¼ã‚¿åˆ†å‰² (Train/Validation/Test)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ç¿Œæ—¥ã®å…¥é›»æ•°ã‚’ç›®çš„å¤‰æ•°ã«ã™ã‚‹\n",
    "    df = df.copy()\n",
    "    df['target_next_day'] = df['call_num'].shift(-1)\n",
    "    \n",
    "    # æœ€å¾Œã®è¡Œã¯targetãŒNaNã«ãªã‚‹ã®ã§å‰Šé™¤\n",
    "    df = df.dropna(subset=['target_next_day']).reset_index(drop=True)\n",
    "    \n",
    "    # å¹³æ—¥ã®ã¿ã‚’ä½¿ç”¨\n",
    "    df_model = df[df['dow'].isin([1, 2, 3, 4, 5])].copy().reset_index(drop=True)\n",
    "    print(f\"\\nå¹³æ—¥ã®ã¿ã«çµã‚Šè¾¼ã¿: {len(df)} â†’ {len(df_model)}è¡Œ\")\n",
    "    \n",
    "    # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ\n",
    "    feature_cols = [\n",
    "        # åŸºæœ¬çš„ãªæ™‚ç³»åˆ—ç‰¹å¾´é‡\n",
    "        'dow', 'day_of_month', 'month', 'quarter', 'year', \n",
    "        'days_from_start', 'day_of_year', 'week_of_year',\n",
    "        'is_month_start', 'is_month_end',\n",
    "        \n",
    "        # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç‰¹å¾´é‡\n",
    "        'woy', 'wom', 'day_before_holiday_flag',\n",
    "        \n",
    "        # å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿\n",
    "        'cm_flg', 'acc_get_cnt', 'search_cnt',\n",
    "        \n",
    "        # é›†ç´„ç‰¹å¾´é‡\n",
    "        'cm_7d', 'gt_ma_7', 'acc_ma_7', 'dow_avg',\n",
    "        \n",
    "        # ãƒ©ã‚°ç‰¹å¾´é‡\n",
    "        'lag_1', 'lag_2', 'lag_3', 'lag_5', 'lag_7', 'lag_14', 'lag_30',\n",
    "        \n",
    "        # ç§»å‹•å¹³å‡ç‰¹å¾´é‡\n",
    "        'ma_3', 'ma_7', 'ma_14', 'ma_30',\n",
    "        'ma_std_3', 'ma_std_7', 'ma_std_14', 'ma_std_30'\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡æ•°: {len(feature_cols)}\")\n",
    "    \n",
    "    # ğŸ”¥ æ™‚ç³»åˆ—3åˆ†å‰²: Train / Validation / Test\n",
    "    max_date = df_model['cdr_date'].max()\n",
    "    \n",
    "    # Testã‚»ãƒƒãƒˆã®é–‹å§‹æ—¥ï¼ˆæœ€å¾Œã®test_monthsæœˆï¼‰\n",
    "    test_start = max_date - pd.Timedelta(days=30*test_months)\n",
    "    \n",
    "    # Validationã‚»ãƒƒãƒˆã®é–‹å§‹æ—¥ï¼ˆTestã®å‰ã®val_monthsæœˆï¼‰\n",
    "    val_start = test_start - pd.Timedelta(days=30*val_months)\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²\n",
    "    train_df = df_model[df_model['cdr_date'] < val_start].copy()\n",
    "    val_df = df_model[(df_model['cdr_date'] >= val_start) & (df_model['cdr_date'] < test_start)].copy()\n",
    "    test_df = df_model[df_model['cdr_date'] >= test_start].copy()\n",
    "    \n",
    "    print(f\"\\næ™‚ç³»åˆ—3åˆ†å‰²:\")\n",
    "    print(f\"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿æœŸé–“      : {train_df['cdr_date'].min()} ~ {train_df['cdr_date'].max()} ({len(train_df)}è¡Œ)\")\n",
    "    print(f\"  Validationãƒ‡ãƒ¼ã‚¿æœŸé–“: {val_df['cdr_date'].min()} ~ {val_df['cdr_date'].max()} ({len(val_df)}è¡Œ)\")\n",
    "    print(f\"  Testãƒ‡ãƒ¼ã‚¿æœŸé–“      : {test_df['cdr_date'].min()} ~ {test_df['cdr_date'].max()} ({len(test_df)}è¡Œ)\")\n",
    "    \n",
    "    # æ¬ æå€¤ãŒã‚ã‚‹è¡Œã‚’å‰Šé™¤\n",
    "    train_clean = train_df.dropna(subset=feature_cols + ['target_next_day'])\n",
    "    val_clean = val_df.dropna(subset=feature_cols + ['target_next_day'])\n",
    "    test_clean = test_df.dropna(subset=feature_cols + ['target_next_day'])\n",
    "    \n",
    "    print(f\"\\næ¬ æå€¤é™¤å»å¾Œ:\")\n",
    "    print(f\"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°      : {len(train_clean)}è¡Œ\")\n",
    "    print(f\"  Validationãƒ‡ãƒ¼ã‚¿æ•°: {len(val_clean)}è¡Œ\")\n",
    "    print(f\"  Testãƒ‡ãƒ¼ã‚¿æ•°      : {len(test_clean)}è¡Œ\")\n",
    "    \n",
    "    # Xï¼ˆç‰¹å¾´é‡ï¼‰ã¨yï¼ˆç›®çš„å¤‰æ•°ï¼‰ã«åˆ†å‰²\n",
    "    X_train = train_clean[feature_cols]\n",
    "    y_train = train_clean['target_next_day']\n",
    "    X_val = val_clean[feature_cols]\n",
    "    y_val = val_clean['target_next_day']\n",
    "    X_test = test_clean[feature_cols]\n",
    "    y_test = test_clean['target_next_day']\n",
    "    \n",
    "    # ãƒ¡ã‚¿æƒ…å ±ã‚‚ä¿å­˜\n",
    "    train_meta = train_clean[['cdr_date', 'call_num', 'target_next_day']]\n",
    "    val_meta = val_clean[['cdr_date', 'call_num', 'target_next_day']]\n",
    "    test_meta = test_clean[['cdr_date', 'call_num', 'target_next_day']]\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, train_meta, val_meta, test_meta, feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°\n",
    "# ==================================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    å…¨ã¦ã®å‡¦ç†ã‚’å®Ÿè¡Œ\n",
    "    \"\"\"\n",
    "    print(\"\\n\")\n",
    "    print(\"*\" * 80)\n",
    "    print(\"exp13: å³å¯†ãªãƒ¢ãƒ‡ãƒ«è©•ä¾¡ (Train/Validation/Test 3åˆ†å‰²)\")\n",
    "    print(\"*\" * 80)\n",
    "    \n",
    "    # Step 1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "    calender, cm_data, gt_service, acc_get, call_data = load_and_preprocess_data()\n",
    "    \n",
    "    # Step 2: ãƒ‡ãƒ¼ã‚¿çµ±åˆ\n",
    "    df = merge_datasets(calender, cm_data, gt_service, acc_get, call_data)\n",
    "    \n",
    "    # Step 3: åŸºæœ¬æ™‚ç³»åˆ—ç‰¹å¾´é‡\n",
    "    df = create_basic_time_features(df)\n",
    "    \n",
    "    # Step 4: ãƒ©ã‚°ç‰¹å¾´é‡\n",
    "    df = create_lag_features(df, target_col='call_num', lags=[1, 2, 3, 5, 7, 14, 30])\n",
    "    \n",
    "    # Step 5: ç§»å‹•å¹³å‡ç‰¹å¾´é‡\n",
    "    df = create_rolling_features(df, target_col='call_num', windows=[3, 7, 14, 30])\n",
    "    \n",
    "    # Step 6: ãã®ä»–é›†ç´„ç‰¹å¾´é‡\n",
    "    df = create_aggregated_features(df)\n",
    "    \n",
    "    # Step 7: ç‰¹å¾´é‡é¸æŠã¨ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆ3åˆ†å‰²ç‰ˆï¼‰\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test, train_meta, val_meta, test_meta, feature_cols = \\\n",
    "        select_features_and_split(df, val_months=2, test_months=2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Œäº†ï¼\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nè¨“ç·´ãƒ‡ãƒ¼ã‚¿      : {X_train.shape}\")\n",
    "    print(f\"Validationãƒ‡ãƒ¼ã‚¿: {X_val.shape}\")\n",
    "    print(f\"Testãƒ‡ãƒ¼ã‚¿      : {X_test.shape}\")\n",
    "    print(f\"ç‰¹å¾´é‡æ•°        : {len(feature_cols)}\")\n",
    "    \n",
    "    return df, X_train, X_val, X_test, y_train, y_val, y_test, feature_cols\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, X_train, X_val, X_test, y_train, y_val, y_test, feature_cols = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨è©•ä¾¡ã‚»ã‚¯ã‚·ãƒ§ãƒ³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Enhanced Evaluation Functions\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_wape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    WAPE (Weighted Absolute Percentage Error) ã‚’è¨ˆç®—\n",
    "    WAPE = sum(|y_true - y_pred|) / sum(|y_true|) * 100\n",
    "    \"\"\"\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true)) * 100\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name, data_type='Validation'):\n",
    "    \"\"\"\n",
    "    ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ã—ã¦è¡¨ç¤º\n",
    "    \n",
    "    Args:\n",
    "        y_true: çœŸã®å€¤\n",
    "        y_pred: äºˆæ¸¬å€¤\n",
    "        model_name: ãƒ¢ãƒ‡ãƒ«å\n",
    "        data_type: ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ï¼ˆ'Validation' or 'Test'ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "        dict: è©•ä¾¡æŒ‡æ¨™ã®è¾æ›¸\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    wape = calculate_wape(y_true, y_pred)\n",
    "    \n",
    "    print(f'\\n[{model_name}] {data_type} Metrics:')\n",
    "    print(f'  MAE  (Mean Absolute Error)       : {mae:8.4f}')\n",
    "    print(f'  RMSE (Root Mean Squared Error)   : {rmse:8.4f}')\n",
    "    print(f'  R2   (R-squared Score)           : {r2:8.4f}')\n",
    "    print(f'  WAPE (Weighted Absolute % Error) : {wape:8.4f}%')\n",
    "    \n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'data_type': data_type,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'WAPE': wape\n",
    "    }\n",
    "\n",
    "print('Evaluation functions loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Training with Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Model Training with Enhanced Evaluation (Train/Validation/Test)\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# è©•ä¾¡çµæœã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ\n",
    "all_evaluation_results = []\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('Training Models with Detailed Evaluation (Train/Val/Test)')\n",
    "print('='*80)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. HistGradientBoosting (hist)\n",
    "# ============================================================================\n",
    "print('\\n' + '='*80)\n",
    "print('[1/5] HistGradientBoosting')\n",
    "print('='*80)\n",
    "\n",
    "hist_model = HistGradientBoostingRegressor(**BEST_PARAMS['HistGradientBoosting'], random_state=42)\n",
    "hist_model.fit(X_train, y_train)\n",
    "\n",
    "# ğŸ”¥ Validationè©•ä¾¡ï¼ˆé‡ã¿æœ€é©åŒ–ã«ä½¿ã†ï¼‰\n",
    "hist_val_pred = hist_model.predict(X_val)\n",
    "hist_val_metrics = evaluate_model(y_val, hist_val_pred, 'HistGradientBoosting', 'Validation')\n",
    "all_evaluation_results.append(hist_val_metrics)\n",
    "\n",
    "# ğŸ”¥ Testè©•ä¾¡ï¼ˆæœ€çµ‚è©•ä¾¡ç”¨ã®ç‹¬ç«‹ãƒ‡ãƒ¼ã‚¿ï¼‰\n",
    "hist_test_pred = hist_model.predict(X_test)\n",
    "hist_test_metrics = evaluate_model(y_test, hist_test_pred, 'HistGradientBoosting', 'Test')\n",
    "all_evaluation_results.append(hist_test_metrics)\n",
    "\n",
    "# ============================================================================\n",
    "# 2. ExtraTrees (extra)\n",
    "# ============================================================================\n",
    "print('\\n' + '='*80)\n",
    "print('[2/5] ExtraTrees')\n",
    "print('='*80)\n",
    "\n",
    "extra_model = ExtraTreesRegressor(**BEST_PARAMS['ExtraTrees'], random_state=42, n_jobs=-1)\n",
    "extra_model.fit(X_train, y_train)\n",
    "\n",
    "# Validationè©•ä¾¡\n",
    "extra_val_pred = extra_model.predict(X_val)\n",
    "extra_val_metrics = evaluate_model(y_val, extra_val_pred, 'ExtraTrees', 'Validation')\n",
    "all_evaluation_results.append(extra_val_metrics)\n",
    "\n",
    "# Testè©•ä¾¡\n",
    "extra_test_pred = extra_model.predict(X_test)\n",
    "extra_test_metrics = evaluate_model(y_test, extra_test_pred, 'ExtraTrees', 'Test')\n",
    "all_evaluation_results.append(extra_test_metrics)\n",
    "\n",
    "# ============================================================================\n",
    "# 3. CatBoost (catboost)\n",
    "# ============================================================================\n",
    "print('\\n' + '='*80)\n",
    "print('[3/5] CatBoost')\n",
    "print('='*80)\n",
    "\n",
    "catboost_model = CatBoostRegressor(**BEST_PARAMS['CatBoost'], random_state=42, verbose=0)\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Validationè©•ä¾¡\n",
    "catboost_val_pred = catboost_model.predict(X_val)\n",
    "catboost_val_metrics = evaluate_model(y_val, catboost_val_pred, 'CatBoost', 'Validation')\n",
    "all_evaluation_results.append(catboost_val_metrics)\n",
    "\n",
    "# Testè©•ä¾¡\n",
    "catboost_test_pred = catboost_model.predict(X_test)\n",
    "catboost_test_metrics = evaluate_model(y_test, catboost_test_pred, 'CatBoost', 'Test')\n",
    "all_evaluation_results.append(catboost_test_metrics)\n",
    "\n",
    "# ============================================================================\n",
    "# 4. Weighted Ensemble A (weightA): Ridge + CatBoost + ExtraTrees + HistGB\n",
    "# ============================================================================\n",
    "print('\\n' + '='*80)\n",
    "print('[4/5] Weighted Ensemble A: Ridge + CatBoost + ExtraTrees + HistGB')\n",
    "print('='*80)\n",
    "\n",
    "# Ridgeãƒ¢ãƒ‡ãƒ«ã‚‚è¨“ç·´\n",
    "ridge_model = Ridge(**BEST_PARAMS['Ridge'], random_state=42)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_val_pred = ridge_model.predict(X_val)\n",
    "ridge_test_pred = ridge_model.predict(X_test)\n",
    "\n",
    "# å„ãƒ¢ãƒ‡ãƒ«ã®Validationäºˆæ¸¬å€¤ã‚’è¾æ›¸ã«ã¾ã¨ã‚ã‚‹\n",
    "base_predictions_val = {\n",
    "    'Ridge': ridge_val_pred,\n",
    "    'CatBoost': catboost_val_pred,\n",
    "    'ExtraTrees': extra_val_pred,\n",
    "    'HistGradientBoosting': hist_val_pred\n",
    "}\n",
    "\n",
    "# å„ãƒ¢ãƒ‡ãƒ«ã®Testäºˆæ¸¬å€¤ã‚’è¾æ›¸ã«ã¾ã¨ã‚ã‚‹\n",
    "base_predictions_test = {\n",
    "    'Ridge': ridge_test_pred,\n",
    "    'CatBoost': catboost_test_pred,\n",
    "    'ExtraTrees': extra_test_pred,\n",
    "    'HistGradientBoosting': hist_test_pred\n",
    "}\n",
    "\n",
    "# é‡ã¿æœ€é©åŒ–é–¢æ•°ï¼ˆValidationã‚»ãƒƒãƒˆã§æœ€é©åŒ–ï¼‰\n",
    "def optimize_weights(predictions_dict, y_true, model_names):\n",
    "    preds_matrix = np.column_stack([predictions_dict[name] for name in model_names])\n",
    "    \n",
    "    def objective(weights):\n",
    "        ensemble_pred = preds_matrix @ weights\n",
    "        return mean_absolute_error(y_true, ensemble_pred)\n",
    "    \n",
    "    constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}\n",
    "    bounds = [(0, 1) for _ in range(len(model_names))]\n",
    "    initial_weights = np.ones(len(model_names)) / len(model_names)\n",
    "    \n",
    "    result = minimize(objective, initial_weights, method='SLSQP',\n",
    "                     bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    return result.x, result.fun\n",
    "\n",
    "# Pattern A: Ridge + CatBoost + ExtraTrees + HistGB\n",
    "pattern_a_models = ['Ridge', 'CatBoost', 'ExtraTrees', 'HistGradientBoosting']\n",
    "# ğŸ”¥ Validationã‚»ãƒƒãƒˆã§é‡ã¿ã‚’æœ€é©åŒ–\n",
    "weights_a, _ = optimize_weights(base_predictions_val, y_val, pattern_a_models)\n",
    "\n",
    "print('\\nOptimized Weights (on Validation set):')\n",
    "for name, w in zip(pattern_a_models, weights_a):\n",
    "    print(f'  {name:25s}: {w:.4f}')\n",
    "\n",
    "# Validationè©•ä¾¡\n",
    "weightA_val_pred = np.column_stack([base_predictions_val[name] for name in pattern_a_models]) @ weights_a\n",
    "weightA_val_metrics = evaluate_model(y_val, weightA_val_pred, 'WeightedEnsemble_A', 'Validation')\n",
    "all_evaluation_results.append(weightA_val_metrics)\n",
    "\n",
    "# ğŸ”¥ åŒã˜é‡ã¿ã‚’Testã‚»ãƒƒãƒˆã«é©ç”¨\n",
    "weightA_test_pred = np.column_stack([base_predictions_test[name] for name in pattern_a_models]) @ weights_a\n",
    "weightA_test_metrics = evaluate_model(y_test, weightA_test_pred, 'WeightedEnsemble_A', 'Test')\n",
    "all_evaluation_results.append(weightA_test_metrics)\n",
    "\n",
    "# ============================================================================\n",
    "# 5. Weighted Ensemble B (weightB): LightGBM + CatBoost + HistGB\n",
    "# ============================================================================\n",
    "print('\\n' + '='*80)\n",
    "print('[5/5] Weighted Ensemble B: LightGBM + CatBoost + HistGB')\n",
    "print('='*80)\n",
    "\n",
    "# LightGBMãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´\n",
    "from lightgbm import LGBMRegressor\n",
    "lgbm_model = LGBMRegressor(**BEST_PARAMS['LightGBM'], random_state=42, n_jobs=-1, verbose=-1)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "lgbm_val_pred = lgbm_model.predict(X_val)\n",
    "lgbm_test_pred = lgbm_model.predict(X_test)\n",
    "\n",
    "# Pattern Bç”¨ã®äºˆæ¸¬å€¤\n",
    "base_predictions_val_b = {\n",
    "    'LightGBM': lgbm_val_pred,\n",
    "    'CatBoost': catboost_val_pred,\n",
    "    'HistGradientBoosting': hist_val_pred\n",
    "}\n",
    "\n",
    "base_predictions_test_b = {\n",
    "    'LightGBM': lgbm_test_pred,\n",
    "    'CatBoost': catboost_test_pred,\n",
    "    'HistGradientBoosting': hist_test_pred\n",
    "}\n",
    "\n",
    "# Pattern B: LightGBM + CatBoost + HistGB\n",
    "pattern_b_models = ['LightGBM', 'CatBoost', 'HistGradientBoosting']\n",
    "# ğŸ”¥ Validationã‚»ãƒƒãƒˆã§é‡ã¿ã‚’æœ€é©åŒ–\n",
    "weights_b, _ = optimize_weights(base_predictions_val_b, y_val, pattern_b_models)\n",
    "\n",
    "print('\\nOptimized Weights (on Validation set):')\n",
    "for name, w in zip(pattern_b_models, weights_b):\n",
    "    print(f'  {name:25s}: {w:.4f}')\n",
    "\n",
    "# Validationè©•ä¾¡\n",
    "weightB_val_pred = np.column_stack([base_predictions_val_b[name] for name in pattern_b_models]) @ weights_b\n",
    "weightB_val_metrics = evaluate_model(y_val, weightB_val_pred, 'WeightedEnsemble_B', 'Validation')\n",
    "all_evaluation_results.append(weightB_val_metrics)\n",
    "\n",
    "# ğŸ”¥ åŒã˜é‡ã¿ã‚’Testã‚»ãƒƒãƒˆã«é©ç”¨\n",
    "weightB_test_pred = np.column_stack([base_predictions_test_b[name] for name in pattern_b_models]) @ weights_b\n",
    "weightB_test_metrics = evaluate_model(y_test, weightB_test_pred, 'WeightedEnsemble_B', 'Test')\n",
    "all_evaluation_results.append(weightB_test_metrics)\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('All models trained and evaluated successfully!')\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Results Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Summary Table: All Models Comparison\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('COMPREHENSIVE MODEL EVALUATION SUMMARY')\n",
    "print('='*80)\n",
    "\n",
    "# è©•ä¾¡çµæœã‚’DataFrameã«å¤‰æ›\n",
    "results_df = pd.DataFrame(all_evaluation_results)\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«åã¨ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã§ä¸¦ã³æ›¿ãˆ\n",
    "results_df = results_df.sort_values(['model', 'data_type']).reset_index(drop=True)\n",
    "\n",
    "print('\\n--- Full Results Table ---')\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Validation ã¨ Test ã‚’åˆ†ã‘ã¦è¡¨ç¤º\n",
    "print('\\n' + '='*80)\n",
    "print('VALIDATION SET RESULTS')\n",
    "print('='*80)\n",
    "val_results = results_df[results_df['data_type'] == 'Validation'].copy()\n",
    "val_results = val_results.sort_values('MAE').reset_index(drop=True)\n",
    "print(val_results[['model', 'MAE', 'RMSE', 'R2', 'WAPE']].to_string(index=False))\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('TEST SET RESULTS')\n",
    "print('='*80)\n",
    "test_results = results_df[results_df['data_type'] == 'Test'].copy()\n",
    "test_results = test_results.sort_values('MAE').reset_index(drop=True)\n",
    "print(test_results[['model', 'MAE', 'RMSE', 'R2', 'WAPE']].to_string(index=False))\n",
    "\n",
    "# ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤º\n",
    "print('\\n' + '='*80)\n",
    "print('BEST MODELS')\n",
    "print('='*80)\n",
    "\n",
    "best_val_mae = val_results.iloc[0]\n",
    "best_test_mae = test_results.iloc[0]\n",
    "\n",
    "print(f\"\\nBest Validation MAE: {best_val_mae['model']} ({best_val_mae['MAE']:.4f})\")\n",
    "print(f\"Best Test MAE: {best_test_mae['model']} ({best_test_mae['MAE']:.4f})\")\n",
    "\n",
    "# CSVä¿å­˜\n",
    "import os\n",
    "output_dir = '../output/exp13'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "results_df.to_csv(f'{output_dir}/model_evaluation_results.csv', index=False)\n",
    "print(f\"\\nçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_dir}/model_evaluation_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Visualization: Model Comparison (Validation vs Test)\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Validation vs Test ã®æ¯”è¼ƒå¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Model Performance Comparison (Validation vs Test)', fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics_to_plot = ['MAE', 'RMSE', 'R2', 'WAPE']\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«Validationã¨Testã‚’ä¸¦ã¹ã‚‹\n",
    "models = val_results['model'].unique()\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    val_values = [val_results[val_results['model'] == m][metric].values[0] for m in models]\n",
    "    test_values = [test_results[test_results['model'] == m][metric].values[0] for m in models]\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, val_values, width, label='Validation', color='#1f77b4', alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, test_values, width, label='Test', color='#ff7f0e', alpha=0.8)\n",
    "    \n",
    "    ax.set_ylabel(metric, fontsize=12)\n",
    "    ax.set_title(f'{metric} Comparison', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=45, ha='right', fontsize=9)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}', ha='center', va='bottom', fontsize=7)\n",
    "    \n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}', ha='center', va='bottom', fontsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/model_comparison_val_vs_test.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nå¯è¦–åŒ–ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_dir}/model_comparison_val_vs_test.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**exp13: å³å¯†ãªãƒ¢ãƒ‡ãƒ«è©•ä¾¡ (Train/Validation/Test 3åˆ†å‰²)**\n",
    "\n",
    "### exp12ã‹ã‚‰ã®æ”¹å–„ç‚¹:\n",
    "- **ãƒ‡ãƒ¼ã‚¿ã‚’3åˆ†å‰²**: Train / Validation / Test\n",
    "- **Validationã‚»ãƒƒãƒˆ**: ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿æœ€é©åŒ–ã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã«ä½¿ç”¨\n",
    "- **Testã‚»ãƒƒãƒˆ**: æœ€çµ‚è©•ä¾¡ç”¨ã®å®Œå…¨ã«ç‹¬ç«‹ã—ãŸãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆã‚»ãƒƒãƒˆ\n",
    "\n",
    "### è©•ä¾¡ã—ãŸãƒ¢ãƒ‡ãƒ«:\n",
    "1. **HistGradientBoosting** (hist)\n",
    "2. **ExtraTrees** (extra)\n",
    "3. **CatBoost** (catboost)\n",
    "4. **Weighted Ensemble A** (weightA): Ridge + CatBoost + ExtraTrees + HistGB\n",
    "5. **Weighted Ensemble B** (weightB): LightGBM + CatBoost + HistGB\n",
    "\n",
    "### è©•ä¾¡æŒ‡æ¨™:\n",
    "- **MAE** (Mean Absolute Error)\n",
    "- **RMSE** (Root Mean Squared Error)\n",
    "- **R2** (R-squared Score)\n",
    "- **WAPE** (Weighted Absolute Percentage Error)\n",
    "\n",
    "### è©•ä¾¡ãƒ‡ãƒ¼ã‚¿:\n",
    "- **Validation Set**: ãƒ¢ãƒ‡ãƒ«é¸æŠã¨é‡ã¿æœ€é©åŒ–ç”¨ï¼ˆ2ãƒ¶æœˆï¼‰\n",
    "- **Test Set**: æœ€çµ‚è©•ä¾¡ç”¨ã®ç‹¬ç«‹ãƒ‡ãƒ¼ã‚¿ï¼ˆ2ãƒ¶æœˆï¼‰\n",
    "\n",
    "### å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:\n",
    "1. `model_evaluation_results.csv` - å…¨ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡çµæœ\n",
    "2. `model_comparison_val_vs_test.png` - Validation vs Test ã®æ¯”è¼ƒå¯è¦–åŒ–"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
