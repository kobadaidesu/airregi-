{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2d9d53a",
   "metadata": {},
   "source": [
    "# AirREGI ヘルプデスク入電予測 - EDA & 特徴量エンジニアリング\n",
    "\n",
    "## 概要\n",
    "このノートブックでは、時系列データの探索的データ分析と特徴量エンジニアリングを行います。\n",
    "\n",
    "### 設計方針\n",
    "- **モジュール化**: 各特徴量グループをクラスで管理\n",
    "- **テスト容易性**: 各特徴量を独立してテスト可能\n",
    "- **データリーケージ防止**: 時系列データで未来の情報を使わない\n",
    "- **可読性**: コードの意図を明確に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd21fa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# ライブラリのインポート\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "from typing import List, Optional, Dict, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 日本語フォント設定（文字化け対策）\n",
    "plt.rcParams['font.sans-serif'] = ['MS Gothic', 'Yu Gothic', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 表示設定\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311eacf2",
   "metadata": {},
   "source": [
    "## 1. データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c29476e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "データ読み込み開始\n",
      "================================================================================\n",
      "\n",
      "読み込み完了:\n",
      "  calender       : (670, 10)\n",
      "  cm_data        : (762, 2)\n",
      "  gt_service     : (109, 2)\n",
      "  acc_get        : (701, 2)\n",
      "  call_data      : (670, 2)\n",
      "\n",
      "================================================================================\n",
      "データ統合開始\n",
      "================================================================================\n",
      "\n",
      "ベースデータ: (670, 2)\n",
      "カレンダー統合後: (670, 11)\n",
      "CM統合後: (670, 12)\n",
      "アカウント取得数統合後: (670, 13)\n",
      "\n",
      "Google Trendsを週次→日次に展開中...\n",
      "Google Trends統合後: (670, 14)\n",
      "\n",
      "日付でソート完了（時系列処理のため）\n",
      "\n",
      "欠損値の数（上位10）:\n",
      "  holiday_name                  :  632 (94.3%)\n",
      "\n",
      "================================================================================\n",
      "統合データ: (670, 14)\n",
      "期間: 2018-06-01 00:00:00 ~ 2020-03-31 00:00:00\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"データ読み込みと前処理を行うクラス\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dir: str = '../input'):\n",
    "        self.input_dir = input_dir\n",
    "        \n",
    "    def load_all(self) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"全データを読み込み、日付型に変換\"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"データ読み込み開始\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # データ読み込み\n",
    "        calender = pd.read_csv(f'{self.input_dir}/calender_data.csv')\n",
    "        cm_data = pd.read_csv(f'{self.input_dir}/cm_data.csv')\n",
    "        gt_service = pd.read_csv(f'{self.input_dir}/gt_service_name.csv')\n",
    "        acc_get = pd.read_csv(f'{self.input_dir}/regi_acc_get_data_transform.csv')\n",
    "        call_data = pd.read_csv(f'{self.input_dir}/regi_call_data_transform.csv')\n",
    "        \n",
    "        # 日付カラムをdatetime型に変換\n",
    "        calender['cdr_date'] = pd.to_datetime(calender['cdr_date'])\n",
    "        cm_data['cdr_date'] = pd.to_datetime(cm_data['cdr_date'])\n",
    "        acc_get['cdr_date'] = pd.to_datetime(acc_get['cdr_date'])\n",
    "        call_data['cdr_date'] = pd.to_datetime(call_data['cdr_date'])\n",
    "        gt_service['week'] = pd.to_datetime(gt_service['week'])\n",
    "        \n",
    "        # データサイズを表示\n",
    "        datasets = {\n",
    "            'calender': calender,\n",
    "            'cm_data': cm_data,\n",
    "            'gt_service': gt_service,\n",
    "            'acc_get': acc_get,\n",
    "            'call_data': call_data\n",
    "        }\n",
    "        \n",
    "        print(\"\\n読み込み完了:\")\n",
    "        for name, df in datasets.items():\n",
    "            print(f\"  {name:15s}: {df.shape}\")\n",
    "        \n",
    "        return datasets\n",
    "    \n",
    "    def merge_all(self, datasets: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "        \"\"\"全データを統合\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"データ統合開始\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # メインデータ（入電数）を基準\n",
    "        df = datasets['call_data'].copy()\n",
    "        print(f\"\\nベースデータ: {df.shape}\")\n",
    "        \n",
    "        # カレンダー情報をマージ\n",
    "        df = df.merge(datasets['calender'], on='cdr_date', how='left')\n",
    "        print(f\"カレンダー統合後: {df.shape}\")\n",
    "        \n",
    "        # CM情報をマージ\n",
    "        df = df.merge(datasets['cm_data'], on='cdr_date', how='left')\n",
    "        print(f\"CM統合後: {df.shape}\")\n",
    "        \n",
    "        # アカウント取得数をマージ\n",
    "        df = df.merge(datasets['acc_get'], on='cdr_date', how='left')\n",
    "        print(f\"アカウント取得数統合後: {df.shape}\")\n",
    "        \n",
    "        # Google Trendsを週次→日次に展開\n",
    "        gt_daily = self._expand_weekly_to_daily(datasets['gt_service'])\n",
    "        df = df.merge(gt_daily, on='cdr_date', how='left')\n",
    "        print(f\"Google Trends統合後: {df.shape}\")\n",
    "        \n",
    "        # 日付でソート（時系列処理のため必須）\n",
    "        df = df.sort_values('cdr_date').reset_index(drop=True)\n",
    "        print(\"\\n日付でソート完了（時系列処理のため）\")\n",
    "        \n",
    "        # 欠損値確認\n",
    "        print(\"\\n欠損値の数（上位10）:\")\n",
    "        missing = df.isnull().sum().sort_values(ascending=False).head(10)\n",
    "        for col, count in missing.items():\n",
    "            if count > 0:\n",
    "                print(f\"  {col:30s}: {count:4d} ({count/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def _expand_weekly_to_daily(gt_service: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"週次データを日次に展開\"\"\"\n",
    "        print(\"\\nGoogle Trendsを週次→日次に展開中...\")\n",
    "        daily_records = []\n",
    "        \n",
    "        for _, row in gt_service.iterrows():\n",
    "            week_start = row['week']\n",
    "            for i in range(7):\n",
    "                date = week_start + timedelta(days=i)\n",
    "                daily_records.append({\n",
    "                    'cdr_date': date,\n",
    "                    'search_cnt': row['search_cnt']\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(daily_records)\n",
    "\n",
    "\n",
    "# データ読み込み実行\n",
    "loader = DataLoader()\n",
    "datasets = loader.load_all()\n",
    "df_raw = loader.merge_all(datasets)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"統合データ: {df_raw.shape}\")\n",
    "print(f\"期間: {df_raw['cdr_date'].min()} ~ {df_raw['cdr_date'].max()}\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf435c",
   "metadata": {},
   "source": [
    "## 2. 特徴量エンジニアリング\n",
    "\n",
    "### 設計パターン\n",
    "各特徴量グループを独立したクラスとして実装し、テストと保守を容易にします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ace13a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徴量エンジニアリングクラス定義完了\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['cdr_date', 'call_num'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BaseFeatureEngineer(ABC):\n",
    "    \"\"\"特徴量エンジニアリングの基底クラス\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.created_features: List[str] = []\n",
    "    \n",
    "    @abstractmethod\n",
    "    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"特徴量を作成（サブクラスで実装）\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_feature_names(self) -> List[str]:\n",
    "        \"\"\"作成された特徴量名のリストを取得\"\"\"\n",
    "        return self.created_features\n",
    "    \n",
    "    def describe(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"特徴量の統計情報を取得\"\"\"\n",
    "        if not self.created_features:\n",
    "            print(f\"{self.name}: 特徴量が未作成です\")\n",
    "            return pd.DataFrame()\n",
    "        return df[self.created_features].describe()\n",
    "\n",
    "\n",
    "class TimeBasedFeatures(BaseFeatureEngineer):\n",
    "    \"\"\"日付から派生する基本的な時系列特徴量\n",
    "    \n",
    "    これらは未来の情報を使わないため、データリーケージの心配がありません。\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"時系列基本特徴量\")\n",
    "    \n",
    "    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 年月日の特徴量\n",
    "        df['year'] = df['cdr_date'].dt.year\n",
    "        df['month'] = df['cdr_date'].dt.month\n",
    "        df['day_of_month'] = df['cdr_date'].dt.day\n",
    "        df['quarter'] = df['cdr_date'].dt.quarter\n",
    "        df['day_of_year'] = df['cdr_date'].dt.dayofyear\n",
    "        df['week_of_year'] = df['cdr_date'].dt.isocalendar().week\n",
    "        \n",
    "        # 経過日数\n",
    "        df['days_from_start'] = (df['cdr_date'] - df['cdr_date'].min()).dt.days\n",
    "        \n",
    "        # 月初・月末フラグ\n",
    "        df['is_month_start'] = (df['day_of_month'] <= 5).astype(int)\n",
    "        df['is_month_end'] = (df['day_of_month'] >= 25).astype(int)\n",
    "        \n",
    "        # 週初・週末（既存のdowを利用）\n",
    "        if 'dow' in df.columns:\n",
    "            df['is_week_start'] = (df['dow'] == 1).astype(int)  # 月曜\n",
    "            df['is_week_end'] = (df['dow'] == 5).astype(int)    # 金曜\n",
    "        \n",
    "        self.created_features = [\n",
    "            'year', 'month', 'day_of_month', 'quarter', 'day_of_year',\n",
    "            'week_of_year', 'days_from_start', 'is_month_start', 'is_month_end',\n",
    "            'is_week_start', 'is_week_end'\n",
    "        ]\n",
    "        \n",
    "        print(f\"{self.name}: {len(self.created_features)}個の特徴量を作成\")\n",
    "        return df\n",
    "\n",
    "\n",
    "class LagFeatures(BaseFeatureEngineer):\n",
    "    \"\"\"ラグ特徴量（過去のデータ）\n",
    "    \n",
    "    重要:\n",
    "    - shift()を使って未来の情報が混入しないようにする\n",
    "    - データは日付順にソート済みであることが前提\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_col: str = 'call_num', lags: List[int] = [1, 2, 3, 5, 7, 14, 30]):\n",
    "        super().__init__(\"ラグ特徴量\")\n",
    "        self.target_col = target_col\n",
    "        self.lags = lags\n",
    "    \n",
    "    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "        \n",
    "        if self.target_col not in df.columns:\n",
    "            print(f\"警告: {self.target_col}が見つかりません\")\n",
    "            return df\n",
    "        \n",
    "        for lag in self.lags:\n",
    "            col_name = f'lag_{lag}'\n",
    "            df[col_name] = df[self.target_col].shift(lag)\n",
    "            self.created_features.append(col_name)\n",
    "        \n",
    "        print(f\"{self.name}: {len(self.created_features)}個の特徴量を作成\")\n",
    "        print(f\"  対象変数: {self.target_col}\")\n",
    "        print(f\"  ラグ: {self.lags}\")\n",
    "        print(f\"  注意: 最初の{max(self.lags)}日間はNaNになります\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "class RollingFeatures(BaseFeatureEngineer):\n",
    "    \"\"\"移動統計量特徴量（移動平均、移動標準偏差など）\n",
    "    \n",
    "    重要:\n",
    "    - rolling()の前にshift(1)を適用してデータリーケージを防止\n",
    "    - 当日のデータが含まれないようにする\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_col: str = 'call_num', windows: List[int] = [3, 7, 14, 30]):\n",
    "        super().__init__(\"移動統計量特徴量\")\n",
    "        self.target_col = target_col\n",
    "        self.windows = windows\n",
    "    \n",
    "    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "        \n",
    "        if self.target_col not in df.columns:\n",
    "            print(f\"警告: {self.target_col}が見つかりません\")\n",
    "            return df\n",
    "        \n",
    "        for window in self.windows:\n",
    "            # 移動平均（当日を含まない）\n",
    "            ma_col = f'ma_{window}'\n",
    "            df[ma_col] = df[self.target_col].shift(1).rolling(\n",
    "                window=window, min_periods=1\n",
    "            ).mean()\n",
    "            self.created_features.append(ma_col)\n",
    "            \n",
    "            # 移動標準偏差（変動性を捉える）\n",
    "            std_col = f'ma_std_{window}'\n",
    "            df[std_col] = df[self.target_col].shift(1).rolling(\n",
    "                window=window, min_periods=1\n",
    "            ).std()\n",
    "            self.created_features.append(std_col)\n",
    "            \n",
    "            # 移動最大値\n",
    "            max_col = f'ma_max_{window}'\n",
    "            df[max_col] = df[self.target_col].shift(1).rolling(\n",
    "                window=window, min_periods=1\n",
    "            ).max()\n",
    "            self.created_features.append(max_col)\n",
    "            \n",
    "            # 移動最小値\n",
    "            min_col = f'ma_min_{window}'\n",
    "            df[min_col] = df[self.target_col].shift(1).rolling(\n",
    "                window=window, min_periods=1\n",
    "            ).min()\n",
    "            self.created_features.append(min_col)\n",
    "        \n",
    "        print(f\"{self.name}: {len(self.created_features)}個の特徴量を作成\")\n",
    "        print(f\"  対象変数: {self.target_col}\")\n",
    "        print(f\"  ウィンドウ: {self.windows}\")\n",
    "        print(f\"  統計量: 平均, 標準偏差, 最大値, 最小値\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "class DomainFeatures(BaseFeatureEngineer):\n",
    "    \"\"\"ドメイン知識に基づく特徴量\n",
    "    \n",
    "    - CM効果の累積\n",
    "    - Google Trendsの平滑化\n",
    "    - アカウント取得数の傾向\n",
    "    - 曜日ごとの過去平均\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"ドメイン特徴量\")\n",
    "    \n",
    "    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "        \n",
    "        # CM効果の累積（過去7日間のCM実施回数）\n",
    "        if 'cm_flg' in df.columns:\n",
    "            df['cm_7d_sum'] = df['cm_flg'].shift(1).rolling(window=7, min_periods=1).sum()\n",
    "            df['cm_14d_sum'] = df['cm_flg'].shift(1).rolling(window=14, min_periods=1).sum()\n",
    "            self.created_features.extend(['cm_7d_sum', 'cm_14d_sum'])\n",
    "        \n",
    "        # Google Trendsの移動平均（ノイズ除去）\n",
    "        if 'search_cnt' in df.columns:\n",
    "            df['gt_ma_7'] = df['search_cnt'].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "            df['gt_ma_14'] = df['search_cnt'].shift(1).rolling(window=14, min_periods=1).mean()\n",
    "            self.created_features.extend(['gt_ma_7', 'gt_ma_14'])\n",
    "        \n",
    "        # アカウント取得数の移動平均\n",
    "        if 'acc_get_cnt' in df.columns:\n",
    "            df['acc_ma_7'] = df['acc_get_cnt'].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "            df['acc_ma_14'] = df['acc_get_cnt'].shift(1).rolling(window=14, min_periods=1).mean()\n",
    "            self.created_features.extend(['acc_ma_7', 'acc_ma_14'])\n",
    "        \n",
    "        # 曜日ごとの過去平均（同じ曜日のパターンを捉える）\n",
    "        if 'dow' in df.columns and 'call_num' in df.columns:\n",
    "            df['dow_avg'] = np.nan\n",
    "            for dow in df['dow'].unique():\n",
    "                mask = df['dow'] == dow\n",
    "                df.loc[mask, 'dow_avg'] = df.loc[mask, 'call_num'].shift(1).expanding().mean()\n",
    "            self.created_features.append('dow_avg')\n",
    "        \n",
    "        print(f\"{self.name}: {len(self.created_features)}個の特徴量を作成\")\n",
    "        return df\n",
    "\n",
    "\n",
    "print(\"特徴量エンジニアリングクラス定義完了\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95af4fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['calender', 'cm_data', 'gt_service', 'acc_get', 'call_data'])\n",
      "datetime64[ns]\n",
      "0   2018-06-01\n",
      "1   2018-06-02\n",
      "2   2018-06-03\n",
      "3   2018-06-04\n",
      "4   2018-06-05\n",
      "Name: cdr_date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# セル4を実行済みなら、これで確認できる\n",
    "print(type(datasets))  # <class 'dict'>\n",
    "print(datasets.keys())  # dict_keys(['calender', 'cm_data', 'gt_service', 'acc_get', 'call_data'])\n",
    "\n",
    "# calenderデータにアクセス\n",
    "print(datasets['calender']['cdr_date'].dtype)  # datetime64[ns]\n",
    "print(datasets['calender']['cdr_date'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf2b5869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存完了: ../output/datasets/call_data.csv ((670, 2))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 保存先ディレクトリの作成\n",
    "output_dir = '../output/datasets'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 各DataFrameをCSVとして保存\n",
    "for name, df in datasets.items():\n",
    "    filepath = f'{output_dir}/{name}.csv'\n",
    "df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "print(f\"保存完了: {filepath} ({df.shape})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f010730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "データ構造の説明（サンプルデータ）\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "1. 結合前の個別データ（datasets）\n",
      "================================================================================\n",
      "\n",
      "[call_data] - 入電数（メインデータ）\n",
      "    cdr_date  call_num\n",
      "0 2018-06-01       183\n",
      "1 2018-06-02         0\n",
      "2 2018-06-03        96\n",
      "shape: (3, 2) （3行 × 2列）\n",
      "columns: ['cdr_date', 'call_num']\n",
      "\n",
      "[calender] - カレンダー情報\n",
      "    cdr_date  dow  dow_name  holiday_flag\n",
      "0 2018-06-01    5    Friday             0\n",
      "1 2018-06-02    6  Saturday             0\n",
      "2 2018-06-03    7    Sunday             0\n",
      "shape: (3, 4) （3行 × 4列）\n",
      "columns: ['cdr_date', 'dow', 'dow_name', 'holiday_flag']\n",
      "\n",
      "[cm_data] - CM実施フラグ\n",
      "    cdr_date  cm_flg\n",
      "0 2018-06-01       0\n",
      "1 2018-06-02       1\n",
      "2 2018-06-03       0\n",
      "shape: (3, 2) （3行 × 2列）\n",
      "columns: ['cdr_date', 'cm_flg']\n",
      "\n",
      "================================================================================\n",
      "2. 結合処理（merge）\n",
      "================================================================================\n",
      "\n",
      "ステップ1: call_dataをコピー\n",
      "  shape: (3, 2)\n",
      "  columns: ['cdr_date', 'call_num']\n",
      "\n",
      "ステップ2: calenderを結合\n",
      "  shape: (3, 5)\n",
      "  columns: ['cdr_date', 'call_num', 'dow', 'dow_name', 'holiday_flag']\n",
      "  ↑ call_dataのカラム + calenderのカラム（cdr_date以外）\n",
      "\n",
      "ステップ3: cm_dataを結合\n",
      "  shape: (3, 6)\n",
      "  columns: ['cdr_date', 'call_num', 'dow', 'dow_name', 'holiday_flag', 'cm_flg']\n",
      "  ↑ さらにcm_dataのカラム（cdr_date以外）を追加\n",
      "\n",
      "================================================================================\n",
      "3. 結合後のデータ（df_raw）\n",
      "================================================================================\n",
      "\n",
      "[df_raw] - 全データが横に結合された1つのテーブル\n",
      "    cdr_date  call_num  dow  dow_name  holiday_flag  cm_flg\n",
      "0 2018-06-01       183    5    Friday             0       0\n",
      "1 2018-06-02         0    6  Saturday             0       1\n",
      "2 2018-06-03        96    7    Sunday             0       0\n",
      "\n",
      "shape: (3, 6) （3行 × 6列）\n",
      "columns: ['cdr_date', 'call_num', 'dow', 'dow_name', 'holiday_flag', 'cm_flg']\n",
      "\n",
      "================================================================================\n",
      "4. データの取り出し方\n",
      "================================================================================\n",
      "\n",
      "■ 1つの列を取り出す\n",
      "df['call_num']\n",
      "0    183\n",
      "1      0\n",
      "2     96\n",
      "Name: call_num, dtype: int64\n",
      "\n",
      "■ 複数の列を取り出す\n",
      "df[['cdr_date', 'call_num', 'dow']]\n",
      "    cdr_date  call_num  dow\n",
      "0 2018-06-01       183    5\n",
      "1 2018-06-02         0    6\n",
      "2 2018-06-03        96    7\n",
      "\n",
      "■ 1行目のデータ\n",
      "df.iloc[0]\n",
      "cdr_date        2018-06-01 00:00:00\n",
      "call_num                        183\n",
      "dow                               5\n",
      "dow_name                     Friday\n",
      "holiday_flag                      0\n",
      "cm_flg                            0\n",
      "Name: 0, dtype: object\n",
      "\n",
      "■ 特定の値\n",
      "df.loc[0, 'call_num']  # 1行目のcall_num\n",
      "183\n",
      "\n",
      "================================================================================\n",
      "5. df.columnsの説明\n",
      "================================================================================\n",
      "\n",
      "df.columns = Index(['cdr_date', 'call_num', 'dow', 'dow_name', 'holiday_flag', 'cm_flg'], dtype='object')\n",
      "型: <class 'pandas.core.indexes.base.Index'>\n",
      "データ型: object\n",
      "\n",
      "■ 列名をリストとして取得\n",
      "df.columns.tolist() = ['cdr_date', 'call_num', 'dow', 'dow_name', 'holiday_flag', 'cm_flg']\n",
      "\n",
      "■ 列数\n",
      "len(df.columns) = 6\n",
      "\n",
      "■ 列名を1つずつ表示\n",
      "  0: cdr_date\n",
      "  1: call_num\n",
      "  2: dow\n",
      "  3: dow_name\n",
      "  4: holiday_flag\n",
      "  5: cm_flg\n",
      "\n",
      "================================================================================\n",
      "6. テーブル構造の視覚化\n",
      "================================================================================\n",
      "\n",
      "結合前:\n",
      "\n",
      "call_data          calender              cm_data\n",
      "┌────────────┐    ┌─────────────────┐    ┌───────────┐\n",
      "│ cdr_date   │    │ cdr_date        │    │ cdr_date  │\n",
      "│ call_num   │    │ dow             │    │ cm_flg    │\n",
      "└────────────┘    │ dow_name        │    └───────────┘\n",
      "   2列            │ holiday_flag    │       2列\n",
      "                  └─────────────────┘\n",
      "                        4列\n",
      "\n",
      "\n",
      "結合後（横に並べる）:\n",
      "\n",
      "df_raw\n",
      "┌───────────────────────────────────────────────────┐\n",
      "│ cdr_date  call_num  dow  dow_name  holiday_flag  cm_flg │\n",
      "└───────────────────────────────────────────────────┘\n",
      "                    6列（全て横に並ぶ）\n",
      "\n",
      "\n",
      "行の構造:\n",
      "\n",
      "0行目:\n",
      "  cdr_date     : 2018-06-01 00:00:00\n",
      "  call_num     : 183\n",
      "  dow          : 5\n",
      "  dow_name     : Friday\n",
      "  holiday_flag : 0\n",
      "  cm_flg       : 0\n",
      "\n",
      "1行目:\n",
      "  cdr_date     : 2018-06-02 00:00:00\n",
      "  call_num     : 0\n",
      "  dow          : 6\n",
      "  dow_name     : Saturday\n",
      "  holiday_flag : 0\n",
      "  cm_flg       : 1\n",
      "\n",
      "2行目:\n",
      "  cdr_date     : 2018-06-03 00:00:00\n",
      "  call_num     : 96\n",
      "  dow          : 7\n",
      "  dow_name     : Sunday\n",
      "  holiday_flag : 0\n",
      "  cm_flg       : 0\n",
      "\n",
      "================================================================================\n",
      "説明完了\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "データ構造を確認するスクリプト\n",
    "EDAノートブックのセル4を実行した後に実行してください\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# ==========================================\n",
    "# サンプルデータで説明\n",
    "# ==========================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"データ構造の説明（サンプルデータ）\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. 個別データ（結合前）\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"1. 結合前の個別データ（datasets）\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "call_data = pd.DataFrame({\n",
    "    'cdr_date': pd.to_datetime(['2018-06-01', '2018-06-02', '2018-06-03']),\n",
    "    'call_num': [183, 0, 96]\n",
    "})\n",
    "print(\"\\n[call_data] - 入電数（メインデータ）\")\n",
    "print(call_data)\n",
    "print(f\"shape: {call_data.shape} （{call_data.shape[0]}行 × {call_data.shape[1]}列）\")\n",
    "print(f\"columns: {call_data.columns.tolist()}\")\n",
    "\n",
    "calender = pd.DataFrame({\n",
    "    'cdr_date': pd.to_datetime(['2018-06-01', '2018-06-02', '2018-06-03']),\n",
    "    'dow': [5, 6, 7],\n",
    "    'dow_name': ['Friday', 'Saturday', 'Sunday'],\n",
    "    'holiday_flag': [0, 0, 0]\n",
    "})\n",
    "print(\"\\n[calender] - カレンダー情報\")\n",
    "print(calender)\n",
    "print(f\"shape: {calender.shape} （{calender.shape[0]}行 × {calender.shape[1]}列）\")\n",
    "print(f\"columns: {calender.columns.tolist()}\")\n",
    "\n",
    "cm_data = pd.DataFrame({\n",
    "    'cdr_date': pd.to_datetime(['2018-06-01', '2018-06-02', '2018-06-03']),\n",
    "    'cm_flg': [0, 1, 0]\n",
    "})\n",
    "print(\"\\n[cm_data] - CM実施フラグ\")\n",
    "print(cm_data)\n",
    "print(f\"shape: {cm_data.shape} （{cm_data.shape[0]}行 × {cm_data.shape[1]}列）\")\n",
    "print(f\"columns: {cm_data.columns.tolist()}\")\n",
    "\n",
    "# 2. 結合処理\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"2. 結合処理（merge）\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df = call_data.copy()\n",
    "print(f\"\\nステップ1: call_dataをコピー\")\n",
    "print(f\"  shape: {df.shape}\")\n",
    "print(f\"  columns: {df.columns.tolist()}\")\n",
    "\n",
    "df = df.merge(calender, on='cdr_date', how='left')\n",
    "print(f\"\\nステップ2: calenderを結合\")\n",
    "print(f\"  shape: {df.shape}\")\n",
    "print(f\"  columns: {df.columns.tolist()}\")\n",
    "print(\"  ↑ call_dataのカラム + calenderのカラム（cdr_date以外）\")\n",
    "\n",
    "df = df.merge(cm_data, on='cdr_date', how='left')\n",
    "print(f\"\\nステップ3: cm_dataを結合\")\n",
    "print(f\"  shape: {df.shape}\")\n",
    "print(f\"  columns: {df.columns.tolist()}\")\n",
    "print(\"  ↑ さらにcm_dataのカラム（cdr_date以外）を追加\")\n",
    "\n",
    "# 3. 結合後のデータ\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"3. 結合後のデータ（df_raw）\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n[df_raw] - 全データが横に結合された1つのテーブル\")\n",
    "print(df)\n",
    "print(f\"\\nshape: {df.shape} （{df.shape[0]}行 × {df.shape[1]}列）\")\n",
    "print(f\"columns: {df.columns.tolist()}\")\n",
    "\n",
    "# 4. データの取り出し方\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"4. データの取り出し方\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n■ 1つの列を取り出す\")\n",
    "print(\"df['call_num']\")\n",
    "print(df['call_num'])\n",
    "\n",
    "print(\"\\n■ 複数の列を取り出す\")\n",
    "print(\"df[['cdr_date', 'call_num', 'dow']]\")\n",
    "print(df[['cdr_date', 'call_num', 'dow']])\n",
    "\n",
    "print(\"\\n■ 1行目のデータ\")\n",
    "print(\"df.iloc[0]\")\n",
    "print(df.iloc[0])\n",
    "\n",
    "print(\"\\n■ 特定の値\")\n",
    "print(\"df.loc[0, 'call_num']  # 1行目のcall_num\")\n",
    "print(df.loc[0, 'call_num'])\n",
    "\n",
    "# 5. df.columnsの説明\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"5. df.columnsの説明\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\ndf.columns = {df.columns}\")\n",
    "print(f\"型: {type(df.columns)}\")\n",
    "print(f\"データ型: {df.columns.dtype}\")\n",
    "\n",
    "print(\"\\n■ 列名をリストとして取得\")\n",
    "print(f\"df.columns.tolist() = {df.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n■ 列数\")\n",
    "print(f\"len(df.columns) = {len(df.columns)}\")\n",
    "\n",
    "print(\"\\n■ 列名を1つずつ表示\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"  {i}: {col}\")\n",
    "\n",
    "# 6. 実際のテーブル構造を視覚化\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"6. テーブル構造の視覚化\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n結合前:\")\n",
    "print(\"\"\"\n",
    "call_data          calender              cm_data\n",
    "┌────────────┐    ┌─────────────────┐    ┌───────────┐\n",
    "│ cdr_date   │    │ cdr_date        │    │ cdr_date  │\n",
    "│ call_num   │    │ dow             │    │ cm_flg    │\n",
    "└────────────┘    │ dow_name        │    └───────────┘\n",
    "   2列            │ holiday_flag    │       2列\n",
    "                  └─────────────────┘\n",
    "                        4列\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n結合後（横に並べる）:\")\n",
    "print(\"\"\"\n",
    "df_raw\n",
    "┌───────────────────────────────────────────────────┐\n",
    "│ cdr_date  call_num  dow  dow_name  holiday_flag  cm_flg │\n",
    "└───────────────────────────────────────────────────┘\n",
    "                    6列（全て横に並ぶ）\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n行の構造:\")\n",
    "for idx, row in df.iterrows():\n",
    "    print(f\"\\n{idx}行目:\")\n",
    "    print(f\"  cdr_date     : {row['cdr_date']}\")\n",
    "    print(f\"  call_num     : {row['call_num']}\")\n",
    "    print(f\"  dow          : {row['dow']}\")\n",
    "    print(f\"  dow_name     : {row['dow_name']}\")\n",
    "    print(f\"  holiday_flag : {row['holiday_flag']}\")\n",
    "    print(f\"  cm_flg       : {row['cm_flg']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"説明完了\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88459cdd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/cm_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_61/3344835459.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# データ読み込み\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcm_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/cm_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0macc_get\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/regi_acc_get_data_transform.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/regi_call_data_transform.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/cm_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# データ読み込み\n",
    "cm_data = pd.read_csv('../input/cm_data.csv')\n",
    "acc_get = pd.read_csv('../input/regi_acc_get_data_transform.csv')\n",
    "call_data = pd.read_csv('../input/regi_call_data_transform.csv')\n",
    "\n",
    "# 日付型に変換\n",
    "cm_data['cdr_date'] = pd.to_datetime(cm_data['cdr_date'])\n",
    "acc_get['cdr_date'] = pd.to_datetime(acc_get['cdr_date'])\n",
    "call_data['cdr_date'] = pd.to_datetime(call_data['cdr_date'])\n",
    "\n",
    "# マージ\n",
    "df = call_data.merge(cm_data, on='cdr_date', how='left')\n",
    "df = df.merge(acc_get, on='cdr_date', how='left')\n",
    "\n",
    "# ========================================\n",
    "# Plot 1: 時系列で比較（2軸）\n",
    "# ========================================\n",
    "fig, ax1 = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "# CM放送日を縦線で表示\n",
    "cm_dates = df[df['cm_flg'] == 1]['cdr_date']\n",
    "for d in cm_dates:\n",
    "    ax1.axvline(x=d, color='red', alpha=0.3, linewidth=1)\n",
    "\n",
    "# アカウント取得数\n",
    "ax1.plot(df['cdr_date'], df['acc_get_cnt'], color='blue', alpha=0.7, label='acc_get_cnt')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('acc_get_cnt', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# 凡例用のダミー\n",
    "ax1.axvline(x=df['cdr_date'].min(), color='red', alpha=0.5, linewidth=2, label='CM broadcast')\n",
    "\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('CM Broadcast vs Account Acquisition (Time Series)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========================================\n",
    "# Plot 2: CM前後のacc_get_cnt比較（箱ひげ図）\n",
    "# ========================================\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# CM放送日とそれ以外で分類\n",
    "df['cm_label'] = df['cm_flg'].map({0: 'No CM', 1: 'CM Day'})\n",
    "df.boxplot(column='acc_get_cnt', by='cm_label', ax=ax)\n",
    "plt.suptitle('')\n",
    "plt.title('acc_get_cnt: CM Day vs No CM Day')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('acc_get_cnt')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========================================\n",
    "# Plot 3: CM放送後のacc_get_cnt推移（イベントスタディ風）\n",
    "# ========================================\n",
    "# CM放送日を基準に前後N日のacc_get_cntを集計\n",
    "window = 14  # CM前後14日\n",
    "\n",
    "cm_indices = df[df['cm_flg'] == 1].index.tolist()\n",
    "effects = []\n",
    "\n",
    "for idx in cm_indices:\n",
    "    for offset in range(-window, window + 1):\n",
    "        target_idx = idx + offset\n",
    "        if 0 <= target_idx < len(df):\n",
    "            effects.append({\n",
    "                'offset': offset,\n",
    "                'acc_get_cnt': df.loc[target_idx, 'acc_get_cnt']\n",
    "            })\n",
    "\n",
    "effects_df = pd.DataFrame(effects)\n",
    "avg_effect = effects_df.groupby('offset')['acc_get_cnt'].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(avg_effect.index, avg_effect.values, color=['red' if x == 0 else 'steelblue' for x in avg_effect.index])\n",
    "ax.axvline(x=0, color='red', linestyle='--', linewidth=2, label='CM Day')\n",
    "ax.set_xlabel('Days from CM Broadcast')\n",
    "ax.set_ylabel('avg acc_get_cnt')\n",
    "ax.set_title(f'Average acc_get_cnt around CM Broadcast (±{window} days)')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========================================\n",
    "# Plot 4: 相関散布図\n",
    "# ========================================\n",
    "# CM放送の累積効果（過去7日間のCM回数）\n",
    "df['cm_7d'] = df['cm_flg'].rolling(window=7, min_periods=1).sum()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 当日CM vs acc_get_cnt\n",
    "axes[0].scatter(df['cm_flg'], df['acc_get_cnt'], alpha=0.5)\n",
    "axes[0].set_xlabel('cm_flg (0 or 1)')\n",
    "axes[0].set_ylabel('acc_get_cnt')\n",
    "axes[0].set_title('CM Flag vs acc_get_cnt')\n",
    "\n",
    "# 過去7日CM回数 vs acc_get_cnt\n",
    "axes[1].scatter(df['cm_7d'], df['acc_get_cnt'], alpha=0.5)\n",
    "axes[1].set_xlabel('CM count in past 7 days')\n",
    "axes[1].set_ylabel('acc_get_cnt')\n",
    "axes[1].set_title('CM (7d cumulative) vs acc_get_cnt')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========================================\n",
    "# 統計サマリ\n",
    "# ========================================\n",
    "print(\"\\n=== CM Day vs No CM Day: acc_get_cnt Stats ===\")\n",
    "print(df.groupby('cm_label')['acc_get_cnt'].describe())\n",
    "\n",
    "print(\"\\n=== Correlation ===\")\n",
    "print(f\"cm_flg vs acc_get_cnt: {df['cm_flg'].corr(df['acc_get_cnt']):.4f}\")\n",
    "print(f\"cm_7d vs acc_get_cnt:  {df['cm_7d'].corr(df['acc_get_cnt']):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
