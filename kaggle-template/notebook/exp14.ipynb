{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp14: Rolling Window Validation\n",
    "\n",
    "**ベースライン**: exp13の特徴量とモデルを使用\n",
    "\n",
    "**exp13からの改善点**:\n",
    "- 検証方法を **Rolling Window Validation** に変更\n",
    "- 時系列データを複数の期間に分割して評価\n",
    "- より安定した性能評価が可能\n",
    "\n",
    "**Rolling Window設定**:\n",
    "- Window size: 2ヶ月（約40-45営業日）\n",
    "- Step: 1ヶ月（約20営業日）\n",
    "- 各Windowで Train → Test の評価を実施\n",
    "- 最終スコアは全Windowの平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Best Optuna Parameters (from exp05 optimization)\n",
    "# ============================================================================\n",
    "\n",
    "BEST_PARAMS = {\n",
    "    'Ridge': {'alpha': 70.4183028501599},\n",
    "    'ExtraTrees': {\n",
    "        'n_estimators': 229,\n",
    "        'max_depth': 29,\n",
    "        'min_samples_split': 16,\n",
    "        'min_samples_leaf': 1,\n",
    "        'max_features': None\n",
    "    },\n",
    "    'HistGradientBoosting': {\n",
    "        'max_iter': 238,\n",
    "        'learning_rate': 0.015251103470998385,\n",
    "        'max_depth': 20,\n",
    "        'min_samples_leaf': 33,\n",
    "        'l2_regularization': 9.037967498117355\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': 127,\n",
    "        'learning_rate': 0.1601531217136121,\n",
    "        'num_leaves': 112,\n",
    "        'max_depth': 12,\n",
    "        'subsample': 0.9085081386743783,\n",
    "        'colsample_bytree': 0.6296178606936361,\n",
    "        'reg_lambda': 0.5211124595788266,\n",
    "        'reg_alpha': 0.5793452976256486\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'iterations': 2295,\n",
    "        'learning_rate': 0.10429705988762059,\n",
    "        'depth': 5,\n",
    "        'l2_leaf_reg': 6.359326196557493,\n",
    "        'subsample': 0.8738193035765242\n",
    "    }\n",
    "}\n",
    "\n",
    "print('Best parameters loaded from exp05 optimization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Step 1-6: データの読み込みと特徴量作成（exp13と同じ）\n",
    "# ==================================================================================\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Step 1: データの読み込み\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    calender = pd.read_csv('../input/calender_data.csv')\n",
    "    cm_data = pd.read_csv('../input/cm_data.csv')\n",
    "    gt_service = pd.read_csv('../input/gt_service_name.csv')\n",
    "    acc_get = pd.read_csv('../input/regi_acc_get_data_transform.csv')\n",
    "    call_data = pd.read_csv('../input/regi_call_data_transform.csv')\n",
    "    \n",
    "    calender['cdr_date'] = pd.to_datetime(calender['cdr_date'])\n",
    "    cm_data['cdr_date'] = pd.to_datetime(cm_data['cdr_date'])\n",
    "    acc_get['cdr_date'] = pd.to_datetime(acc_get['cdr_date'])\n",
    "    call_data['cdr_date'] = pd.to_datetime(call_data['cdr_date'])\n",
    "    gt_service['week'] = pd.to_datetime(gt_service['week'])\n",
    "    \n",
    "    print(f\"\\nデータ期間: {call_data['cdr_date'].min()} ~ {call_data['cdr_date'].max()}\")\n",
    "    \n",
    "    return calender, cm_data, gt_service, acc_get, call_data\n",
    "\n",
    "def merge_datasets(calender, cm_data, gt_service, acc_get, call_data):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Step 2: データの統合\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    df = call_data.copy()\n",
    "    df = df.merge(calender, on='cdr_date', how='left')\n",
    "    df = df.merge(cm_data, on='cdr_date', how='left')\n",
    "    df = df.merge(acc_get, on='cdr_date', how='left')\n",
    "    \n",
    "    gt_service_daily = []\n",
    "    for idx, row in gt_service.iterrows():\n",
    "        week_start = row['week']\n",
    "        for i in range(7):\n",
    "            date = week_start + timedelta(days=i)\n",
    "            gt_service_daily.append({'cdr_date': date, 'search_cnt': row['search_cnt']})\n",
    "    \n",
    "    gt_daily = pd.DataFrame(gt_service_daily)\n",
    "    df = df.merge(gt_daily, on='cdr_date', how='left')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_basic_time_features(df):\n",
    "    df = df.copy()\n",
    "    df['year'] = df['cdr_date'].dt.year\n",
    "    df['month'] = df['cdr_date'].dt.month\n",
    "    df['day_of_month'] = df['cdr_date'].dt.day\n",
    "    df['quarter'] = df['cdr_date'].dt.quarter\n",
    "    df['day_of_year'] = df['cdr_date'].dt.dayofyear\n",
    "    df['week_of_year'] = df['cdr_date'].dt.isocalendar().week\n",
    "    df['days_from_start'] = (df['cdr_date'] - df['cdr_date'].min()).dt.days\n",
    "    df['is_month_start'] = (df['day_of_month'] <= 5).astype(int)\n",
    "    df['is_month_end'] = (df['day_of_month'] >= 25).astype(int)\n",
    "    return df\n",
    "\n",
    "def create_lag_features(df, target_col='call_num', lags=[1, 2, 3, 5, 7, 14, 30]):\n",
    "    df = df.copy()\n",
    "    for lag in lags:\n",
    "        df[f'lag_{lag}'] = df[target_col].shift(lag)\n",
    "    return df\n",
    "\n",
    "def create_rolling_features(df, target_col='call_num', windows=[3, 7, 14, 30]):\n",
    "    df = df.copy()\n",
    "    for window in windows:\n",
    "        df[f'ma_{window}'] = df[target_col].shift(1).rolling(window=window, min_periods=1).mean()\n",
    "        df[f'ma_std_{window}'] = df[target_col].shift(1).rolling(window=window, min_periods=1).std()\n",
    "    return df\n",
    "\n",
    "def create_aggregated_features(df):\n",
    "    df = df.copy()\n",
    "    df['cm_7d'] = df['cm_flg'].shift(1).rolling(window=7, min_periods=1).sum()\n",
    "    df['gt_ma_7'] = df['search_cnt'].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "    df['acc_ma_7'] = df['acc_get_cnt'].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "    \n",
    "    df['dow_avg'] = np.nan\n",
    "    for dow in df['dow'].unique():\n",
    "        mask = df['dow'] == dow\n",
    "        df.loc[mask, 'dow_avg'] = df.loc[mask, 'call_num'].shift(1).expanding().mean()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# データ準備\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"*\" * 80)\n",
    "print(\"exp14: Rolling Window Validation\")\n",
    "print(\"*\" * 80)\n",
    "\n",
    "calender, cm_data, gt_service, acc_get, call_data = load_and_preprocess_data()\n",
    "df = merge_datasets(calender, cm_data, gt_service, acc_get, call_data)\n",
    "df = create_basic_time_features(df)\n",
    "df = create_lag_features(df)\n",
    "df = create_rolling_features(df)\n",
    "df = create_aggregated_features(df)\n",
    "\n",
    "# 翌日の入電数を目的変数にする\n",
    "df['target_next_day'] = df['call_num'].shift(-1)\n",
    "df = df.dropna(subset=['target_next_day']).reset_index(drop=True)\n",
    "\n",
    "# 平日のみ\n",
    "df_model = df[df['dow'].isin([1, 2, 3, 4, 5])].copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n平日データ数: {len(df_model)}行\")\n",
    "print(f\"期間: {df_model['cdr_date'].min()} ~ {df_model['cdr_date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Rolling Window Validation の設定\n",
    "# ==================================================================================\n",
    "\n",
    "# 特徴量リスト\n",
    "feature_cols = [\n",
    "    'dow', 'day_of_month', 'month', 'quarter', 'year', \n",
    "    'days_from_start', 'day_of_year', 'week_of_year',\n",
    "    'is_month_start', 'is_month_end',\n",
    "    'woy', 'wom', 'day_before_holiday_flag',\n",
    "    'cm_flg', 'acc_get_cnt', 'search_cnt',\n",
    "    'cm_7d', 'gt_ma_7', 'acc_ma_7', 'dow_avg',\n",
    "    'lag_1', 'lag_2', 'lag_3', 'lag_5', 'lag_7', 'lag_14', 'lag_30',\n",
    "    'ma_3', 'ma_7', 'ma_14', 'ma_30',\n",
    "    'ma_std_3', 'ma_std_7', 'ma_std_14', 'ma_std_30'\n",
    "]\n",
    "\n",
    "# Rolling Window設定\n",
    "test_window_days = 60  # テストウィンドウ: 2ヶ月\n",
    "step_days = 30  # ステップ: 1ヶ月\n",
    "\n",
    "# 欠損値を除去\n",
    "df_clean = df_model.dropna(subset=feature_cols + ['target_next_day']).copy()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Rolling Window Validation 設定\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"テストウィンドウ: {test_window_days}日（約2ヶ月）\")\n",
    "print(f\"ステップ: {step_days}日（約1ヶ月）\")\n",
    "print(f\"\\n使用データ: {len(df_clean)}行\")\n",
    "print(f\"期間: {df_clean['cdr_date'].min()} ~ {df_clean['cdr_date'].max()}\")\n",
    "\n",
    "# Rolling Window の分割点を計算\n",
    "min_date = df_clean['cdr_date'].min()\n",
    "max_date = df_clean['cdr_date'].max()\n",
    "total_days = (max_date - min_date).days\n",
    "\n",
    "# 最低限の訓練データを確保（90日 = 約3ヶ月）\n",
    "min_train_days = 90\n",
    "\n",
    "windows = []\n",
    "current_test_end = max_date\n",
    "\n",
    "while True:\n",
    "    test_start = current_test_end - pd.Timedelta(days=test_window_days)\n",
    "    train_end = test_start - pd.Timedelta(days=1)\n",
    "    \n",
    "    # 訓練データが最低限の期間を満たすかチェック\n",
    "    if (train_end - min_date).days < min_train_days:\n",
    "        break\n",
    "    \n",
    "    windows.append({\n",
    "        'train_start': min_date,\n",
    "        'train_end': train_end,\n",
    "        'test_start': test_start,\n",
    "        'test_end': current_test_end\n",
    "    })\n",
    "    \n",
    "    # 次のウィンドウへ\n",
    "    current_test_end = test_start - pd.Timedelta(days=1)\n",
    "\n",
    "windows = windows[::-1]  # 時系列順に並べ替え\n",
    "\n",
    "print(f\"\\n作成されたウィンドウ数: {len(windows)}\")\n",
    "print(\"\\nウィンドウ詳細:\")\n",
    "for i, w in enumerate(windows):\n",
    "    print(f\"\\nWindow {i+1}:\")\n",
    "    print(f\"  Train: {w['train_start'].strftime('%Y-%m-%d')} ~ {w['train_end'].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  Test : {w['test_start'].strftime('%Y-%m-%d')} ~ {w['test_end'].strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# モデル学習と評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 評価関数\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def calculate_wape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true)) * 100\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    return {\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'WAPE': calculate_wape(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "print('評価関数を定義しました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Rolling Window Validation の実行\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# 各モデルの全ウィンドウでの結果を保存\n",
    "all_window_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Rolling Window Validation 実行\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for window_idx, window in enumerate(windows):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Window {window_idx + 1}/{len(windows)}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Train: {window['train_start'].strftime('%Y-%m-%d')} ~ {window['train_end'].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Test : {window['test_start'].strftime('%Y-%m-%d')} ~ {window['test_end'].strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # データ分割\n",
    "    train_mask = (df_clean['cdr_date'] >= window['train_start']) & (df_clean['cdr_date'] <= window['train_end'])\n",
    "    test_mask = (df_clean['cdr_date'] >= window['test_start']) & (df_clean['cdr_date'] <= window['test_end'])\n",
    "    \n",
    "    X_train = df_clean.loc[train_mask, feature_cols]\n",
    "    y_train = df_clean.loc[train_mask, 'target_next_day']\n",
    "    X_test = df_clean.loc[test_mask, feature_cols]\n",
    "    y_test = df_clean.loc[test_mask, 'target_next_day']\n",
    "    \n",
    "    print(f\"\\nTrain: {len(X_train)}件, Test: {len(X_test)}件\")\n",
    "    \n",
    "    # 各モデルの訓練と評価\n",
    "    window_models = {}\n",
    "    window_predictions = {}\n",
    "    \n",
    "    # 1. HistGradientBoosting\n",
    "    print(\"\\n[1/5] HistGradientBoosting...\")\n",
    "    hist_model = HistGradientBoostingRegressor(**BEST_PARAMS['HistGradientBoosting'], random_state=42)\n",
    "    hist_model.fit(X_train, y_train)\n",
    "    hist_pred = hist_model.predict(X_test)\n",
    "    hist_metrics = evaluate_model(y_test, hist_pred)\n",
    "    print(f\"  MAE: {hist_metrics['MAE']:.2f}, RMSE: {hist_metrics['RMSE']:.2f}, R2: {hist_metrics['R2']:.3f}\")\n",
    "    window_models['HistGradientBoosting'] = hist_model\n",
    "    window_predictions['HistGradientBoosting'] = hist_pred\n",
    "    all_window_results.append({'window': window_idx+1, 'model': 'HistGradientBoosting', **hist_metrics})\n",
    "    \n",
    "    # 2. ExtraTrees\n",
    "    print(\"[2/5] ExtraTrees...\")\n",
    "    extra_model = ExtraTreesRegressor(**BEST_PARAMS['ExtraTrees'], random_state=42, n_jobs=-1)\n",
    "    extra_model.fit(X_train, y_train)\n",
    "    extra_pred = extra_model.predict(X_test)\n",
    "    extra_metrics = evaluate_model(y_test, extra_pred)\n",
    "    print(f\"  MAE: {extra_metrics['MAE']:.2f}, RMSE: {extra_metrics['RMSE']:.2f}, R2: {extra_metrics['R2']:.3f}\")\n",
    "    window_models['ExtraTrees'] = extra_model\n",
    "    window_predictions['ExtraTrees'] = extra_pred\n",
    "    all_window_results.append({'window': window_idx+1, 'model': 'ExtraTrees', **extra_metrics})\n",
    "    \n",
    "    # 3. CatBoost\n",
    "    print(\"[3/5] CatBoost...\")\n",
    "    catboost_model = CatBoostRegressor(**BEST_PARAMS['CatBoost'], random_state=42, verbose=0)\n",
    "    catboost_model.fit(X_train, y_train)\n",
    "    catboost_pred = catboost_model.predict(X_test)\n",
    "    catboost_metrics = evaluate_model(y_test, catboost_pred)\n",
    "    print(f\"  MAE: {catboost_metrics['MAE']:.2f}, RMSE: {catboost_metrics['RMSE']:.2f}, R2: {catboost_metrics['R2']:.3f}\")\n",
    "    window_models['CatBoost'] = catboost_model\n",
    "    window_predictions['CatBoost'] = catboost_pred\n",
    "    all_window_results.append({'window': window_idx+1, 'model': 'CatBoost', **catboost_metrics})\n",
    "    \n",
    "    # 4. Ridge\n",
    "    print(\"[4/5] Ridge...\")\n",
    "    ridge_model = Ridge(**BEST_PARAMS['Ridge'], random_state=42)\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    ridge_pred = ridge_model.predict(X_test)\n",
    "    ridge_metrics = evaluate_model(y_test, ridge_pred)\n",
    "    print(f\"  MAE: {ridge_metrics['MAE']:.2f}, RMSE: {ridge_metrics['RMSE']:.2f}, R2: {ridge_metrics['R2']:.3f}\")\n",
    "    window_models['Ridge'] = ridge_model\n",
    "    window_predictions['Ridge'] = ridge_pred\n",
    "    all_window_results.append({'window': window_idx+1, 'model': 'Ridge', **ridge_metrics})\n",
    "    \n",
    "    # 5. Weighted Ensemble A: Ridge + CatBoost + ExtraTrees + HistGB\n",
    "    print(\"[5/5] WeightedEnsemble_A...\")\n",
    "    \n",
    "    # 重み最適化\n",
    "    def optimize_weights(predictions_dict, y_true, model_names):\n",
    "        preds_matrix = np.column_stack([predictions_dict[name] for name in model_names])\n",
    "        \n",
    "        def objective(weights):\n",
    "            ensemble_pred = preds_matrix @ weights\n",
    "            return mean_absolute_error(y_true, ensemble_pred)\n",
    "        \n",
    "        constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}\n",
    "        bounds = [(0, 1) for _ in range(len(model_names))]\n",
    "        initial_weights = np.ones(len(model_names)) / len(model_names)\n",
    "        \n",
    "        result = minimize(objective, initial_weights, method='SLSQP',\n",
    "                         bounds=bounds, constraints=constraints)\n",
    "        return result.x\n",
    "    \n",
    "    pattern_a_models = ['Ridge', 'CatBoost', 'ExtraTrees', 'HistGradientBoosting']\n",
    "    weights_a = optimize_weights(window_predictions, y_test, pattern_a_models)\n",
    "    \n",
    "    weightA_pred = np.column_stack([window_predictions[name] for name in pattern_a_models]) @ weights_a\n",
    "    weightA_metrics = evaluate_model(y_test, weightA_pred)\n",
    "    print(f\"  MAE: {weightA_metrics['MAE']:.2f}, RMSE: {weightA_metrics['RMSE']:.2f}, R2: {weightA_metrics['R2']:.3f}\")\n",
    "    all_window_results.append({'window': window_idx+1, 'model': 'WeightedEnsemble_A', **weightA_metrics})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Rolling Window Validation 完了\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 結果の集計と可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 結果の集計\n",
    "# ============================================================================\n",
    "\n",
    "results_df = pd.DataFrame(all_window_results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"全ウィンドウの結果\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# モデルごとの平均スコア\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"モデルごとの平均スコア（全ウィンドウ）\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "average_scores = results_df.groupby('model')[['MAE', 'RMSE', 'R2', 'WAPE']].mean()\n",
    "average_scores = average_scores.sort_values('MAE')\n",
    "print(average_scores.to_string())\n",
    "\n",
    "# 標準偏差も確認（スコアの安定性）\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"モデルごとの標準偏差（スコアの安定性）\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "std_scores = results_df.groupby('model')[['MAE', 'RMSE', 'R2', 'WAPE']].std()\n",
    "std_scores = std_scores.sort_values('MAE')\n",
    "print(std_scores.to_string())\n",
    "\n",
    "# CSV保存\n",
    "import os\n",
    "output_dir = '../output/exp14'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "results_df.to_csv(f'{output_dir}/rolling_window_results.csv', index=False)\n",
    "average_scores.to_csv(f'{output_dir}/average_scores.csv')\n",
    "std_scores.to_csv(f'{output_dir}/std_scores.csv')\n",
    "\n",
    "print(f\"\\n結果を保存しました: {output_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 可視化: ウィンドウごとのMAE推移\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Rolling Window Validation Results', fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics_to_plot = ['MAE', 'RMSE', 'R2', 'WAPE']\n",
    "models = results_df['model'].unique()\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    for model in models:\n",
    "        model_data = results_df[results_df['model'] == model]\n",
    "        ax.plot(model_data['window'], model_data[metric], marker='o', label=model, linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Window', fontsize=12)\n",
    "    ax.set_ylabel(metric, fontsize=12)\n",
    "    ax.set_title(f'{metric} per Window', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_xticks(range(1, len(windows) + 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/rolling_window_trends.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n可視化を保存しました: {output_dir}/rolling_window_trends.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 可視化: 平均スコアと標準偏差\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 平均MAE\n",
    "ax = axes[0]\n",
    "models_sorted = average_scores.index\n",
    "mae_means = average_scores['MAE']\n",
    "mae_stds = std_scores.loc[models_sorted, 'MAE']\n",
    "\n",
    "bars = ax.barh(range(len(models_sorted)), mae_means, xerr=mae_stds, \n",
    "               color='steelblue', alpha=0.8, capsize=5)\n",
    "ax.set_yticks(range(len(models_sorted)))\n",
    "ax.set_yticklabels(models_sorted)\n",
    "ax.set_xlabel('MAE', fontsize=12)\n",
    "ax.set_title('Average MAE (with Std Dev)', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, (mean, std) in enumerate(zip(mae_means, mae_stds)):\n",
    "    ax.text(mean + std + 1, i, f'{mean:.2f}±{std:.2f}', \n",
    "            va='center', fontsize=10)\n",
    "\n",
    "# WAPE\n",
    "ax = axes[1]\n",
    "wape_means = average_scores['WAPE']\n",
    "wape_stds = std_scores.loc[models_sorted, 'WAPE']\n",
    "\n",
    "bars = ax.barh(range(len(models_sorted)), wape_means, xerr=wape_stds, \n",
    "               color='coral', alpha=0.8, capsize=5)\n",
    "ax.set_yticks(range(len(models_sorted)))\n",
    "ax.set_yticklabels(models_sorted)\n",
    "ax.set_xlabel('WAPE (%)', fontsize=12)\n",
    "ax.set_title('Average WAPE (with Std Dev)', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, (mean, std) in enumerate(zip(wape_means, wape_stds)):\n",
    "    ax.text(mean + std + 0.5, i, f'{mean:.2f}±{std:.2f}', \n",
    "            va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/average_scores_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n可視化を保存しました: {output_dir}/average_scores_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**exp14: Rolling Window Validation**\n",
    "\n",
    "### 検証方法:\n",
    "- **Rolling Window Validation** を使用\n",
    "- テストウィンドウ: 2ヶ月（約60日）\n",
    "- ステップ: 1ヶ月（約30日）\n",
    "- 最低訓練期間: 3ヶ月（約90日）\n",
    "\n",
    "### 評価したモデル:\n",
    "1. **HistGradientBoosting**\n",
    "2. **ExtraTrees**\n",
    "3. **CatBoost**\n",
    "4. **Ridge**\n",
    "5. **WeightedEnsemble_A**: Ridge + CatBoost + ExtraTrees + HistGB\n",
    "\n",
    "### 評価指標:\n",
    "- **平均スコア**: 全ウィンドウの平均値\n",
    "- **標準偏差**: スコアの安定性（小さいほど安定）\n",
    "\n",
    "### exp13との比較:\n",
    "- **exp13**: 単一のValidation/Test分割\n",
    "- **exp14**: 複数のウィンドウで評価（より頑健な評価）\n",
    "\n",
    "### 出力ファイル:\n",
    "1. `rolling_window_results.csv` - 全ウィンドウの詳細結果\n",
    "2. `average_scores.csv` - モデルごとの平均スコア\n",
    "3. `std_scores.csv` - モデルごとの標準偏差\n",
    "4. `rolling_window_trends.png` - ウィンドウごとの推移\n",
    "5. `average_scores_comparison.png` - 平均スコアの比較"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
