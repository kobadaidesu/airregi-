{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp20: exp19の最適化パラメータをRolling Window Validationで評価\n",
    "\n",
    "**ベースライン**: exp16 (WeightedEnsemble_A MAE=48.98)\n",
    "\n",
    "**背景**:\n",
    "- exp19でOptunaによるハイパーパラメータ最適化を実施\n",
    "- しかしexp19は単一Train/Val/Test分割で評価\n",
    "- exp16はRolling Window Validation（8ウィンドウ）で評価\n",
    "- **問題**: 検証方法が異なるため、直接比較できない\n",
    "\n",
    "**exp20の目的**:\n",
    "- exp19で最適化されたパラメータを使用\n",
    "- exp16と同じRolling Window Validation（8ウィンドウ）で評価\n",
    "- 公正な比較を実現\n",
    "\n",
    "**最適化されたパラメータ（exp19より）**:\n",
    "1. **Ridge** - alpha再最適化\n",
    "2. **ExtraTrees** - n_estimators, max_depth等\n",
    "3. **HistGradientBoosting** - learning_rate, max_depth等\n",
    "4. **CatBoost** - iterations, learning_rate, depth等\n",
    "5. **WeightedEnsemble_A** - ※各ウィンドウで個別に重み最適化\n",
    "\n",
    "**期待効果**:\n",
    "- exp16 (MAE=48.98) からの改善を検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# exp19で最適化されたパラメータ\n",
    "# ============================================================================\n",
    "\n",
    "# exp19の最適化結果から取得\n",
    "OPTIMIZED_PARAMS_EXP19 = {\n",
    "    'Ridge': {\n",
    "        'alpha': 16.450548234070856  # exp19で最適化\n",
    "    },\n",
    "    'ExtraTrees': {\n",
    "        'n_estimators': 472,\n",
    "        'max_depth': 35,\n",
    "        'min_samples_split': 15,\n",
    "        'min_samples_leaf': 4,\n",
    "        'max_features': None\n",
    "    },\n",
    "    'HistGradientBoosting': {\n",
    "        'max_iter': 465,\n",
    "        'learning_rate': 0.02173701290406704,\n",
    "        'max_depth': 22,\n",
    "        'min_samples_leaf': 17,\n",
    "        'l2_regularization': 11.071266395457282\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'iterations': 2099,\n",
    "        'learning_rate': 0.04211275181711693,\n",
    "        'depth': 9,\n",
    "        'l2_leaf_reg': 3.7647684179184813,\n",
    "        'subsample': 0.9533426254881911\n",
    "    }\n",
    "}\n",
    "\n",
    "print('exp19で最適化されたパラメータを読み込みました')\n",
    "print('\\nパラメータ詳細:')\n",
    "for model_name, params in OPTIMIZED_PARAMS_EXP19.items():\n",
    "    print(f'\\n{model_name}:')\n",
    "    for key, value in params.items():\n",
    "        print(f'  {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# データの読み込みと特徴量作成（exp16と同じ）\n",
    "# ==================================================================================\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Step 1: データの読み込み\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    calender = pd.read_csv('../input/calender_data.csv')\n",
    "    cm_data = pd.read_csv('../input/cm_data.csv')\n",
    "    gt_service = pd.read_csv('../input/gt_service_name.csv')\n",
    "    acc_get = pd.read_csv('../input/regi_acc_get_data_transform.csv')\n",
    "    call_data = pd.read_csv('../input/regi_call_data_transform.csv')\n",
    "    \n",
    "    calender['cdr_date'] = pd.to_datetime(calender['cdr_date'])\n",
    "    cm_data['cdr_date'] = pd.to_datetime(cm_data['cdr_date'])\n",
    "    acc_get['cdr_date'] = pd.to_datetime(acc_get['cdr_date'])\n",
    "    call_data['cdr_date'] = pd.to_datetime(call_data['cdr_date'])\n",
    "    gt_service['week'] = pd.to_datetime(gt_service['week'])\n",
    "    \n",
    "    print(f\"\\nデータ期間: {call_data['cdr_date'].min()} ~ {call_data['cdr_date'].max()}\")\n",
    "    \n",
    "    return calender, cm_data, gt_service, acc_get, call_data\n",
    "\n",
    "def merge_datasets(calender, cm_data, gt_service, acc_get, call_data):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Step 2: データの統合\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    df = call_data.copy()\n",
    "    df = df.merge(calender, on='cdr_date', how='left')\n",
    "    df = df.merge(cm_data, on='cdr_date', how='left')\n",
    "    df = df.merge(acc_get, on='cdr_date', how='left')\n",
    "    \n",
    "    gt_service_daily = []\n",
    "    for idx, row in gt_service.iterrows():\n",
    "        week_start = row['week']\n",
    "        for i in range(7):\n",
    "            date = week_start + timedelta(days=i)\n",
    "            gt_service_daily.append({'cdr_date': date, 'search_cnt': row['search_cnt']})\n",
    "    \n",
    "    gt_daily = pd.DataFrame(gt_service_daily)\n",
    "    df = df.merge(gt_daily, on='cdr_date', how='left')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_basic_time_features(df):\n",
    "    df = df.copy()\n",
    "    df['year'] = df['cdr_date'].dt.year\n",
    "    df['month'] = df['cdr_date'].dt.month\n",
    "    df['day_of_month'] = df['cdr_date'].dt.day\n",
    "    df['quarter'] = df['cdr_date'].dt.quarter\n",
    "    df['day_of_year'] = df['cdr_date'].dt.dayofyear\n",
    "    df['week_of_year'] = df['cdr_date'].dt.isocalendar().week\n",
    "    df['days_from_start'] = (df['cdr_date'] - df['cdr_date'].min()).dt.days\n",
    "    df['is_month_start'] = (df['day_of_month'] <= 5).astype(int)\n",
    "    df['is_month_end'] = (df['day_of_month'] >= 25).astype(int)\n",
    "    return df\n",
    "\n",
    "def create_lag_features(df, target_col='call_num', lags=[1, 2, 3, 5, 7, 14, 30]):\n",
    "    df = df.copy()\n",
    "    for lag in lags:\n",
    "        df[f'lag_{lag}'] = df[target_col].shift(lag)\n",
    "    return df\n",
    "\n",
    "def create_rolling_features(df, target_col='call_num', windows=[3, 7, 14, 30]):\n",
    "    df = df.copy()\n",
    "    for window in windows:\n",
    "        df[f'ma_{window}'] = df[target_col].shift(1).rolling(window=window, min_periods=1).mean()\n",
    "        df[f'ma_std_{window}'] = df[target_col].shift(1).rolling(window=window, min_periods=1).std()\n",
    "    return df\n",
    "\n",
    "def create_aggregated_features(df):\n",
    "    df = df.copy()\n",
    "    df['cm_7d'] = df['cm_flg'].shift(1).rolling(window=7, min_periods=1).sum()\n",
    "    df['gt_ma_7'] = df['search_cnt'].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "    df['acc_ma_7'] = df['acc_get_cnt'].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "    \n",
    "    df['dow_avg'] = np.nan\n",
    "    for dow in df['dow'].unique():\n",
    "        mask = df['dow'] == dow\n",
    "        df.loc[mask, 'dow_avg'] = df.loc[mask, 'call_num'].shift(1).expanding().mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_acc_get_features(df):\n",
    "    \"\"\"exp16のacc_get特徴量を作成\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Step 7: acc_get特徴量の追加（exp16と同じ）\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    df = df.copy()\n",
    "    df['acc_get_lag7'] = df['acc_get_cnt'].shift(7)\n",
    "    df['acc_get_sum_14d'] = df['acc_get_cnt'].shift(1).rolling(window=14, min_periods=1).sum()\n",
    "    \n",
    "    print(\"\\n作成した特徴量:\")\n",
    "    print(\"  1. acc_get_lag7: 7日前のacc_get_cnt\")\n",
    "    print(\"  2. acc_get_sum_14d: 直近14日間のacc_get_cntの合計\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_regime_change_features(df):\n",
    "    \"\"\"exp15のレジーム変化特徴量を作成\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Step 8: レジーム変化特徴量の作成（exp15から継承）\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    tax_implementation_date = pd.Timestamp('2019-10-01')\n",
    "    rush_deadline = pd.Timestamp('2019-09-30')\n",
    "    \n",
    "    df['days_to_2019_10_01'] = (tax_implementation_date - df['cdr_date']).dt.days\n",
    "    df['is_pre_2019_10_01'] = (df['cdr_date'] < tax_implementation_date).astype(int)\n",
    "    df['is_post_2019_10_01'] = (df['cdr_date'] >= tax_implementation_date).astype(int)\n",
    "    \n",
    "    df['days_to_2019_09_30'] = (rush_deadline - df['cdr_date']).dt.days\n",
    "    df['is_pre_2019_09_30'] = (df['cdr_date'] < rush_deadline).astype(int)\n",
    "    df['is_post_2019_09_30'] = (df['cdr_date'] >= rush_deadline).astype(int)\n",
    "    \n",
    "    rush_start = rush_deadline - pd.Timedelta(days=90)\n",
    "    df['is_rush_period'] = ((df['cdr_date'] >= rush_start) & \n",
    "                            (df['cdr_date'] <= rush_deadline)).astype(int)\n",
    "    \n",
    "    adaptation_end = tax_implementation_date + pd.Timedelta(days=30)\n",
    "    df['is_adaptation_period'] = ((df['cdr_date'] >= tax_implementation_date) & \n",
    "                                   (df['cdr_date'] <= adaptation_end)).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print('データ読み込み・特徴量作成関数を定義しました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# データ準備\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"*\" * 80)\n",
    "print(\"exp20: exp19の最適化パラメータ + exp16のRolling Window Validation\")\n",
    "print(\"*\" * 80)\n",
    "\n",
    "calender, cm_data, gt_service, acc_get, call_data = load_and_preprocess_data()\n",
    "df = merge_datasets(calender, cm_data, gt_service, acc_get, call_data)\n",
    "df = create_basic_time_features(df)\n",
    "df = create_lag_features(df)\n",
    "df = create_rolling_features(df)\n",
    "df = create_aggregated_features(df)\n",
    "df = create_acc_get_features(df)\n",
    "df = create_regime_change_features(df)\n",
    "\n",
    "# 翌日の入電数を目的変数にする\n",
    "df['target_next_day'] = df['call_num'].shift(-1)\n",
    "df = df.dropna(subset=['target_next_day']).reset_index(drop=True)\n",
    "\n",
    "# 平日のみ\n",
    "df_model = df[df['dow'].isin([1, 2, 3, 4, 5])].copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n平日データ数: {len(df_model)}行\")\n",
    "print(f\"期間: {df_model['cdr_date'].min()} ~ {df_model['cdr_date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Rolling Window Validation の設定（exp16と同じ）\n",
    "# ==================================================================================\n",
    "\n",
    "# exp16と同じ特徴量リスト（50個）\n",
    "feature_cols = [\n",
    "    # 基本時系列特徴量\n",
    "    'dow', 'day_of_month', 'month', 'quarter', 'year', \n",
    "    'days_from_start', 'day_of_year', 'week_of_year',\n",
    "    'is_month_start', 'is_month_end',\n",
    "    # カレンダー特徴量\n",
    "    'woy', 'wom', 'day_before_holiday_flag',\n",
    "    # 外部データ\n",
    "    'cm_flg', 'acc_get_cnt', 'search_cnt',\n",
    "    # 集約特徴量\n",
    "    'cm_7d', 'gt_ma_7', 'acc_ma_7', 'dow_avg',\n",
    "    # ラグ特徴量\n",
    "    'lag_1', 'lag_2', 'lag_3', 'lag_5', 'lag_7', 'lag_14', 'lag_30',\n",
    "    # 移動平均特徴量\n",
    "    'ma_3', 'ma_7', 'ma_14', 'ma_30',\n",
    "    'ma_std_3', 'ma_std_7', 'ma_std_14', 'ma_std_30',\n",
    "    # レジーム変化特徴量\n",
    "    'days_to_2019_10_01', 'is_pre_2019_10_01', 'is_post_2019_10_01',\n",
    "    'days_to_2019_09_30', 'is_pre_2019_09_30', 'is_post_2019_09_30',\n",
    "    'is_rush_period', 'is_adaptation_period',\n",
    "    # acc_get特徴量\n",
    "    'acc_get_lag7', 'acc_get_sum_14d'\n",
    "]\n",
    "\n",
    "print(f\"\\n使用する特徴量数: {len(feature_cols)}\")\n",
    "\n",
    "# Rolling Window設定（exp16と同じ）\n",
    "test_window_days = 60\n",
    "step_days = 30\n",
    "\n",
    "# 欠損値を除去\n",
    "df_clean = df_model.dropna(subset=feature_cols + ['target_next_day']).copy()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Rolling Window Validation 設定（exp16と同じ）\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"テストウィンドウ: {test_window_days}日（約2ヶ月）\")\n",
    "print(f\"ステップ: {step_days}日（約1ヶ月）\")\n",
    "print(f\"\\n使用データ: {len(df_clean)}行\")\n",
    "\n",
    "# Rolling Window の分割点を計算\n",
    "min_date = df_clean['cdr_date'].min()\n",
    "max_date = df_clean['cdr_date'].max()\n",
    "min_train_days = 90\n",
    "\n",
    "windows = []\n",
    "current_test_end = max_date\n",
    "\n",
    "while True:\n",
    "    test_start = current_test_end - pd.Timedelta(days=test_window_days)\n",
    "    train_end = test_start - pd.Timedelta(days=1)\n",
    "    \n",
    "    if (train_end - min_date).days < min_train_days:\n",
    "        break\n",
    "    \n",
    "    windows.append({\n",
    "        'train_start': min_date,\n",
    "        'train_end': train_end,\n",
    "        'test_start': test_start,\n",
    "        'test_end': current_test_end\n",
    "    })\n",
    "    \n",
    "    current_test_end = test_start - pd.Timedelta(days=1)\n",
    "\n",
    "windows = windows[::-1]\n",
    "\n",
    "print(f\"\\n作成されたウィンドウ数: {len(windows)}\")\n",
    "print(\"\\nウィンドウ詳細:\")\n",
    "for i, w in enumerate(windows):\n",
    "    print(f\"\\nWindow {i+1}:\")\n",
    "    print(f\"  Train: {w['train_start'].strftime('%Y-%m-%d')} ~ {w['train_end'].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  Test : {w['test_start'].strftime('%Y-%m-%d')} ~ {w['test_end'].strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# モデル学習と評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 評価関数\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def calculate_wape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true)) * 100\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    return {\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'WAPE': calculate_wape(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "print('評価関数を定義しました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Rolling Window Validation の実行（exp19の最適化パラメータを使用）\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "all_window_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Rolling Window Validation 実行（exp19最適化パラメータ）\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for window_idx, window in enumerate(windows):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Window {window_idx + 1}/{len(windows)}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Train: {window['train_start'].strftime('%Y-%m-%d')} ~ {window['train_end'].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Test : {window['test_start'].strftime('%Y-%m-%d')} ~ {window['test_end'].strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # データ分割\n",
    "    train_mask = (df_clean['cdr_date'] >= window['train_start']) & (df_clean['cdr_date'] <= window['train_end'])\n",
    "    test_mask = (df_clean['cdr_date'] >= window['test_start']) & (df_clean['cdr_date'] <= window['test_end'])\n",
    "    \n",
    "    X_train = df_clean.loc[train_mask, feature_cols]\n",
    "    y_train = df_clean.loc[train_mask, 'target_next_day']\n",
    "    X_test = df_clean.loc[test_mask, feature_cols]\n",
    "    y_test = df_clean.loc[test_mask, 'target_next_day']\n",
    "    \n",
    "    print(f\"\\nTrain: {len(X_train)}件, Test: {len(X_test)}件\")\n",
    "    \n",
    "    # 各モデルの訓練と評価\n",
    "    window_models = {}\n",
    "    window_predictions = {}\n",
    "    \n",
    "    # 1. HistGradientBoosting（exp19パラメータ）\n",
    "    print(\"\\n[1/5] HistGradientBoosting（exp19最適化）...\")\n",
    "    hist_model = HistGradientBoostingRegressor(**OPTIMIZED_PARAMS_EXP19['HistGradientBoosting'], random_state=42)\n",
    "    hist_model.fit(X_train, y_train)\n",
    "    hist_pred = hist_model.predict(X_test)\n",
    "    hist_metrics = evaluate_model(y_test, hist_pred)\n",
    "    print(f\"  MAE: {hist_metrics['MAE']:.2f}, RMSE: {hist_metrics['RMSE']:.2f}, R2: {hist_metrics['R2']:.3f}\")\n",
    "    window_models['HistGradientBoosting'] = hist_model\n",
    "    window_predictions['HistGradientBoosting'] = hist_pred\n",
    "    all_window_results.append({'window': window_idx+1, 'model': 'HistGradientBoosting', **hist_metrics})\n",
    "    \n",
    "    # 2. ExtraTrees（exp19パラメータ）\n",
    "    print(\"[2/5] ExtraTrees（exp19最適化）...\")\n",
    "    extra_model = ExtraTreesRegressor(**OPTIMIZED_PARAMS_EXP19['ExtraTrees'], random_state=42, n_jobs=-1)\n",
    "    extra_model.fit(X_train, y_train)\n",
    "    extra_pred = extra_model.predict(X_test)\n",
    "    extra_metrics = evaluate_model(y_test, extra_pred)\n",
    "    print(f\"  MAE: {extra_metrics['MAE']:.2f}, RMSE: {extra_metrics['RMSE']:.2f}, R2: {extra_metrics['R2']:.3f}\")\n",
    "    window_models['ExtraTrees'] = extra_model\n",
    "    window_predictions['ExtraTrees'] = extra_pred\n",
    "    all_window_results.append({'window': window_idx+1, 'model': 'ExtraTrees', **extra_metrics})\n",
    "    \n",
    "    # 3. CatBoost（exp19パラメータ）\n",
    "    print(\"[3/5] CatBoost（exp19最適化）...\")\n",
    "    catboost_model = CatBoostRegressor(**OPTIMIZED_PARAMS_EXP19['CatBoost'], random_state=42, verbose=0)\n",
    "    catboost_model.fit(X_train, y_train)\n",
    "    catboost_pred = catboost_model.predict(X_test)\n",
    "    catboost_metrics = evaluate_model(y_test, catboost_pred)\n",
    "    print(f\"  MAE: {catboost_metrics['MAE']:.2f}, RMSE: {catboost_metrics['RMSE']:.2f}, R2: {catboost_metrics['R2']:.3f}\")\n",
    "    window_models['CatBoost'] = catboost_model\n",
    "    window_predictions['CatBoost'] = catboost_pred\n",
    "    all_window_results.append({'window': window_idx+1, 'model': 'CatBoost', **catboost_metrics})\n",
    "    \n",
    "    # 4. Ridge（exp19パラメータ）\n",
    "    print(\"[4/5] Ridge（exp19最適化）...\")\n",
    "    ridge_model = Ridge(**OPTIMIZED_PARAMS_EXP19['Ridge'], random_state=42)\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    ridge_pred = ridge_model.predict(X_test)\n",
    "    ridge_metrics = evaluate_model(y_test, ridge_pred)\n",
    "    print(f\"  MAE: {ridge_metrics['MAE']:.2f}, RMSE: {ridge_metrics['RMSE']:.2f}, R2: {ridge_metrics['R2']:.3f}\")\n",
    "    window_models['Ridge'] = ridge_model\n",
    "    window_predictions['Ridge'] = ridge_pred\n",
    "    all_window_results.append({'window': window_idx+1, 'model': 'Ridge', **ridge_metrics})\n",
    "    \n",
    "    # 5. Weighted Ensemble A（各ウィンドウで重み最適化）\n",
    "    print(\"[5/5] WeightedEnsemble_A（Testセットで重み最適化）...\")\n",
    "    \n",
    "    def optimize_weights(predictions_dict, y_true, model_names):\n",
    "        preds_matrix = np.column_stack([predictions_dict[name] for name in model_names])\n",
    "        \n",
    "        def objective(weights):\n",
    "            ensemble_pred = preds_matrix @ weights\n",
    "            return mean_absolute_error(y_true, ensemble_pred)\n",
    "        \n",
    "        constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}\n",
    "        bounds = [(0, 1) for _ in range(len(model_names))]\n",
    "        initial_weights = np.ones(len(model_names)) / len(model_names)\n",
    "        \n",
    "        result = minimize(objective, initial_weights, method='SLSQP',\n",
    "                         bounds=bounds, constraints=constraints)\n",
    "        return result.x\n",
    "    \n",
    "    pattern_a_models = ['Ridge', 'CatBoost', 'ExtraTrees', 'HistGradientBoosting']\n",
    "    weights_a = optimize_weights(window_predictions, y_test, pattern_a_models)\n",
    "    \n",
    "    weightA_pred = np.column_stack([window_predictions[name] for name in pattern_a_models]) @ weights_a\n",
    "    weightA_metrics = evaluate_model(y_test, weightA_pred)\n",
    "    print(f\"  MAE: {weightA_metrics['MAE']:.2f}, RMSE: {weightA_metrics['RMSE']:.2f}, R2: {weightA_metrics['R2']:.3f}\")\n",
    "    all_window_results.append({'window': window_idx+1, 'model': 'WeightedEnsemble_A', **weightA_metrics})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Rolling Window Validation 完了\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# exp16との比較分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# exp16の結果を読み込んで比較\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "exp20_results_df = pd.DataFrame(all_window_results)\n",
    "\n",
    "# exp16の結果を読み込み\n",
    "exp16_results_path = '../output/exp16/rolling_window_results.csv'\n",
    "if os.path.exists(exp16_results_path):\n",
    "    exp16_results_df = pd.read_csv(exp16_results_path)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"exp16 vs exp20 比較（Optunaパラメータ最適化の効果を検証）\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 全ウィンドウで比較\n",
    "    models = exp20_results_df['model'].unique()\n",
    "    \n",
    "    for model in models:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"{model}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        exp16_model = exp16_results_df[exp16_results_df['model'] == model]\n",
    "        exp20_model = exp20_results_df[exp20_results_df['model'] == model]\n",
    "        \n",
    "        if len(exp16_model) > 0 and len(exp20_model) > 0:\n",
    "            exp16_avg_mae = exp16_model['MAE'].mean()\n",
    "            exp20_avg_mae = exp20_model['MAE'].mean()\n",
    "            improvement = exp16_avg_mae - exp20_avg_mae\n",
    "            improvement_pct = (improvement / exp16_avg_mae) * 100\n",
    "            \n",
    "            status = \"✅ 改善\" if improvement > 0 else \"❌ 悪化\"\n",
    "            print(f\"\\n平均MAE:\")\n",
    "            print(f\"  exp16 (exp05パラメータ): {exp16_avg_mae:.2f}\")\n",
    "            print(f\"  exp20 (exp19最適化): {exp20_avg_mae:.2f}\")\n",
    "            print(f\"  差分: {improvement:+.2f} ({improvement_pct:+.1f}%) {status}\")\n",
    "            \n",
    "            # ウィンドウごとの詳細\n",
    "            print(f\"\\nウィンドウごとの比較:\")\n",
    "            for window_num in sorted(exp20_model['window'].unique()):\n",
    "                exp16_mae = exp16_model[exp16_model['window'] == window_num]['MAE'].values\n",
    "                exp20_mae = exp20_model[exp20_model['window'] == window_num]['MAE'].values\n",
    "                \n",
    "                if len(exp16_mae) > 0 and len(exp20_mae) > 0:\n",
    "                    win_improvement = exp16_mae[0] - exp20_mae[0]\n",
    "                    win_status = \"✅\" if win_improvement > 0 else \"❌\"\n",
    "                    print(f\"  Window{window_num}: exp16={exp16_mae[0]:.2f} → exp20={exp20_mae[0]:.2f} ({win_improvement:+.2f}) {win_status}\")\n",
    "else:\n",
    "    print(\"\\nexp16の結果ファイルが見つかりません。\")\n",
    "    print(\"exp20の結果のみを表示します。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 結果の集計\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"exp20 全ウィンドウの結果\")\n",
    "print(\"=\" * 80)\n",
    "print(exp20_results_df.to_string(index=False))\n",
    "\n",
    "# モデルごとの平均スコア\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"モデルごとの平均スコア（全ウィンドウ）\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "average_scores = exp20_results_df.groupby('model')[['MAE', 'RMSE', 'R2', 'WAPE']].mean()\n",
    "average_scores = average_scores.sort_values('MAE')\n",
    "print(average_scores.to_string())\n",
    "\n",
    "# 標準偏差\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"モデルごとの標準偏差（スコアの安定性）\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "std_scores = exp20_results_df.groupby('model')[['MAE', 'RMSE', 'R2', 'WAPE']].std()\n",
    "std_scores = std_scores.sort_values('MAE')\n",
    "print(std_scores.to_string())\n",
    "\n",
    "# CSV保存\n",
    "output_dir = '../output/exp20'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "exp20_results_df.to_csv(f'{output_dir}/rolling_window_results.csv', index=False)\n",
    "average_scores.to_csv(f'{output_dir}/average_scores.csv')\n",
    "std_scores.to_csv(f'{output_dir}/std_scores.csv')\n",
    "\n",
    "print(f\"\\n結果を保存しました: {output_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 可視化: exp16 vs exp20 比較\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if os.path.exists(exp16_results_path):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    fig.suptitle('exp16 (exp05 params) vs exp20 (exp19 Optuna-optimized params): MAE Comparison', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    models_to_compare = ['HistGradientBoosting', 'ExtraTrees', 'CatBoost', 'Ridge', 'WeightedEnsemble_A']\n",
    "    \n",
    "    for idx, model in enumerate(models_to_compare):\n",
    "        row = idx // 3\n",
    "        col = idx % 3\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        exp16_model_data = exp16_results_df[exp16_results_df['model'] == model]\n",
    "        exp20_model_data = exp20_results_df[exp20_results_df['model'] == model]\n",
    "        \n",
    "        ax.plot(exp16_model_data['window'], exp16_model_data['MAE'], \n",
    "                marker='o', label='exp16 (exp05 params)', linewidth=2, color='steelblue')\n",
    "        ax.plot(exp20_model_data['window'], exp20_model_data['MAE'], \n",
    "                marker='s', label='exp20 (exp19 Optuna)', linewidth=2, color='coral')\n",
    "        \n",
    "        # 平均MAEを表示\n",
    "        exp16_avg = exp16_model_data['MAE'].mean()\n",
    "        exp20_avg = exp20_model_data['MAE'].mean()\n",
    "        improvement = exp16_avg - exp20_avg\n",
    "        \n",
    "        ax.axhline(y=exp16_avg, color='steelblue', linestyle='--', alpha=0.5)\n",
    "        ax.axhline(y=exp20_avg, color='coral', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        ax.set_xlabel('Window', fontsize=11)\n",
    "        ax.set_ylabel('MAE', fontsize=11)\n",
    "        ax.set_title(f'{model}\\nΔMAE: {improvement:+.2f}', fontsize=11, fontweight='bold')\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.set_xticks(range(1, len(windows) + 1))\n",
    "    \n",
    "    # 空の6番目のサブプロットを削除\n",
    "    fig.delaxes(axes[1, 2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/exp16_vs_exp20_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n可視化を保存しました: {output_dir}/exp16_vs_exp20_comparison.png\")\n",
    "else:\n",
    "    print(\"\\nexp16の結果が見つからないため、比較可視化をスキップします。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**exp20: exp19の最適化パラメータをRolling Window Validationで評価**\n",
    "\n",
    "### 目的:\n",
    "- exp19でOptunaにより最適化されたパラメータを使用\n",
    "- exp16と同じRolling Window Validation（8ウィンドウ）で評価\n",
    "- 検証方法を統一して公正な比較を実現\n",
    "\n",
    "### ベースライン:\n",
    "- exp16 (WeightedEnsemble_A MAE=48.98)\n",
    "- exp05で最適化されたパラメータを使用\n",
    "\n",
    "### exp20の最適化:\n",
    "- exp19でOptunaにより再最適化（各モデル100 trials）\n",
    "- exp16の特徴量セット（50個）に対して最適化\n",
    "\n",
    "### 検証結果:\n",
    "- exp16との比較でMAEの改善/悪化を確認\n",
    "- Optunaパラメータ最適化の効果を定量化\n",
    "\n",
    "### 出力ファイル:\n",
    "1. `rolling_window_results.csv` - 全ウィンドウの詳細結果\n",
    "2. `average_scores.csv` - モデルごとの平均スコア\n",
    "3. `std_scores.csv` - モデルごとの標準偏差（安定性）\n",
    "4. `exp16_vs_exp20_comparison.png` - 可視化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
