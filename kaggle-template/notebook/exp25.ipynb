{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# exp25: Window 1-5 CV + Window 6 Holdout + Optuna\n",
    "\n",
    "**目的**:\n",
    "- Window 1-5 で Cross Validation（ハイパーパラメータ最適化）\n",
    "- Window 6 を Holdout として最終評価\n",
    "- データリーケージを防止した正しい時系列評価\n",
    "\n",
    "**構成**:\n",
    "```\n",
    "Window 1: Train 2017-11 ~ 2018-10 → Test 2018-11 ~ 2018-12\n",
    "Window 2: Train 2017-11 ~ 2018-12 → Test 2019-01 ~ 2019-02\n",
    "Window 3: Train 2017-11 ~ 2019-02 → Test 2019-03 ~ 2019-04\n",
    "Window 4: Train 2017-11 ~ 2019-04 → Test 2019-05 ~ 2019-06\n",
    "Window 5: Train 2017-11 ~ 2019-06 → Test 2019-07 ~ 2019-08  ← CV用\n",
    "-----------------------------------------------------------\n",
    "Window 6: Train 2017-11 ~ 2019-08 → Test 2019-09 ~ 2019-10  ← Holdout（最終評価）\n",
    "```\n",
    "\n",
    "**重要**: Window 6 は Optuna 最適化には使用しない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "# 出力ディレクトリ\n",
    "output_dir = '../output/exp25'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"exp25: Window 1-5 CV + Window 6 Holdout + Optuna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# データの読み込みと特徴量作成\n",
    "# ==================================================================================\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    calender = pd.read_csv('../input/calender_data.csv')\n",
    "    cm_data = pd.read_csv('../input/cm_data.csv')\n",
    "    gt_service = pd.read_csv('../input/gt_service_name.csv')\n",
    "    acc_get = pd.read_csv('../input/regi_acc_get_data_transform.csv')\n",
    "    call_data = pd.read_csv('../input/regi_call_data_transform.csv')\n",
    "    \n",
    "    calender['cdr_date'] = pd.to_datetime(calender['cdr_date'])\n",
    "    cm_data['cdr_date'] = pd.to_datetime(cm_data['cdr_date'])\n",
    "    acc_get['cdr_date'] = pd.to_datetime(acc_get['cdr_date'])\n",
    "    call_data['cdr_date'] = pd.to_datetime(call_data['cdr_date'])\n",
    "    gt_service['week'] = pd.to_datetime(gt_service['week'])\n",
    "    \n",
    "    return calender, cm_data, gt_service, acc_get, call_data\n",
    "\n",
    "def merge_datasets(calender, cm_data, gt_service, acc_get, call_data):\n",
    "    df = call_data.copy()\n",
    "    df = df.merge(calender, on='cdr_date', how='left')\n",
    "    df = df.merge(cm_data, on='cdr_date', how='left')\n",
    "    df = df.merge(acc_get, on='cdr_date', how='left')\n",
    "    \n",
    "    gt_service_daily = []\n",
    "    for idx, row in gt_service.iterrows():\n",
    "        week_start = row['week']\n",
    "        for i in range(7):\n",
    "            date = week_start + timedelta(days=i)\n",
    "            gt_service_daily.append({'cdr_date': date, 'search_cnt': row['search_cnt']})\n",
    "    \n",
    "    gt_daily = pd.DataFrame(gt_service_daily)\n",
    "    df = df.merge(gt_daily, on='cdr_date', how='left')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_basic_time_features(df):\n",
    "    df = df.copy()\n",
    "    df['year'] = df['cdr_date'].dt.year\n",
    "    df['month'] = df['cdr_date'].dt.month\n",
    "    df['day_of_month'] = df['cdr_date'].dt.day\n",
    "    df['quarter'] = df['cdr_date'].dt.quarter\n",
    "    df['day_of_year'] = df['cdr_date'].dt.dayofyear\n",
    "    df['week_of_year'] = df['cdr_date'].dt.isocalendar().week\n",
    "    df['days_from_start'] = (df['cdr_date'] - df['cdr_date'].min()).dt.days\n",
    "    df['is_month_start'] = (df['day_of_month'] <= 5).astype(int)\n",
    "    df['is_month_end'] = (df['day_of_month'] >= 25).astype(int)\n",
    "    return df\n",
    "\n",
    "def create_lag_features(df, target_col='call_num', lags=[1, 2, 3, 5, 7, 14, 30]):\n",
    "    df = df.copy()\n",
    "    for lag in lags:\n",
    "        df[f'lag_{lag}'] = df[target_col].shift(lag)\n",
    "    return df\n",
    "\n",
    "def create_rolling_features(df, target_col='call_num', windows=[3, 7, 14, 30]):\n",
    "    df = df.copy()\n",
    "    for window in windows:\n",
    "        df[f'ma_{window}'] = df[target_col].shift(1).rolling(window=window, min_periods=1).mean()\n",
    "        df[f'ma_std_{window}'] = df[target_col].shift(1).rolling(window=window, min_periods=1).std()\n",
    "    return df\n",
    "\n",
    "def create_aggregated_features(df):\n",
    "    df = df.copy()\n",
    "    df['cm_7d'] = df['cm_flg'].shift(1).rolling(window=7, min_periods=1).sum()\n",
    "    df['gt_ma_7'] = df['search_cnt'].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "    df['acc_ma_7'] = df['acc_get_cnt'].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "    \n",
    "    df['dow_avg'] = np.nan\n",
    "    for dow in df['dow'].unique():\n",
    "        mask = df['dow'] == dow\n",
    "        df.loc[mask, 'dow_avg'] = df.loc[mask, 'call_num'].shift(1).expanding().mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_regime_change_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    tax_implementation_date = pd.Timestamp('2019-10-01')\n",
    "    rush_deadline = pd.Timestamp('2019-09-30')\n",
    "    \n",
    "    df['days_to_2019_10_01'] = (tax_implementation_date - df['cdr_date']).dt.days\n",
    "    df['is_post_2019_10_01'] = (df['cdr_date'] >= tax_implementation_date).astype(int)\n",
    "    df['is_post_2019_09_30'] = (df['cdr_date'] >= rush_deadline).astype(int)\n",
    "    \n",
    "    rush_start = rush_deadline - pd.Timedelta(days=90)\n",
    "    df['is_rush_period'] = ((df['cdr_date'] >= rush_start) & \n",
    "                            (df['cdr_date'] <= rush_deadline)).astype(int)\n",
    "    \n",
    "    adaptation_end = tax_implementation_date + pd.Timedelta(days=30)\n",
    "    df['is_adaptation_period'] = ((df['cdr_date'] >= tax_implementation_date) & \n",
    "                                   (df['cdr_date'] <= adaptation_end)).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print('データ読み込み・特徴量作成関数を定義しました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# データ準備\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"*\" * 80)\n",
    "print(\"データ準備\")\n",
    "print(\"*\" * 80)\n",
    "\n",
    "calender, cm_data, gt_service, acc_get, call_data = load_and_preprocess_data()\n",
    "df = merge_datasets(calender, cm_data, gt_service, acc_get, call_data)\n",
    "df = create_basic_time_features(df)\n",
    "df = create_lag_features(df)\n",
    "df = create_rolling_features(df)\n",
    "df = create_aggregated_features(df)\n",
    "df = create_regime_change_features(df)\n",
    "\n",
    "# 翌日の入電数を目的変数にする\n",
    "df['target_next_day'] = df['call_num'].shift(-1)\n",
    "df = df.dropna(subset=['target_next_day']).reset_index(drop=True)\n",
    "\n",
    "# 平日のみ\n",
    "df_model = df[df['dow'].isin([1, 2, 3, 4, 5])].copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n平日データ数: {len(df_model)}行\")\n",
    "print(f\"期間: {df_model['cdr_date'].min()} ~ {df_model['cdr_date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 特徴量（37個）\n",
    "# ==================================================================================\n",
    "\n",
    "feature_cols = [\n",
    "    # 基本時系列特徴量\n",
    "    'dow', 'day_of_month', 'year', \n",
    "    'day_of_year', 'week_of_year',\n",
    "    'is_month_start', 'is_month_end',\n",
    "    # カレンダー特徴量\n",
    "    'day_before_holiday_flag',\n",
    "    # 外部データ\n",
    "    'cm_flg', 'acc_get_cnt', 'search_cnt',\n",
    "    # 集約特徴量\n",
    "    'cm_7d', 'gt_ma_7', 'acc_ma_7', 'dow_avg',\n",
    "    # ラグ特徴量\n",
    "    'lag_1', 'lag_2', 'lag_3', 'lag_5', 'lag_7', 'lag_14', 'lag_30',\n",
    "    # 移動平均特徴量\n",
    "    'ma_3', 'ma_7', 'ma_30',\n",
    "    'ma_std_3', 'ma_std_7', 'ma_std_30',\n",
    "    # レジーム変化特徴量\n",
    "    'days_to_2019_10_01', 'is_post_2019_10_01',\n",
    "    'is_post_2019_09_30',\n",
    "    'is_rush_period', 'is_adaptation_period',\n",
    "]\n",
    "\n",
    "print(f\"使用する特徴量数: {len(feature_cols)}\")\n",
    "\n",
    "# 欠損値を除去\n",
    "df_clean = df_model.dropna(subset=feature_cols + ['target_next_day']).copy()\n",
    "print(f\"欠損値除去後: {len(df_clean)}行\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Window設定: Window 1-5 = CV, Window 6 = Holdout\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Window設定: Window 1-5 (CV) + Window 6 (Holdout)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "train_months = 12\n",
    "test_months = 2\n",
    "n_cv_windows = 5  # CV用\n",
    "n_holdout_window = 6  # Holdout\n",
    "\n",
    "# ウィンドウを生成\n",
    "first_test_start = pd.Timestamp('2018-11-01')\n",
    "\n",
    "all_windows = []\n",
    "for i in range(n_holdout_window):\n",
    "    test_start = first_test_start + pd.DateOffset(months=i * test_months)\n",
    "    test_end = test_start + pd.DateOffset(months=test_months) - pd.Timedelta(days=1)\n",
    "    train_start = test_start - pd.DateOffset(months=train_months)\n",
    "    train_end = test_start - pd.Timedelta(days=1)\n",
    "    \n",
    "    all_windows.append({\n",
    "        'window': i + 1,\n",
    "        'train_start': train_start,\n",
    "        'train_end': train_end,\n",
    "        'test_start': test_start,\n",
    "        'test_end': test_end\n",
    "    })\n",
    "\n",
    "# CV用とHoldout用に分割\n",
    "cv_windows = all_windows[:n_cv_windows]  # Window 1-5\n",
    "holdout_window = all_windows[n_cv_windows]  # Window 6\n",
    "\n",
    "print(\"\\n【CV用 Window 1-5】\")\n",
    "for w in cv_windows:\n",
    "    print(f\"  Window {w['window']}: Train {w['train_start'].strftime('%Y-%m-%d')} ~ {w['train_end'].strftime('%Y-%m-%d')} | Test {w['test_start'].strftime('%Y-%m-%d')} ~ {w['test_end'].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "print(\"\\n【Holdout Window 6】（Optunaには使用しない）\")\n",
    "print(f\"  Window {holdout_window['window']}: Train {holdout_window['train_start'].strftime('%Y-%m-%d')} ~ {holdout_window['train_end'].strftime('%Y-%m-%d')} | Test {holdout_window['test_start'].strftime('%Y-%m-%d')} ~ {holdout_window['test_end'].strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 評価関数\n",
    "# ==================================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def calculate_wape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true)) * 100\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    return {\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'WAPE': calculate_wape(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "print('評価関数を定義しました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# CV用データ取得関数（リーク防止）\n",
    "# ==================================================================================\n",
    "\n",
    "def get_cv_data(df, cv_windows, feature_cols):\n",
    "    \"\"\"Window 1-5 のCV用データを取得\"\"\"\n",
    "    cv_data = []\n",
    "    \n",
    "    for w in cv_windows:\n",
    "        train_mask = (df['cdr_date'] >= w['train_start']) & (df['cdr_date'] <= w['train_end'])\n",
    "        test_mask = (df['cdr_date'] >= w['test_start']) & (df['cdr_date'] <= w['test_end'])\n",
    "        \n",
    "        train_df = df[train_mask].copy()\n",
    "        test_df = df[test_mask].copy()\n",
    "        \n",
    "        if len(train_df) == 0 or len(test_df) == 0:\n",
    "            continue\n",
    "        \n",
    "        X_train = train_df[feature_cols]\n",
    "        y_train = train_df['target_next_day']\n",
    "        X_test = test_df[feature_cols]\n",
    "        y_test = test_df['target_next_day']\n",
    "        \n",
    "        cv_data.append({\n",
    "            'window': w['window'],\n",
    "            'X_train': X_train,\n",
    "            'y_train': y_train,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test\n",
    "        })\n",
    "    \n",
    "    return cv_data\n",
    "\n",
    "def get_holdout_data(df, holdout_window, feature_cols):\n",
    "    \"\"\"Window 6 のHoldout用データを取得\"\"\"\n",
    "    train_mask = (df['cdr_date'] >= holdout_window['train_start']) & (df['cdr_date'] <= holdout_window['train_end'])\n",
    "    test_mask = (df['cdr_date'] >= holdout_window['test_start']) & (df['cdr_date'] <= holdout_window['test_end'])\n",
    "    \n",
    "    train_df = df[train_mask].copy()\n",
    "    test_df = df[test_mask].copy()\n",
    "    \n",
    "    X_train = train_df[feature_cols]\n",
    "    y_train = train_df['target_next_day']\n",
    "    X_test = test_df[feature_cols]\n",
    "    y_test = test_df['target_next_day']\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# CV用データ取得\n",
    "cv_data = get_cv_data(df_clean, cv_windows, feature_cols)\n",
    "print(f\"CV用データ: {len(cv_data)} windows\")\n",
    "for d in cv_data:\n",
    "    print(f\"  Window {d['window']}: Train {len(d['X_train'])}件, Test {len(d['X_test'])}件\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "# Optuna最適化（Window 1-5 CVで評価）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Optuna最適化: Ridge\n",
    "# ==================================================================================\n",
    "\n",
    "import optuna\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def objective_ridge(trial):\n",
    "    \"\"\"Window 1-5 の平均MAEを最小化\"\"\"\n",
    "    alpha = trial.suggest_float('alpha', 0.001, 100.0, log=True)\n",
    "    \n",
    "    mae_scores = []\n",
    "    for d in cv_data:\n",
    "        model = Ridge(alpha=alpha, random_state=42)\n",
    "        model.fit(d['X_train'], d['y_train'])\n",
    "        pred = model.predict(d['X_test'])\n",
    "        mae = mean_absolute_error(d['y_test'], pred)\n",
    "        mae_scores.append(mae)\n",
    "    \n",
    "    return np.mean(mae_scores)\n",
    "\n",
    "print(\"Ridge最適化開始（Window 1-5 CVで評価）\")\n",
    "study_ridge = optuna.create_study(direction='minimize', study_name='Ridge')\n",
    "study_ridge.optimize(objective_ridge, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nRidge最適パラメータ: {study_ridge.best_params}\")\n",
    "print(f\"Ridge最良CV MAE: {study_ridge.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Optuna最適化: ExtraTrees\n",
    "# ==================================================================================\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "def objective_extratrees(trial):\n",
    "    \"\"\"Window 1-5 の平均MAEを最小化\"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    mae_scores = []\n",
    "    for d in cv_data:\n",
    "        model = ExtraTreesRegressor(**params)\n",
    "        model.fit(d['X_train'], d['y_train'])\n",
    "        pred = model.predict(d['X_test'])\n",
    "        mae = mean_absolute_error(d['y_test'], pred)\n",
    "        mae_scores.append(mae)\n",
    "    \n",
    "    return np.mean(mae_scores)\n",
    "\n",
    "print(\"ExtraTrees最適化開始（Window 1-5 CVで評価）\")\n",
    "study_extra = optuna.create_study(direction='minimize', study_name='ExtraTrees')\n",
    "study_extra.optimize(objective_extratrees, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nExtraTrees最適パラメータ: {study_extra.best_params}\")\n",
    "print(f\"ExtraTrees最良CV MAE: {study_extra.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Optuna最適化: HistGradientBoosting\n",
    "# ==================================================================================\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "def objective_hist(trial):\n",
    "    \"\"\"Window 1-5 の平均MAEを最小化\"\"\"\n",
    "    params = {\n",
    "        'max_iter': trial.suggest_int('max_iter', 50, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 30),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 50),\n",
    "        'l2_regularization': trial.suggest_float('l2_regularization', 0.0001, 10.0, log=True),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    mae_scores = []\n",
    "    for d in cv_data:\n",
    "        model = HistGradientBoostingRegressor(**params)\n",
    "        model.fit(d['X_train'], d['y_train'])\n",
    "        pred = model.predict(d['X_test'])\n",
    "        mae = mean_absolute_error(d['y_test'], pred)\n",
    "        mae_scores.append(mae)\n",
    "    \n",
    "    return np.mean(mae_scores)\n",
    "\n",
    "print(\"HistGradientBoosting最適化開始（Window 1-5 CVで評価）\")\n",
    "study_hist = optuna.create_study(direction='minimize', study_name='HistGradientBoosting')\n",
    "study_hist.optimize(objective_hist, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nHistGradientBoosting最適パラメータ: {study_hist.best_params}\")\n",
    "print(f\"HistGradientBoosting最良CV MAE: {study_hist.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Optuna最適化: CatBoost\n",
    "# ==================================================================================\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    \"\"\"Window 1-5 の平均MAEを最小化\"\"\"\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 2000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.01, 10.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'random_state': 42,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    \n",
    "    mae_scores = []\n",
    "    for d in cv_data:\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(d['X_train'], d['y_train'])\n",
    "        pred = model.predict(d['X_test'])\n",
    "        mae = mean_absolute_error(d['y_test'], pred)\n",
    "        mae_scores.append(mae)\n",
    "    \n",
    "    return np.mean(mae_scores)\n",
    "\n",
    "print(\"CatBoost最適化開始（Window 1-5 CVで評価）\")\n",
    "study_catboost = optuna.create_study(direction='minimize', study_name='CatBoost')\n",
    "study_catboost.optimize(objective_catboost, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nCatBoost最適パラメータ: {study_catboost.best_params}\")\n",
    "print(f\"CatBoost最良CV MAE: {study_catboost.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 最適化結果まとめ\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Optuna最適化結果まとめ（Window 1-5 CVで最適化）\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_params = {\n",
    "    'Ridge': study_ridge.best_params,\n",
    "    'ExtraTrees': study_extra.best_params,\n",
    "    'HistGradientBoosting': study_hist.best_params,\n",
    "    'CatBoost': study_catboost.best_params\n",
    "}\n",
    "\n",
    "cv_scores = {\n",
    "    'Ridge': study_ridge.best_value,\n",
    "    'ExtraTrees': study_extra.best_value,\n",
    "    'HistGradientBoosting': study_hist.best_value,\n",
    "    'CatBoost': study_catboost.best_value\n",
    "}\n",
    "\n",
    "for model_name, params in best_params.items():\n",
    "    print(f\"\\n{model_name} (CV MAE: {cv_scores[model_name]:.4f}):\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# パラメータを保存\n",
    "import json\n",
    "with open(f'{output_dir}/best_params.json', 'w') as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "print(f\"\\n保存: {output_dir}/best_params.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "# Window 6 Holdout 最終評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Window 6 Holdout 最終評価\n",
    "# ==================================================================================\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Window 6 Holdout 最終評価（Optunaで最適化したパラメータを使用）\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Holdoutデータ取得\n",
    "X_train_ho, y_train_ho, X_test_ho, y_test_ho = get_holdout_data(df_clean, holdout_window, feature_cols)\n",
    "print(f\"\\nHoldout Train: {len(X_train_ho)}件\")\n",
    "print(f\"Holdout Test: {len(X_test_ho)}件\")\n",
    "print(f\"Test期間: {holdout_window['test_start'].strftime('%Y-%m-%d')} ~ {holdout_window['test_end'].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "holdout_results = []\n",
    "predictions_ho = {}\n",
    "\n",
    "# 1. Ridge\n",
    "ridge = Ridge(**best_params['Ridge'], random_state=42)\n",
    "ridge.fit(X_train_ho, y_train_ho)\n",
    "ridge_pred = ridge.predict(X_test_ho)\n",
    "ridge_metrics = evaluate_model(y_test_ho, ridge_pred)\n",
    "predictions_ho['Ridge'] = ridge_pred\n",
    "holdout_results.append({'model': 'Ridge', **ridge_metrics})\n",
    "print(f\"\\nRidge Holdout MAE: {ridge_metrics['MAE']:.2f}\")\n",
    "\n",
    "# 2. ExtraTrees\n",
    "extra_params = {k: v for k, v in best_params['ExtraTrees'].items()}\n",
    "extra = ExtraTreesRegressor(**extra_params, random_state=42, n_jobs=-1)\n",
    "extra.fit(X_train_ho, y_train_ho)\n",
    "extra_pred = extra.predict(X_test_ho)\n",
    "extra_metrics = evaluate_model(y_test_ho, extra_pred)\n",
    "predictions_ho['ExtraTrees'] = extra_pred\n",
    "holdout_results.append({'model': 'ExtraTrees', **extra_metrics})\n",
    "print(f\"ExtraTrees Holdout MAE: {extra_metrics['MAE']:.2f}\")\n",
    "\n",
    "# 3. HistGradientBoosting\n",
    "hist = HistGradientBoostingRegressor(**best_params['HistGradientBoosting'], random_state=42)\n",
    "hist.fit(X_train_ho, y_train_ho)\n",
    "hist_pred = hist.predict(X_test_ho)\n",
    "hist_metrics = evaluate_model(y_test_ho, hist_pred)\n",
    "predictions_ho['HistGradientBoosting'] = hist_pred\n",
    "holdout_results.append({'model': 'HistGradientBoosting', **hist_metrics})\n",
    "print(f\"HistGradientBoosting Holdout MAE: {hist_metrics['MAE']:.2f}\")\n",
    "\n",
    "# 4. CatBoost\n",
    "catboost = CatBoostRegressor(**best_params['CatBoost'], random_state=42, verbose=0)\n",
    "catboost.fit(X_train_ho, y_train_ho)\n",
    "catboost_pred = catboost.predict(X_test_ho)\n",
    "catboost_metrics = evaluate_model(y_test_ho, catboost_pred)\n",
    "predictions_ho['CatBoost'] = catboost_pred\n",
    "holdout_results.append({'model': 'CatBoost', **catboost_metrics})\n",
    "print(f\"CatBoost Holdout MAE: {catboost_metrics['MAE']:.2f}\")\n",
    "\n",
    "# 5. WeightedEnsemble（CV Window 1-5で重み最適化）\n",
    "def optimize_weights_cv(cv_data, best_params):\n",
    "    \"\"\"CV Window 1-5 を使って重みを最適化（リーク防止）\"\"\"\n",
    "    all_preds = {name: [] for name in ['Ridge', 'ExtraTrees', 'HistGradientBoosting', 'CatBoost']}\n",
    "    all_y = []\n",
    "    \n",
    "    for d in cv_data:\n",
    "        # Ridge\n",
    "        m = Ridge(**best_params['Ridge'], random_state=42)\n",
    "        m.fit(d['X_train'], d['y_train'])\n",
    "        all_preds['Ridge'].extend(m.predict(d['X_test']))\n",
    "        \n",
    "        # ExtraTrees\n",
    "        m = ExtraTreesRegressor(**best_params['ExtraTrees'], random_state=42, n_jobs=-1)\n",
    "        m.fit(d['X_train'], d['y_train'])\n",
    "        all_preds['ExtraTrees'].extend(m.predict(d['X_test']))\n",
    "        \n",
    "        # HistGradientBoosting\n",
    "        m = HistGradientBoostingRegressor(**best_params['HistGradientBoosting'], random_state=42)\n",
    "        m.fit(d['X_train'], d['y_train'])\n",
    "        all_preds['HistGradientBoosting'].extend(m.predict(d['X_test']))\n",
    "        \n",
    "        # CatBoost\n",
    "        m = CatBoostRegressor(**best_params['CatBoost'], random_state=42, verbose=0)\n",
    "        m.fit(d['X_train'], d['y_train'])\n",
    "        all_preds['CatBoost'].extend(m.predict(d['X_test']))\n",
    "        \n",
    "        all_y.extend(d['y_test'])\n",
    "    \n",
    "    # 重み最適化\n",
    "    model_names = ['Ridge', 'ExtraTrees', 'HistGradientBoosting', 'CatBoost']\n",
    "    preds_matrix = np.column_stack([all_preds[name] for name in model_names])\n",
    "    y_array = np.array(all_y)\n",
    "    \n",
    "    def objective(weights):\n",
    "        ensemble_pred = preds_matrix @ weights\n",
    "        return mean_absolute_error(y_array, ensemble_pred)\n",
    "    \n",
    "    constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}\n",
    "    bounds = [(0, 1) for _ in range(len(model_names))]\n",
    "    initial_weights = np.ones(len(model_names)) / len(model_names)\n",
    "    result = minimize(objective, initial_weights, method='SLSQP',\n",
    "                     bounds=bounds, constraints=constraints)\n",
    "    return dict(zip(model_names, result.x))\n",
    "\n",
    "print(\"\\nアンサンブル重み最適化中（CV Window 1-5）...\")\n",
    "ensemble_weights = optimize_weights_cv(cv_data, best_params)\n",
    "print(\"\\n最適化された重み:\")\n",
    "for name, weight in ensemble_weights.items():\n",
    "    print(f\"  {name}: {weight:.4f}\")\n",
    "\n",
    "# Holdoutに適用\n",
    "ensemble_pred = sum(predictions_ho[name] * weight for name, weight in ensemble_weights.items())\n",
    "ensemble_metrics = evaluate_model(y_test_ho, ensemble_pred)\n",
    "holdout_results.append({'model': 'WeightedEnsemble', **ensemble_metrics})\n",
    "print(f\"\\nWeightedEnsemble Holdout MAE: {ensemble_metrics['MAE']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 最終結果まとめ\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"最終結果: Window 6 Holdout\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "holdout_df = pd.DataFrame(holdout_results)\n",
    "holdout_df = holdout_df.sort_values('MAE')\n",
    "print(\"\\n\" + holdout_df.to_string(index=False))\n",
    "\n",
    "# CV vs Holdout 比較\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CV MAE vs Holdout MAE 比較\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison = []\n",
    "for model in ['Ridge', 'ExtraTrees', 'HistGradientBoosting', 'CatBoost']:\n",
    "    cv_mae = cv_scores[model]\n",
    "    ho_mae = holdout_df[holdout_df['model'] == model]['MAE'].values[0]\n",
    "    comparison.append({\n",
    "        'model': model,\n",
    "        'CV_MAE (Window 1-5)': cv_mae,\n",
    "        'Holdout_MAE (Window 6)': ho_mae,\n",
    "        'diff': ho_mae - cv_mae\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison)\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# 結果保存\n",
    "holdout_df.to_csv(f'{output_dir}/holdout_results.csv', index=False)\n",
    "comparison_df.to_csv(f'{output_dir}/cv_vs_holdout.csv', index=False)\n",
    "print(f\"\\n保存:\")\n",
    "print(f\"  {output_dir}/holdout_results.csv\")\n",
    "print(f\"  {output_dir}/cv_vs_holdout.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 可視化\n",
    "# ==================================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 1. CV vs Holdout MAE比較\n",
    "ax1 = axes[0]\n",
    "models = comparison_df['model'].tolist()\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "ax1.bar(x - width/2, comparison_df['CV_MAE (Window 1-5)'], width, label='CV (Window 1-5)', color='steelblue', alpha=0.8)\n",
    "ax1.bar(x + width/2, comparison_df['Holdout_MAE (Window 6)'], width, label='Holdout (Window 6)', color='coral', alpha=0.8)\n",
    "ax1.set_xlabel('Model', fontsize=11)\n",
    "ax1.set_ylabel('MAE', fontsize=11)\n",
    "ax1.set_title('CV vs Holdout MAE Comparison', fontsize=12, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(models, rotation=15, ha='right')\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# 2. Holdout予測 vs 実績\n",
    "ax2 = axes[1]\n",
    "test_dates = df_clean[(df_clean['cdr_date'] >= holdout_window['test_start']) & \n",
    "                       (df_clean['cdr_date'] <= holdout_window['test_end'])]['cdr_date']\n",
    "ax2.plot(test_dates.values, y_test_ho.values, 'o-', label='Actual', color='black', linewidth=2, markersize=4)\n",
    "ax2.plot(test_dates.values, catboost_pred, 's--', label='CatBoost', color='coral', alpha=0.8, markersize=4)\n",
    "ax2.plot(test_dates.values, ensemble_pred, '^--', label='Ensemble', color='green', alpha=0.8, markersize=4)\n",
    "ax2.set_xlabel('Date', fontsize=11)\n",
    "ax2.set_ylabel('call_num', fontsize=11)\n",
    "ax2.set_title('Window 6 Holdout: Prediction vs Actual', fontsize=12, fontweight='bold')\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/exp25_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n保存: {output_dir}/exp25_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "**exp25: Window 1-5 CV + Window 6 Holdout + Optuna**\n",
    "\n",
    "### 構成\n",
    "- **CV (Window 1-5)**: Optunaでハイパーパラメータ最適化\n",
    "- **Holdout (Window 6)**: 最終評価（2019-09 ~ 2019-10）\n",
    "- **リーク防止**: Holdout期間のデータは最適化に一切使用していない\n",
    "\n",
    "### 評価の流れ\n",
    "1. Window 1-5 の平均MAEでOptuna最適化（50 trials × 4モデル）\n",
    "2. アンサンブル重みも Window 1-5 で最適化\n",
    "3. Window 6 で最終評価（1回のみ）\n",
    "\n",
    "### 出力ファイル\n",
    "1. `best_params.json` - 最適化されたパラメータ\n",
    "2. `holdout_results.csv` - Window 6 の最終結果\n",
    "3. `cv_vs_holdout.csv` - CV vs Holdout 比較\n",
    "4. `exp25_results.png` - 可視化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
