{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp22_v4: 追加モデル（XGBoost, LightGBM）のOptuna最適化\n",
    "\n",
    "**ベースライン**: exp22_v3\n",
    "\n",
    "**変更点**:\n",
    "- RandomForestを除外（計算コスト削減）\n",
    "\n",
    "**使用モデル**:\n",
    "1. Ridge\n",
    "2. HistGradientBoosting\n",
    "3. CatBoost\n",
    "4. XGBoost\n",
    "5. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "# 出力ディレクトリ\n",
    "output_dir = '../output/exp22_v4'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# データの読み込みと特徴量作成（exp22と同じ）\n",
    "# ==================================================================================\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    calender = pd.read_csv('../input/calender_data.csv')\n",
    "    cm_data = pd.read_csv('../input/cm_data.csv')\n",
    "    gt_service = pd.read_csv('../input/gt_service_name.csv')\n",
    "    acc_get = pd.read_csv('../input/regi_acc_get_data_transform.csv')\n",
    "    call_data = pd.read_csv('../input/regi_call_data_transform.csv')\n",
    "    \n",
    "    calender['cdr_date'] = pd.to_datetime(calender['cdr_date'])\n",
    "    cm_data['cdr_date'] = pd.to_datetime(cm_data['cdr_date'])\n",
    "    acc_get['cdr_date'] = pd.to_datetime(acc_get['cdr_date'])\n",
    "    call_data['cdr_date'] = pd.to_datetime(call_data['cdr_date'])\n",
    "    gt_service['week'] = pd.to_datetime(gt_service['week'])\n",
    "    \n",
    "    return calender, cm_data, gt_service, acc_get, call_data\n",
    "\n",
    "def merge_datasets(calender, cm_data, gt_service, acc_get, call_data):\n",
    "    df = call_data.copy()\n",
    "    df = df.merge(calender, on='cdr_date', how='left')\n",
    "    df = df.merge(cm_data, on='cdr_date', how='left')\n",
    "    df = df.merge(acc_get, on='cdr_date', how='left')\n",
    "    \n",
    "    gt_service_daily = []\n",
    "    for idx, row in gt_service.iterrows():\n",
    "        week_start = row['week']\n",
    "        for i in range(7):\n",
    "            date = week_start + timedelta(days=i)\n",
    "            gt_service_daily.append({'cdr_date': date, 'search_cnt': row['search_cnt']})\n",
    "    \n",
    "    gt_daily = pd.DataFrame(gt_service_daily)\n",
    "    df = df.merge(gt_daily, on='cdr_date', how='left')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_basic_time_features(df):\n",
    "    df = df.copy()\n",
    "    df['year'] = df['cdr_date'].dt.year\n",
    "    df['month'] = df['cdr_date'].dt.month\n",
    "    df['day_of_month'] = df['cdr_date'].dt.day\n",
    "    df['quarter'] = df['cdr_date'].dt.quarter\n",
    "    df['day_of_year'] = df['cdr_date'].dt.dayofyear\n",
    "    df['week_of_year'] = df['cdr_date'].dt.isocalendar().week\n",
    "    df['days_from_start'] = (df['cdr_date'] - df['cdr_date'].min()).dt.days\n",
    "    df['is_month_start'] = (df['day_of_month'] <= 5).astype(int)\n",
    "    df['is_month_end'] = (df['day_of_month'] >= 25).astype(int)\n",
    "    return df\n",
    "\n",
    "def create_lag_features(df, target_col='call_num', lags=[1, 2, 3, 5, 7, 14, 30]):\n",
    "    df = df.copy()\n",
    "    for lag in lags:\n",
    "        df[f'lag_{lag}'] = df[target_col].shift(lag)\n",
    "    return df\n",
    "\n",
    "def create_rolling_features(df, target_col='call_num', windows=[3, 7, 14, 30]):\n",
    "    df = df.copy()\n",
    "    for window in windows:\n",
    "        df[f'ma_{window}'] = df[target_col].shift(1).rolling(window=window, min_periods=1).mean()\n",
    "        df[f'ma_std_{window}'] = df[target_col].shift(1).rolling(window=window, min_periods=1).std()\n",
    "    return df\n",
    "\n",
    "def create_aggregated_features(df):\n",
    "    df = df.copy()\n",
    "    df['cm_7d'] = df['cm_flg'].shift(1).rolling(window=7, min_periods=1).sum()\n",
    "    df['gt_ma_7'] = df['search_cnt'].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "    df['acc_ma_7'] = df['acc_get_cnt'].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "    \n",
    "    df['dow_avg'] = np.nan\n",
    "    for dow in df['dow'].unique():\n",
    "        mask = df['dow'] == dow\n",
    "        df.loc[mask, 'dow_avg'] = df.loc[mask, 'call_num'].shift(1).expanding().mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_acc_get_features(df):\n",
    "    df = df.copy()\n",
    "    df['acc_get_lag7'] = df['acc_get_cnt'].shift(7)\n",
    "    df['acc_get_sum_14d'] = df['acc_get_cnt'].shift(1).rolling(window=14, min_periods=1).sum()\n",
    "    return df\n",
    "\n",
    "def create_regime_change_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    tax_implementation_date = pd.Timestamp('2019-10-01')\n",
    "    rush_deadline = pd.Timestamp('2019-09-30')\n",
    "    \n",
    "    df['days_to_2019_10_01'] = (tax_implementation_date - df['cdr_date']).dt.days\n",
    "    df['is_pre_2019_10_01'] = (df['cdr_date'] < tax_implementation_date).astype(int)\n",
    "    df['is_post_2019_10_01'] = (df['cdr_date'] >= tax_implementation_date).astype(int)\n",
    "    \n",
    "    df['days_to_2019_09_30'] = (rush_deadline - df['cdr_date']).dt.days\n",
    "    df['is_pre_2019_09_30'] = (df['cdr_date'] < rush_deadline).astype(int)\n",
    "    df['is_post_2019_09_30'] = (df['cdr_date'] >= rush_deadline).astype(int)\n",
    "    \n",
    "    rush_start = rush_deadline - pd.Timedelta(days=90)\n",
    "    df['is_rush_period'] = ((df['cdr_date'] >= rush_start) & \n",
    "                            (df['cdr_date'] <= rush_deadline)).astype(int)\n",
    "    \n",
    "    adaptation_end = tax_implementation_date + pd.Timedelta(days=30)\n",
    "    df['is_adaptation_period'] = ((df['cdr_date'] >= tax_implementation_date) & \n",
    "                                   (df['cdr_date'] <= adaptation_end)).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print('データ読み込み・特徴量作成関数を定義しました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# データ準備\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"*\" * 80)\n",
    "print(\"exp22_v4: 追加モデル（XGBoost, LightGBM）のOptuna最適化\")\n",
    "print(\"*\" * 80)\n",
    "\n",
    "calender, cm_data, gt_service, acc_get, call_data = load_and_preprocess_data()\n",
    "df = merge_datasets(calender, cm_data, gt_service, acc_get, call_data)\n",
    "df = create_basic_time_features(df)\n",
    "df = create_lag_features(df)\n",
    "df = create_rolling_features(df)\n",
    "df = create_aggregated_features(df)\n",
    "df = create_acc_get_features(df)\n",
    "df = create_regime_change_features(df)\n",
    "\n",
    "# 翌日の入電数を目的変数にする\n",
    "df['target_next_day'] = df['call_num'].shift(-1)\n",
    "df = df.dropna(subset=['target_next_day']).reset_index(drop=True)\n",
    "\n",
    "# 平日のみ\n",
    "df_model = df[df['dow'].isin([1, 2, 3, 4, 5])].copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n平日データ数: {len(df_model)}行\")\n",
    "print(f\"期間: {df_model['cdr_date'].min()} ~ {df_model['cdr_date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# exp22の特徴量（33個）\n",
    "# ==================================================================================\n",
    "\n",
    "feature_cols_exp22 = [\n",
    "    # 基本時系列特徴量\n",
    "    'dow', 'day_of_month', 'year', \n",
    "    'day_of_year', 'week_of_year',\n",
    "    'is_month_start', 'is_month_end',\n",
    "    # カレンダー特徴量\n",
    "    'day_before_holiday_flag',\n",
    "    # 外部データ\n",
    "    'cm_flg', 'acc_get_cnt', 'search_cnt',\n",
    "    # 集約特徴量\n",
    "    'cm_7d', 'gt_ma_7', 'acc_ma_7', 'dow_avg',\n",
    "    # ラグ特徴量\n",
    "    'lag_1', 'lag_2', 'lag_3', 'lag_5', 'lag_7', 'lag_14', 'lag_30',\n",
    "    # 移動平均特徴量（ma_14, ma_std_14削除）\n",
    "    'ma_3', 'ma_7', 'ma_30',\n",
    "    'ma_std_3', 'ma_std_7', 'ma_std_30',\n",
    "    # レジーム変化特徴量（is_pre_*削除、days_to_2019_09_30削除）\n",
    "    'days_to_2019_10_01', 'is_post_2019_10_01',\n",
    "    'is_post_2019_09_30',\n",
    "    'is_rush_period', 'is_adaptation_period',\n",
    "]\n",
    "\n",
    "print(f\"特徴量数: {len(feature_cols_exp22)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Holdout Validation 設定（exp22と同じ）\n",
    "# ==================================================================================\n",
    "\n",
    "# 欠損値を除去\n",
    "df_clean = df_model.dropna(subset=feature_cols_exp22 + ['target_next_day']).copy()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Holdout Validation 設定\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Holdout分割\n",
    "test_start_date = pd.Timestamp('2020-01-30')\n",
    "train_end_date = test_start_date - pd.Timedelta(days=1)\n",
    "\n",
    "train_df = df_clean[df_clean['cdr_date'] <= train_end_date].copy()\n",
    "test_df = df_clean[df_clean['cdr_date'] >= test_start_date].copy()\n",
    "\n",
    "X_train = train_df[feature_cols_exp22]\n",
    "y_train = train_df['target_next_day']\n",
    "X_test = test_df[feature_cols_exp22]\n",
    "y_test = test_df['target_next_day']\n",
    "\n",
    "print(f\"\\nTrain: {len(X_train)}件 ({train_df['cdr_date'].min().strftime('%Y-%m-%d')} ~ {train_df['cdr_date'].max().strftime('%Y-%m-%d')})\")\n",
    "print(f\"Test : {len(X_test)}件 ({test_df['cdr_date'].min().strftime('%Y-%m-%d')} ~ {test_df['cdr_date'].max().strftime('%Y-%m-%d')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 評価関数\n",
    "# ==================================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def calculate_wape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true)) * 100\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    return {\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'R2': r2_score(y_true, y_pred),\n",
    "        'WAPE': calculate_wape(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "print('評価関数を定義しました')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 1: Optunaによる最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Optuna による最適化 - 準備\n",
    "# ==================================================================================\n",
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# TimeSeriesCV（3分割）\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Step 1: Optunaによる最適化\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n各モデル100トライアル、TimeSeriesCV(n_splits=3)で評価\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# Ridge 最適化\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"[1/5] Ridge 最適化\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "def objective_ridge(trial):\n",
    "    alpha = trial.suggest_float('alpha', 0.01, 100.0, log=True)\n",
    "    \n",
    "    scores = []\n",
    "    for train_idx, val_idx in tscv.split(X_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model = Ridge(alpha=alpha, random_state=42)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        pred = model.predict(X_val)\n",
    "        scores.append(mean_absolute_error(y_val, pred))\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "study_ridge = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study_ridge.optimize(objective_ridge, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nBest MAE (CV): {study_ridge.best_value:.2f}\")\n",
    "print(f\"Best params: {study_ridge.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# HistGradientBoosting 最適化\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"[2/5] HistGradientBoosting 最適化\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "def objective_hist(trial):\n",
    "    params = {\n",
    "        'max_iter': trial.suggest_int('max_iter', 100, 600),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 30),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 5, 50),\n",
    "        'l2_regularization': trial.suggest_float('l2_regularization', 0.01, 50.0, log=True),\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    for train_idx, val_idx in tscv.split(X_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model = HistGradientBoostingRegressor(**params, random_state=42)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        pred = model.predict(X_val)\n",
    "        scores.append(mean_absolute_error(y_val, pred))\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "study_hist = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study_hist.optimize(objective_hist, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nBest MAE (CV): {study_hist.best_value:.2f}\")\n",
    "print(f\"Best params: {study_hist.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# CatBoost 最適化\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"[3/5] CatBoost 最適化\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 500, 3000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'depth': trial.suggest_int('depth', 4, 12),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.1, 10.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    for train_idx, val_idx in tscv.split(X_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model = CatBoostRegressor(**params, random_state=42, verbose=0)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        pred = model.predict(X_val)\n",
    "        scores.append(mean_absolute_error(y_val, pred))\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "study_catboost = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study_catboost.optimize(objective_catboost, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nBest MAE (CV): {study_catboost.best_value:.2f}\")\n",
    "print(f\"Best params: {study_catboost.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# XGBoost 最適化\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"[4/5] XGBoost 最適化\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "def objective_xgboost(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 10.0, log=True),\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    for train_idx, val_idx in tscv.split(X_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model = XGBRegressor(**params, random_state=42, verbosity=0, n_jobs=-1)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        pred = model.predict(X_val)\n",
    "        scores.append(mean_absolute_error(y_val, pred))\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "study_xgboost = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study_xgboost.optimize(objective_xgboost, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nBest MAE (CV): {study_xgboost.best_value:.2f}\")\n",
    "print(f\"Best params: {study_xgboost.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# LightGBM 最適化\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"[5/5] LightGBM 最適化\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "def objective_lightgbm(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 10.0, log=True),\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    for train_idx, val_idx in tscv.split(X_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model = LGBMRegressor(**params, random_state=42, verbosity=-1, n_jobs=-1)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        pred = model.predict(X_val)\n",
    "        scores.append(mean_absolute_error(y_val, pred))\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "study_lightgbm = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study_lightgbm.optimize(objective_lightgbm, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nBest MAE (CV): {study_lightgbm.best_value:.2f}\")\n",
    "print(f\"Best params: {study_lightgbm.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 最適化されたパラメータの保存\n",
    "# ==================================================================================\n",
    "\n",
    "OPTIMIZED_PARAMS = {\n",
    "    'Ridge': study_ridge.best_params,\n",
    "    'HistGradientBoosting': study_hist.best_params,\n",
    "    'CatBoost': study_catboost.best_params,\n",
    "    'XGBoost': study_xgboost.best_params,\n",
    "    'LightGBM': study_lightgbm.best_params,\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"exp22_v4 最適化パラメータ\")\n",
    "print(\"=\" * 80)\n",
    "for model_name, params in OPTIMIZED_PARAMS.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# パラメータをCSVに保存\n",
    "params_list = []\n",
    "for model_name, params in OPTIMIZED_PARAMS.items():\n",
    "    for key, value in params.items():\n",
    "        params_list.append({'model': model_name, 'param': key, 'value': value})\n",
    "\n",
    "params_df = pd.DataFrame(params_list)\n",
    "params_df.to_csv(f'{output_dir}/optimized_params.csv', index=False)\n",
    "print(f\"\\nパラメータを保存しました: {output_dir}/optimized_params.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 2: 最適化パラメータでの最終評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 最適化パラメータでの最終評価\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Step 2: 最適化パラメータでの最終評価（Holdout Test）\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "final_results = []\n",
    "final_predictions = {}\n",
    "final_models = {}\n",
    "\n",
    "# 1. Ridge\n",
    "print(\"\\n[1/5] Ridge...\")\n",
    "ridge_opt = Ridge(**OPTIMIZED_PARAMS['Ridge'], random_state=42)\n",
    "ridge_opt.fit(X_train, y_train)\n",
    "ridge_pred_opt = ridge_opt.predict(X_test)\n",
    "ridge_metrics_opt = evaluate_model(y_test, ridge_pred_opt)\n",
    "print(f\"  MAE: {ridge_metrics_opt['MAE']:.2f}\")\n",
    "final_predictions['Ridge'] = ridge_pred_opt\n",
    "final_models['Ridge'] = ridge_opt\n",
    "final_results.append({'model': 'Ridge', **ridge_metrics_opt})\n",
    "\n",
    "# 2. HistGradientBoosting\n",
    "print(\"\\n[2/5] HistGradientBoosting...\")\n",
    "hist_opt = HistGradientBoostingRegressor(**OPTIMIZED_PARAMS['HistGradientBoosting'], random_state=42)\n",
    "hist_opt.fit(X_train, y_train)\n",
    "hist_pred_opt = hist_opt.predict(X_test)\n",
    "hist_metrics_opt = evaluate_model(y_test, hist_pred_opt)\n",
    "print(f\"  MAE: {hist_metrics_opt['MAE']:.2f}\")\n",
    "final_predictions['HistGradientBoosting'] = hist_pred_opt\n",
    "final_models['HistGradientBoosting'] = hist_opt\n",
    "final_results.append({'model': 'HistGradientBoosting', **hist_metrics_opt})\n",
    "\n",
    "# 3. CatBoost\n",
    "print(\"\\n[3/5] CatBoost...\")\n",
    "catboost_opt = CatBoostRegressor(**OPTIMIZED_PARAMS['CatBoost'], random_state=42, verbose=0)\n",
    "catboost_opt.fit(X_train, y_train)\n",
    "catboost_pred_opt = catboost_opt.predict(X_test)\n",
    "catboost_metrics_opt = evaluate_model(y_test, catboost_pred_opt)\n",
    "print(f\"  MAE: {catboost_metrics_opt['MAE']:.2f}\")\n",
    "final_predictions['CatBoost'] = catboost_pred_opt\n",
    "final_models['CatBoost'] = catboost_opt\n",
    "final_results.append({'model': 'CatBoost', **catboost_metrics_opt})\n",
    "\n",
    "# 4. XGBoost\n",
    "print(\"\\n[4/5] XGBoost...\")\n",
    "xgboost_opt = XGBRegressor(**OPTIMIZED_PARAMS['XGBoost'], random_state=42, verbosity=0, n_jobs=-1)\n",
    "xgboost_opt.fit(X_train, y_train)\n",
    "xgboost_pred_opt = xgboost_opt.predict(X_test)\n",
    "xgboost_metrics_opt = evaluate_model(y_test, xgboost_pred_opt)\n",
    "print(f\"  MAE: {xgboost_metrics_opt['MAE']:.2f}\")\n",
    "final_predictions['XGBoost'] = xgboost_pred_opt\n",
    "final_models['XGBoost'] = xgboost_opt\n",
    "final_results.append({'model': 'XGBoost', **xgboost_metrics_opt})\n",
    "\n",
    "# 5. LightGBM\n",
    "print(\"\\n[5/5] LightGBM...\")\n",
    "lightgbm_opt = LGBMRegressor(**OPTIMIZED_PARAMS['LightGBM'], random_state=42, verbosity=-1, n_jobs=-1)\n",
    "lightgbm_opt.fit(X_train, y_train)\n",
    "lightgbm_pred_opt = lightgbm_opt.predict(X_test)\n",
    "lightgbm_metrics_opt = evaluate_model(y_test, lightgbm_pred_opt)\n",
    "print(f\"  MAE: {lightgbm_metrics_opt['MAE']:.2f}\")\n",
    "final_predictions['LightGBM'] = lightgbm_pred_opt\n",
    "final_models['LightGBM'] = lightgbm_opt\n",
    "final_results.append({'model': 'LightGBM', **lightgbm_metrics_opt})\n",
    "\n",
    "final_df = pd.DataFrame(final_results).sort_values('MAE')\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"最適化パラメータでの結果\")\n",
    "print(\"=\" * 80)\n",
    "print(final_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 3: exp22との比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# exp22との比較\n",
    "# ==================================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"exp22 vs exp22_v4 比較\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# exp22の結果を読み込み\n",
    "exp22_path = '../output/exp22/final_results.csv'\n",
    "if os.path.exists(exp22_path):\n",
    "    exp22_df = pd.read_csv(exp22_path)\n",
    "    \n",
    "    print(\"\\n【exp22の結果】\")\n",
    "    print(exp22_df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n【exp22_v4の結果】\")\n",
    "    print(final_df.to_string(index=False))\n",
    "    \n",
    "    # 共通モデルの比較\n",
    "    common_models = set(exp22_df['model']) & set(final_df['model'])\n",
    "    if common_models:\n",
    "        print(\"\\n【共通モデルの比較】\")\n",
    "        comparison_data = []\n",
    "        for model in common_models:\n",
    "            exp22_mae = exp22_df[exp22_df['model'] == model]['MAE'].values[0]\n",
    "            exp22_v4_mae = final_df[final_df['model'] == model]['MAE'].values[0]\n",
    "            comparison_data.append({\n",
    "                'model': model,\n",
    "                'exp22_MAE': exp22_mae,\n",
    "                'exp22_v4_MAE': exp22_v4_mae,\n",
    "                'diff': exp22_v4_mae - exp22_mae\n",
    "            })\n",
    "        comparison_df = pd.DataFrame(comparison_data).sort_values('exp22_v4_MAE')\n",
    "        print(comparison_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"exp22の結果ファイルが見つかりません。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 可視化\n",
    "# ==================================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "models = final_df['model'].tolist()\n",
    "maes = final_df['MAE'].tolist()\n",
    "r2s = final_df['R2'].tolist()\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(models)))\n",
    "bars = ax.bar(models, maes, color=colors)\n",
    "\n",
    "ax.set_xlabel('Model', fontsize=12)\n",
    "ax.set_ylabel('MAE', fontsize=12)\n",
    "ax.set_title('exp22_v4: Model Comparison (Holdout Test)', fontsize=14, fontweight='bold')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# MAE値をバーの上に表示\n",
    "for bar, mae, r2 in zip(bars, maes, r2s):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "            f'{mae:.1f}\\n(R²={r2:.2f})', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n保存しました: {output_dir}/model_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 特徴量重要度分析\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"特徴量重要度分析\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 各モデルの特徴量重要度\n",
    "importance_data = {}\n",
    "\n",
    "# XGBoost\n",
    "importance_data['XGBoost'] = xgboost_opt.feature_importances_\n",
    "\n",
    "# LightGBM\n",
    "importance_data['LightGBM'] = lightgbm_opt.feature_importances_\n",
    "\n",
    "# CatBoost\n",
    "importance_data['CatBoost'] = catboost_opt.feature_importances_\n",
    "\n",
    "# DataFrameにまとめる\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols_exp22,\n",
    "    'XGBoost': importance_data['XGBoost'],\n",
    "    'LightGBM': importance_data['LightGBM'],\n",
    "    'CatBoost': importance_data['CatBoost']\n",
    "})\n",
    "\n",
    "# 各モデルの重要度を表示\n",
    "for model_name in ['XGBoost', 'LightGBM', 'CatBoost']:\n",
    "    print(f\"\\n【{model_name}】Top 10\")\n",
    "    sorted_df = importance_df[['feature', model_name]].sort_values(model_name, ascending=False).head(10)\n",
    "    print(sorted_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 特徴量重要度の可視化\n",
    "# ==================================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 10))\n",
    "\n",
    "for idx, model_name in enumerate(['XGBoost', 'LightGBM', 'CatBoost']):\n",
    "    ax = axes[idx]\n",
    "    sorted_df = importance_df[['feature', model_name]].sort_values(model_name, ascending=True)\n",
    "    colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(sorted_df)))\n",
    "    ax.barh(sorted_df['feature'], sorted_df[model_name], color=colors)\n",
    "    ax.set_xlabel('Importance', fontsize=11)\n",
    "    ax.set_title(f'{model_name}', fontsize=13, fontweight='bold')\n",
    "    ax.grid(alpha=0.3, axis='x')\n",
    "\n",
    "plt.suptitle('Feature Importance (exp22_v4 Models)', fontsize=15, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "importance_df.to_csv(f'{output_dir}/feature_importance.csv', index=False)\n",
    "print(f\"\\n保存しました: {output_dir}/feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# 最終結果の保存\n",
    "# ==================================================================================\n",
    "\n",
    "final_df.to_csv(f'{output_dir}/final_results.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"exp22_v4 最終結果\")\n",
    "print(\"=\" * 80)\n",
    "print(final_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n保存しました: {output_dir}/final_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**exp22_v4: 追加モデル（XGBoost, LightGBM）のOptuna最適化**\n",
    "\n",
    "### 使用モデル\n",
    "- Ridge\n",
    "- HistGradientBoosting\n",
    "- CatBoost\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "\n",
    "### 除外したモデル\n",
    "- WeightedEnsemble\n",
    "- ExtraTrees\n",
    "- RandomForest（exp22_v3から除外）\n",
    "\n",
    "### 実験内容\n",
    "1. **Optuna最適化**: 各モデル100トライアル、TimeSeriesCV(n_splits=3)\n",
    "2. **最終評価**: Holdout Test（exp22と同じ期間）\n",
    "3. **exp22との比較**\n",
    "\n",
    "### 出力ファイル\n",
    "1. `optimized_params.csv` - 最適化パラメータ\n",
    "2. `final_results.csv` - 最終結果\n",
    "3. `model_comparison.png` - モデル比較グラフ\n",
    "4. `feature_importance.csv` - 特徴量重要度\n",
    "5. `feature_importance.png` - 特徴量重要度グラフ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
